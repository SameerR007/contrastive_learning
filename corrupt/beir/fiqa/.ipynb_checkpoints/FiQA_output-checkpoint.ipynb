{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6d4b65f-fa6b-4517-8694-8627bc49833b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T00:41:46.856014Z",
     "iopub.status.busy": "2025-03-05T00:41:46.855377Z",
     "iopub.status.idle": "2025-03-05T00:41:46.941363Z",
     "shell.execute_reply": "2025-03-05T00:41:46.940762Z"
    },
    "papermill": {
     "duration": 0.091493,
     "end_time": "2025-03-05T00:41:46.942121",
     "exception": false,
     "start_time": "2025-03-05T00:41:46.850628",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dss/dsshome1/07/ra65bex2/srawat/myenv/lib/python3.12/site-packages/beir/datasets/data_loader.py:8: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "from beir.datasets.data_loader import GenericDataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a91d6914-e301-422c-b839-1fafeb1e8fa4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T00:41:46.950288Z",
     "iopub.status.busy": "2025-03-05T00:41:46.949785Z",
     "iopub.status.idle": "2025-03-05T00:41:46.952567Z",
     "shell.execute_reply": "2025-03-05T00:41:46.952259Z"
    },
    "papermill": {
     "duration": 0.007299,
     "end_time": "2025-03-05T00:41:46.953291",
     "exception": false,
     "start_time": "2025-03-05T00:41:46.945992",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_path = '/dss/dsshome1/07/ra65bex2/srawat/fiqa/fiqa'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41e17333-2c34-4b7b-91f6-3cbd3972f0d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T00:41:46.962255Z",
     "iopub.status.busy": "2025-03-05T00:41:46.961762Z",
     "iopub.status.idle": "2025-03-05T00:41:47.380210Z",
     "shell.execute_reply": "2025-03-05T00:41:47.379648Z"
    },
    "papermill": {
     "duration": 0.424296,
     "end_time": "2025-03-05T00:41:47.381018",
     "exception": false,
     "start_time": "2025-03-05T00:41:46.956722",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d48d79afba7247569ae5c17956bab16b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/57638 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "corpus, queries, qrels = GenericDataLoader(data_path).load(split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d653c60-435a-4e10-8506-6ef5d01f8675",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T00:41:47.389674Z",
     "iopub.status.busy": "2025-03-05T00:41:47.389457Z",
     "iopub.status.idle": "2025-03-05T00:41:49.720566Z",
     "shell.execute_reply": "2025-03-05T00:41:49.720031Z"
    },
    "papermill": {
     "duration": 2.336101,
     "end_time": "2025-03-05T00:41:49.721321",
     "exception": false,
     "start_time": "2025-03-05T00:41:47.385220",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /dss/dsshome1/07/ra65bex2/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /dss/dsshome1/07/ra65bex2/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "def clean_text(text):\n",
    "    return re.sub(r'[^\\w\\s.!?]', '', text)\n",
    "def select_words(text, percentage):\n",
    "    words = [w for w in text.split() if w.lower() not in stop_words]\n",
    "    return random.sample(words, min(int(percentage*len(words)), len(words)))\n",
    "def introduce_typo(word):\n",
    "    if len(word) > 1:\n",
    "        idx = random.randint(0, len(word) - 1)\n",
    "        return word[:idx] + random.choice('abcdefghijklmnopqrstuvwxyz') + word[idx+1:]\n",
    "    return word\n",
    "def introduce_noise(word):\n",
    "    noise_chars = ['@', '#', '$', '%', '&', '*']\n",
    "    if len(word) > 1:\n",
    "        idx = random.randint(0, len(word) - 1)\n",
    "        return word[:idx] + random.choice(noise_chars) + word[idx+1:]\n",
    "    return word\n",
    "def replace_with_synonym(word):\n",
    "    synonyms = [syn.lemmas()[0].name() for syn in wordnet.synsets(word) if syn.lemmas()]\n",
    "    return random.choice(synonyms) if synonyms else word\n",
    "def corrupt_word(word, method):\n",
    "    if method == 'typo':\n",
    "        return introduce_typo(word)\n",
    "    elif method == 'noise':\n",
    "        return introduce_noise(word)\n",
    "    elif method == 'synonym':\n",
    "        return replace_with_synonym(word)\n",
    "    return word\n",
    "def corrupt_text(text):\n",
    "    corrupted_words = []  \n",
    "    words_to_corrupt=select_words(clean_text(text), percentage=0.5)\n",
    "    for word in clean_text(text).split():\n",
    "        if word in words_to_corrupt:\n",
    "            corruption_method = random.choice(['typo', 'noise', 'synonym'])\n",
    "            corrupted_words.append(corrupt_word(word, corruption_method))\n",
    "        else:\n",
    "            corrupted_words.append(word)\n",
    "    return ' '.join(corrupted_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a29044d5-3952-4f3d-aa43-e1efd34fcad3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T00:41:49.731496Z",
     "iopub.status.busy": "2025-03-05T00:41:49.731271Z",
     "iopub.status.idle": "2025-03-05T00:41:54.982724Z",
     "shell.execute_reply": "2025-03-05T00:41:54.981201Z"
    },
    "papermill": {
     "duration": 5.256922,
     "end_time": "2025-03-05T00:41:54.984086",
     "exception": false,
     "start_time": "2025-03-05T00:41:49.727164",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "contrastive_pairs=[]\n",
    "query_lengths = []\n",
    "import random\n",
    "c=0\n",
    "for query_id, relevant_docs in qrels.items():\n",
    "    try:\n",
    "        query_text = queries[query_id]\n",
    "        query_lengths.append(len(query_text.split()))\n",
    "        for doc_id in relevant_docs:\n",
    "            positive = corpus[doc_id][\"text\"]\n",
    "        #print(relevant_docs)\n",
    "        positive_doc_ids = set(relevant_docs)\n",
    "        all_doc_ids = set(corpus.keys())\n",
    "        negative_doc_ids = all_doc_ids - positive_doc_ids\n",
    "        negative_doc_ids=list(negative_doc_ids)\n",
    "        negative_doc_samples = random.sample(negative_doc_ids, k=5)\n",
    "        negatives=[]\n",
    "        for neg_doc_id in negative_doc_samples:\n",
    "            negative_doc_text = corpus[neg_doc_id][\"text\"]\n",
    "            negatives.append(negative_doc_text)\n",
    "        contrastive_pairs.append({\n",
    "            \"anchor\": corrupt_text(query_text),\n",
    "            \"positive\": positive,\n",
    "            \"negatives\": negatives\n",
    "        })\n",
    "    except:\n",
    "        c=c+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49721946-fff3-4690-bd92-d981cecdf62b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T00:41:55.000119Z",
     "iopub.status.busy": "2025-03-05T00:41:54.999478Z",
     "iopub.status.idle": "2025-03-05T00:41:55.005616Z",
     "shell.execute_reply": "2025-03-05T00:41:55.005146Z"
    },
    "papermill": {
     "duration": 0.012437,
     "end_time": "2025-03-05T00:41:55.006362",
     "exception": false,
     "start_time": "2025-03-05T00:41:54.993925",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de8ef367-dcb4-4bb6-af3a-20f190930ed1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T00:41:55.014071Z",
     "iopub.status.busy": "2025-03-05T00:41:55.013934Z",
     "iopub.status.idle": "2025-03-05T00:41:55.050063Z",
     "shell.execute_reply": "2025-03-05T00:41:55.049651Z"
    },
    "papermill": {
     "duration": 0.040868,
     "end_time": "2025-03-05T00:41:55.050817",
     "exception": false,
     "start_time": "2025-03-05T00:41:55.009949",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "648"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(contrastive_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a2ccada-419a-4f79-ad4d-b605780281a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T00:41:55.059245Z",
     "iopub.status.busy": "2025-03-05T00:41:55.058670Z",
     "iopub.status.idle": "2025-03-05T00:41:55.071895Z",
     "shell.execute_reply": "2025-03-05T00:41:55.071463Z"
    },
    "papermill": {
     "duration": 0.017956,
     "end_time": "2025-03-05T00:41:55.072564",
     "exception": false,
     "start_time": "2025-03-05T00:41:55.054608",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'anchor': 'How to depo&it a cheque iss@ed to an associate in my business into my clientele account?',\n",
       "  'positive': \"Just have the associate sign the back and then deposit it.  It's called a third party cheque and is perfectly legal.  I wouldn't be surprised if it has a longer hold period and, as always, you don't get the money if the cheque doesn't clear. Now, you may have problems if it's a large amount or you're not very well known at the bank.  In that case you can have the associate go to the bank and endorse it in front of the teller with some ID.  You don't even technically have to be there.  Anybody can deposit money to your account if they have the account number. He could also just deposit it in his account and write a cheque to the business.\",\n",
       "  'negatives': [\"It would be worth looking at their details as they will outline clearly what the 2% is on. Having said that the 2% will probably be on the value of the portfolio at the time the charge is calculated. (It might be that they don't levy this on the cash section of portfolio, it might be that they do.) They will usually make you sign a direct debit form so that they can take the fees straight from you. There are much better deals around than this, 2% is a huge fee if you had an portfolio that is worth £100,000 after some years the fees they would be charging you would be £2,000 a year. it's worth shopping around for a better deal, as it can prove costly to change ISA provider at later date.\",\n",
       "   \"Private Equity is simply some type of an investment company, which is owned in a way not accessible to the public. ie: Warren Buffet runs Berkshire Hatheway, which is an investment company which itself is traded on the New York Stock Exchange. This means that anyone can buy shares in the company, and own a small fraction of it. If Warren Buffet owned all the shares of Berkshire Hatheway, it would be a Private Equity company. Note that 'Equity' refers to the ownership of the company itself; a private investment company may simply buy Bonds (which are a form of Debt), in which case, they would not be technically considered a 'Private Equity' company. A Hedge Fund is a very broad term which I don't believe has significant meaning. Technically, it means something along the lines of an investment fund (either public or private) which attempts to hedge the risks of its portfolio, by carefully considering what type of investments it purchased. This refers back to the meaning of 'hedge', ie: 'hedging your bets'. In my opinion, 'Hedge Fund' is not meaningfully different from 'investment fund' or other similar terms. It is just the most popular way to refer to this type of industry at the present time.  You can see the trend of using the term 'investment fund' vs 'hedge fund' using this link: https://trends.google.com/trends/explore?date=all&q=hedge%20fund,investment%20fund Note that the high-point of the use of 'hedge fund' occurred on October 2008, right at the peak of the global financial crisis. The term evokes a certain image of 'high finance' / 'wall-street types' that may exploit various situations (such as tax legislation, or 'secret information') for their own gain. Without a clear definition, however, it is a term without much meaning. If you do a similar comparison between 'hedge fund' and 'private equity', you can see that the two correlate very closely; I believe the term 'private equity' is similarly misused to generally refer to 'investment bankers'. However in that case, 'private equity' has a more clear definition on its own merits.\",\n",
       "   \"Simply put, expansionary capex is seen as an investment and maintenance capex is seen as a cost.  In terms of valuation, free cash flow will not include expansionary capex because you are valuing the company as its current business. It's important to note that this approach will usually undervalue companies with strong investment opportunities.  Also, like /u/scarletham said, please edit out the identifying information to avoid any disclosure problems.\",\n",
       "   '\"Not cumulative volatility. It\\'s cumulative probability density. Time value isn\\'t linear because PDFs (probability distribution function) aren\\'t linear. It\\'s a type of distribution e.g. \"\"bell-curves\"\") These distributions are based on empirical data i.e. what we observe. BSM i.e. Black-Scholes-Merton includes the factors that influence an option price and include a PDF to represent the uncertainty/probability. Time value is based on historical volatility in the underlying asset price, in this case equity(stock). At the beginning, time value is high since there\\'s time until expiration and the stock is expected to move within a certain range based on historical performance. As it nears expiration, uncertainty over the final value diminishes. This causes probability for a certain price range to become more likely.  We can relate that to how people think, which affects the variation in the stock market price. Most people who are hoping for a value increase are optimistic about their chances of winning and will hold out towards the end. They see in the past d days, the stock has moved [-2%,+5%] so as a call buyer, they\\'re looking for that upside. With little time remaining though, their hopes quickly drop to 0 for any significant changes beyond the market price. (Likewise, people keep playing the lottery up until a certain age when they\\'re older and suddenly determine they\\'re never going to win.)  We see that reflected in the PDF used to represent options price movements. Thus your time value which is a function of probability decreases in a non-linear fashion.  Option price = intrinsic value + time value At expiration, your option price = intrinsic value = stock price - strike price, St >= K, and 0 for St < K.\"',\n",
       "   'Get a wide range of services for cylinder heads by reaching out to a competent company. From reconditioned cylinder heads to crack testing, chemical cleaning, grinding, manifold repairs, injector tube fitting, wet blasting and valve guide repairs you will get all these services at such companies.']},\n",
       " {'anchor': 'Can I send a monei ordmr from USPS as a business?',\n",
       "  'positive': \"Sure you can.  You can fill in whatever you want in the From section of a money order, so your business name and address would be fine. The price only includes the money order itself.  You can hand deliver it yourself if you want, but if you want to mail it, you'll have to provide an envelope and a stamp. Note that, since you won't have a bank record of this payment, you'll want to make sure you keep other records, such as the stub of the money order.  You should probably also ask the contractor to give you a receipt.\",\n",
       "  'negatives': ['The mortgage is a debt and you pay interest on it, typically more than you can earn elsewhere (especially once taxes are taken into account.) By lowering the principal, you lower the total interest you pay. This is true whether you sell the house after 1 year, 10 years, or 100 years. In your case, prepayments made in the next few years would mean that when you sell, your mortgage principal would be lower than it otherwise would have been, and your house equity will be higher. You can therefore either move up to more house for the same monthly payment, or have a lower monthly payment for the same kind of house. Either of those are good things, right? Now is the easiest time to find a little more money, so do it if you can. Later you will have more obligations, and develop a taste for more expensive things (statistically speaking) and therefore find a few hundred a month much harder to come by.',\n",
       "   'Now sweetums . .its the Fed that buys US treasuries to keep the Yield down  . . .wait but how can that be?  How can the Fed be the biggest holder of US treasuries . . .that would be like sucking your own dick . . .but hey . .its good for the economy  Its a good thing we have bred fucking Morons or the dollar might go into hyper inflation if Americans knew how to add',\n",
       "   \"Yes, from the point-of-view to the end speculator/investor in stocks, it is ludicrous to take on liabilities when you don't have to.  That's why single-stock options are far more liquid than single-stock futures. However, if you are a farmer with a huge mortgage depending upon the chaos of agricultural markets which are extremely volatile, a different structure might appeal to you.  You could long your inputs while shorting your outputs, locking in a profit.  That profit is probably lower than what one could expect over the long run without hedging, but it will surely be less volatile. Here's where the advantage of futures come in for that kind of structure: the margin on the longs and shorts can offset each other, forcing the farmer to have to put up much less of one's own money to hedge.  With options, this is not the case. Also, the gross margin between the inputs rarely fluctuate to an unmanageable degree, so if your shorts rise faster than your longs, you'll only have to post margin in the amount of the change in the net of the longs and shorts. This is why while options on commodities exist to satisfy speculators, futures are the most liquid.\",\n",
       "   '\"If you are already invested in a particular stock, I like JoeTaxpayer\\'s answer. Think about it as if you are re-buying the stocks you own every day you decide to keep them and don\\'t set emotional anchor points about what you paid for them or what they might be worth tomorrow. These lead to two major logical fallacies that investor\\'s commonly fall prey to, Loss Aversion and Sunk Cost, both of which can be bad for your portfolio in the long run. To avert these natural tendencies, I suggest having a game plan before you purchase a stock based on on your investment goals for that stock. For example a combination of one or more of the following: I\\'m investing for the long term and I expect this stock to appreciate and will hold it until (specific event/time) at which point I will (sell it all/sell it gradually over a fixed time period) right around the time I need the money. I\\'m going to bail on this stock if it falls more than X % from my purchase price. I\\'m going to cash out (all/half/some) of this investment if it gains more than x % from my purchase price to lock in my returns. The important thing is to arrive at a strategy before you are invested and are likely to be more emotional than rational.  Otherwise, it can be very hard to sell a \"\"hot\"\" stock that has suddenly jumped in price 25% because \"\"it has momentum\"\" (gambler\\'s fallacy). Conversely it can be hard to sell a stock when it drops by 25% because \"\"I know it will bounce back eventually\"\" (Sunk Cost/Loss Aversion Fallacy).  Also, remember that there is opportunity cost from sticking with a losing investment because your brain is saying \"\"I really haven\\'t lost money until I give up and sell it.\"\" When logically you should be thinking, \"\"If I move my money to a more promising investment I could get a better return than I am likely to on what I\\'m holding.\"\"\"',\n",
       "   '\"I made this mistake and tried calling Paypal...the first time I have ever been unhappy with their service.  The girl gave me some number but didn\\'t make it clear whether it was an order reference number or a reference phone number for the company I ordered from.  I called within 10 minutes of placing my order and they were unable to cancel or change the payment method.  I did find however, that even though you can\\'t pay paypal with your credit card, some banks will let you.  I went into my account and \"\"paid\"\" my account the amount needed using my credit card from the same bank that I had intended to use in the first place...hopefully it went through quickly enough to not get a service fee from Paypal\"']}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contrastive_pairs[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ade92f9-e3df-4d0a-b849-b1a721e18cf6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T00:41:55.080936Z",
     "iopub.status.busy": "2025-03-05T00:41:55.080599Z",
     "iopub.status.idle": "2025-03-05T00:41:55.091347Z",
     "shell.execute_reply": "2025-03-05T00:41:55.090931Z"
    },
    "papermill": {
     "duration": 0.015545,
     "end_time": "2025-03-05T00:41:55.092014",
     "exception": false,
     "start_time": "2025-03-05T00:41:55.076469",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "648"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(qrels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b97f7b4-f007-41f6-bfbb-1b9b01665e9d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T00:41:55.100771Z",
     "iopub.status.busy": "2025-03-05T00:41:55.100409Z",
     "iopub.status.idle": "2025-03-05T00:41:58.363931Z",
     "shell.execute_reply": "2025-03-05T00:41:58.363309Z"
    },
    "papermill": {
     "duration": 3.268829,
     "end_time": "2025-03-05T00:41:58.364972",
     "exception": false,
     "start_time": "2025-03-05T00:41:55.096143",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a415b29a-a543-4679-8f78-44f715b3067d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T00:41:58.375991Z",
     "iopub.status.busy": "2025-03-05T00:41:58.375728Z",
     "iopub.status.idle": "2025-03-05T00:41:58.379732Z",
     "shell.execute_reply": "2025-03-05T00:41:58.379293Z"
    },
    "papermill": {
     "duration": 0.0093,
     "end_time": "2025-03-05T00:41:58.380380",
     "exception": false,
     "start_time": "2025-03-05T00:41:58.371080",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ContrastiveDataset:\n",
    "    def __init__(self, pairs):\n",
    "        self.pairs = pairs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.pairs[idx]\n",
    "        return item[\"anchor\"], item[\"positive\"], item[\"negatives\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a39efeab-fd20-411a-80c5-315f362e00d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T00:41:58.389816Z",
     "iopub.status.busy": "2025-03-05T00:41:58.389462Z",
     "iopub.status.idle": "2025-03-05T00:41:58.413768Z",
     "shell.execute_reply": "2025-03-05T00:41:58.413373Z"
    },
    "papermill": {
     "duration": 0.029439,
     "end_time": "2025-03-05T00:41:58.414486",
     "exception": false,
     "start_time": "2025-03-05T00:41:58.385047",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "contrastive_dataset = ContrastiveDataset(contrastive_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d103bbfa-895a-4020-a7e5-21de659f27dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T00:41:58.423542Z",
     "iopub.status.busy": "2025-03-05T00:41:58.423119Z",
     "iopub.status.idle": "2025-03-05T00:41:58.433637Z",
     "shell.execute_reply": "2025-03-05T00:41:58.433246Z"
    },
    "papermill": {
     "duration": 0.015685,
     "end_time": "2025-03-05T00:41:58.434309",
     "exception": false,
     "start_time": "2025-03-05T00:41:58.418624",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_loader = DataLoader(contrastive_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8b0277f-f526-4087-82da-c4cdd65d32da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T00:41:58.443609Z",
     "iopub.status.busy": "2025-03-05T00:41:58.442812Z",
     "iopub.status.idle": "2025-03-05T00:41:58.454437Z",
     "shell.execute_reply": "2025-03-05T00:41:58.454015Z"
    },
    "papermill": {
     "duration": 0.016783,
     "end_time": "2025-03-05T00:41:58.455058",
     "exception": false,
     "start_time": "2025-03-05T00:41:58.438275",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e15526a4-b3fe-435b-91c9-ad4064562f0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T00:41:58.463789Z",
     "iopub.status.busy": "2025-03-05T00:41:58.463566Z",
     "iopub.status.idle": "2025-03-05T00:42:02.107126Z",
     "shell.execute_reply": "2025-03-05T00:42:02.106231Z"
    },
    "papermill": {
     "duration": 3.648958,
     "end_time": "2025-03-05T00:42:02.108132",
     "exception": false,
     "start_time": "2025-03-05T00:41:58.459174",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1164340/261098231.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  lora_model_baseline = torch.load(file_path_baseline)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "file_path_baseline =\"/dss/dsshome1/07/ra65bex2/srawat/contrastive_learning/v1.1/app_baseline/checkpoint_epoch_3.pth\"\n",
    "lora_model_baseline = torch.load(file_path_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9999e628-5966-4dda-b5c5-c0d762fce27d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T00:42:02.125216Z",
     "iopub.status.busy": "2025-03-05T00:42:02.124365Z",
     "iopub.status.idle": "2025-03-05T00:42:02.131256Z",
     "shell.execute_reply": "2025-03-05T00:42:02.130870Z"
    },
    "papermill": {
     "duration": 0.012517,
     "end_time": "2025-03-05T00:42:02.131960",
     "exception": false,
     "start_time": "2025-03-05T00:42:02.119443",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "lora_model_baseline = lora_model_baseline.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7e6a3a61-8db0-43db-b575-6399f8515950",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T00:42:02.140813Z",
     "iopub.status.busy": "2025-03-05T00:42:02.140599Z",
     "iopub.status.idle": "2025-03-05T00:42:02.574408Z",
     "shell.execute_reply": "2025-03-05T00:42:02.573803Z"
    },
    "papermill": {
     "duration": 0.439038,
     "end_time": "2025-03-05T00:42:02.575157",
     "exception": false,
     "start_time": "2025-03-05T00:42:02.136119",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "68ac4919-76f1-4349-a314-4b1061126655",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T00:42:02.584414Z",
     "iopub.status.busy": "2025-03-05T00:42:02.584179Z",
     "iopub.status.idle": "2025-03-05T00:42:02.586938Z",
     "shell.execute_reply": "2025-03-05T00:42:02.586564Z"
    },
    "papermill": {
     "duration": 0.008151,
     "end_time": "2025-03-05T00:42:02.587609",
     "exception": false,
     "start_time": "2025-03-05T00:42:02.579458",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cosine_distance(x, y):\n",
    "    return 1 - torch.nn.functional.cosine_similarity(x, y, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "990f63bd-4d48-4f58-a001-3b3250f65312",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T00:42:02.596839Z",
     "iopub.status.busy": "2025-03-05T00:42:02.596535Z",
     "iopub.status.idle": "2025-03-05T00:42:02.611192Z",
     "shell.execute_reply": "2025-03-05T00:42:02.610592Z"
    },
    "papermill": {
     "duration": 0.020177,
     "end_time": "2025-03-05T00:42:02.612176",
     "exception": false,
     "start_time": "2025-03-05T00:42:02.591999",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_mrr_baseline(model, data_loader_val, distance_fn):\n",
    "    model.eval()\n",
    "\n",
    "    total_rr = 0.0\n",
    "    num_queries = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader_val:\n",
    "            anchor_text = batch[0]\n",
    "            positive_text = batch[1]\n",
    "            negative_texts = batch[2]\n",
    "\n",
    "            anchor_input = tokenizer(anchor_text, return_tensors='pt', padding=True, truncation=True, max_length=512).to(device)\n",
    "            positive_input = tokenizer(positive_text, return_tensors='pt', padding=True, truncation=True, max_length=512).to(device)\n",
    "\n",
    "            anchor_embedding = model(**anchor_input).last_hidden_state[:, 0, :]\n",
    "            positive_embedding = model(**positive_input).last_hidden_state[:, 0, :]\n",
    "            negative_embedding = [model(**tokenizer(neg, return_tensors='pt', padding=True, truncation=True, max_length=512).to(device)).last_hidden_state[:, 0, :] for neg in negative_texts]\n",
    "\n",
    "            pos_dist = distance_fn(anchor_embedding, positive_embedding)\n",
    "            neg_dist = torch.stack([distance_fn(anchor_embedding, neg) for neg in negative_embedding], dim=-1)\n",
    "            all_similarities=torch.cat([-pos_dist.unsqueeze(1), -neg_dist], dim=1)\n",
    "\n",
    "            sorted_similarities, sorted_indices = torch.sort(all_similarities, dim=1, descending=True)\n",
    "\n",
    "            # Find the rank of the first relevant (positive) document\n",
    "            positive_rank = (sorted_indices == 0).nonzero(as_tuple=True)[1] + 1  # +1 to make rank 1-based\n",
    "            total_rr += torch.sum(1.0 / positive_rank.float()).item()  # Reciprocal rank\n",
    "            num_queries += len(positive_rank)\n",
    "\n",
    "    mrr = total_rr / num_queries\n",
    "    return mrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "534a9ec5-4211-4cb6-81f1-fb8a30caff92",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T00:42:02.621871Z",
     "iopub.status.busy": "2025-03-05T00:42:02.621387Z",
     "iopub.status.idle": "2025-03-05T00:42:25.958187Z",
     "shell.execute_reply": "2025-03-05T00:42:25.957460Z"
    },
    "papermill": {
     "duration": 23.342399,
     "end_time": "2025-03-05T00:42:25.959064",
     "exception": false,
     "start_time": "2025-03-05T00:42:02.616665",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5297325231410839\n"
     ]
    }
   ],
   "source": [
    "mrr_validation_baseline = evaluate_mrr_baseline(lora_model_baseline, data_loader, cosine_distance)\n",
    "print(mrr_validation_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61bbd65-41c9-4ac7-80ef-ba4a4fb02d45",
   "metadata": {
    "papermill": {
     "duration": 0.004314,
     "end_time": "2025-03-05T00:42:25.974655",
     "exception": false,
     "start_time": "2025-03-05T00:42:25.970341",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8a3dfd17-ee43-4c4e-9287-8ec6451bc062",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T00:42:25.984790Z",
     "iopub.status.busy": "2025-03-05T00:42:25.984336Z",
     "iopub.status.idle": "2025-03-05T00:42:26.351161Z",
     "shell.execute_reply": "2025-03-05T00:42:26.350653Z"
    },
    "papermill": {
     "duration": 0.373042,
     "end_time": "2025-03-05T00:42:26.352182",
     "exception": false,
     "start_time": "2025-03-05T00:42:25.979140",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1164340/2975798179.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  lora_model_average = torch.load(file_path_average)\n"
     ]
    }
   ],
   "source": [
    "file_path_average=\"/dss/dsshome1/07/ra65bex2/srawat/contrastive_learning/v1.1/app_average/average_checkpoint_epoch_3.pth\"\n",
    "lora_model_average = torch.load(file_path_average)\n",
    "lora_model_average = lora_model_average.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "49c10d3f-c53d-4222-aba4-0e763451baff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T00:42:26.363983Z",
     "iopub.status.busy": "2025-03-05T00:42:26.363261Z",
     "iopub.status.idle": "2025-03-05T00:42:26.366941Z",
     "shell.execute_reply": "2025-03-05T00:42:26.366545Z"
    },
    "papermill": {
     "duration": 0.009348,
     "end_time": "2025-03-05T00:42:26.367698",
     "exception": false,
     "start_time": "2025-03-05T00:42:26.358350",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def avg_embedding(inputs, model):\n",
    "    input=model(**inputs)\n",
    "    input_last_hidden_state=input.last_hidden_state\n",
    "    input_attention_mask = inputs['attention_mask']\n",
    "    input_masked_embeddings = input_last_hidden_state * input_attention_mask.unsqueeze(-1)\n",
    "    input_sum_embeddings = torch.sum(input_masked_embeddings, dim=1)\n",
    "    input_token_counts = torch.sum(input_attention_mask, dim=1).unsqueeze(-1)\n",
    "    input_avg_embeddings = input_sum_embeddings / input_token_counts\n",
    "    return(input_avg_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "22570a1b-93bf-41ef-99fe-de41c3857b41",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T00:42:26.377240Z",
     "iopub.status.busy": "2025-03-05T00:42:26.376919Z",
     "iopub.status.idle": "2025-03-05T00:42:26.390155Z",
     "shell.execute_reply": "2025-03-05T00:42:26.389746Z"
    },
    "papermill": {
     "duration": 0.018744,
     "end_time": "2025-03-05T00:42:26.390889",
     "exception": false,
     "start_time": "2025-03-05T00:42:26.372145",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_mrr_average(model, data_loader_val, distance_fn):\n",
    "    model.eval()  \n",
    "\n",
    "    total_rr = 0.0\n",
    "    num_queries = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader_val:\n",
    "            anchor_text = batch[0]\n",
    "            positive_text = batch[1]\n",
    "            negative_texts = batch[2]\n",
    "\n",
    "            anchor_input = tokenizer(anchor_text, return_tensors='pt', padding=True, truncation=True, max_length=512).to(device)\n",
    "            positive_input = tokenizer(positive_text, return_tensors='pt', padding=True, truncation=True, max_length=512).to(device)\n",
    "\n",
    "            anchor_embedding = avg_embedding(anchor_input, model)\n",
    "            positive_embedding = avg_embedding(positive_input, model)\n",
    "            negative_embedding = [avg_embedding(tokenizer(neg, return_tensors='pt', padding=True, truncation=True, max_length=512).to(device), model) for neg in negative_texts]\n",
    "\n",
    "            pos_dist = distance_fn(anchor_embedding, positive_embedding)\n",
    "            neg_dist = torch.stack([distance_fn(anchor_embedding, neg) for neg in negative_embedding], dim=-1)\n",
    "            all_similarities=torch.cat([-pos_dist.unsqueeze(1), -neg_dist], dim=1)\n",
    "            \n",
    "            sorted_similarities, sorted_indices = torch.sort(all_similarities, dim=1, descending=True)\n",
    "\n",
    "            # Find the rank of the first relevant (positive) document\n",
    "            positive_rank = (sorted_indices == 0).nonzero(as_tuple=True)[1] + 1  # +1 to make rank 1-based\n",
    "            total_rr += torch.sum(1.0 / positive_rank.float()).item()  # Reciprocal rank\n",
    "            num_queries += len(positive_rank)\n",
    "\n",
    "    mrr = total_rr / num_queries\n",
    "    return mrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "82977667-a984-467e-9eb6-9d6520ecb3b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T00:42:26.400793Z",
     "iopub.status.busy": "2025-03-05T00:42:26.400421Z",
     "iopub.status.idle": "2025-03-05T00:42:48.983935Z",
     "shell.execute_reply": "2025-03-05T00:42:48.983221Z"
    },
    "papermill": {
     "duration": 22.589165,
     "end_time": "2025-03-05T00:42:48.984763",
     "exception": false,
     "start_time": "2025-03-05T00:42:26.395598",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5387088568122299\n"
     ]
    }
   ],
   "source": [
    "mrr_validation_average = evaluate_mrr_average(lora_model_average, data_loader, cosine_distance)\n",
    "print(mrr_validation_average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966c23c7-dc92-49e8-bb1f-1520c0ccd13b",
   "metadata": {
    "papermill": {
     "duration": 0.005008,
     "end_time": "2025-03-05T00:42:49.001377",
     "exception": false,
     "start_time": "2025-03-05T00:42:48.996369",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "af58281c-1786-4bda-9eec-0fa0f127d140",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T00:42:49.012014Z",
     "iopub.status.busy": "2025-03-05T00:42:49.011337Z",
     "iopub.status.idle": "2025-03-05T00:42:49.353867Z",
     "shell.execute_reply": "2025-03-05T00:42:49.353202Z"
    },
    "papermill": {
     "duration": 0.34868,
     "end_time": "2025-03-05T00:42:49.354880",
     "exception": false,
     "start_time": "2025-03-05T00:42:49.006200",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1164340/2502257612.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  lora_model_hyperbolic = torch.load(file_path_hyperbolic)\n"
     ]
    }
   ],
   "source": [
    "file_path_hyperbolic=\"/dss/dsshome1/07/ra65bex2/srawat/contrastive_learning/v1.1/0.1hyperbolic/hyperbolic_lora_checkpoint_epoch_3.pth\"\n",
    "lora_model_hyperbolic = torch.load(file_path_hyperbolic)\n",
    "lora_model_hyperbolic = lora_model_hyperbolic.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d6f9507b-01e9-49d0-8327-760677bfcf0b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T00:42:49.365720Z",
     "iopub.status.busy": "2025-03-05T00:42:49.365578Z",
     "iopub.status.idle": "2025-03-05T00:42:49.370627Z",
     "shell.execute_reply": "2025-03-05T00:42:49.369503Z"
    },
    "papermill": {
     "duration": 0.011074,
     "end_time": "2025-03-05T00:42:49.371293",
     "exception": false,
     "start_time": "2025-03-05T00:42:49.360219",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def lorentzian_distance(x, y):\n",
    "    \n",
    "    dot_product = torch.sum(x * y, dim=-1)\n",
    "    norm_x = torch.norm(x, dim=-1)\n",
    "    norm_y = torch.norm(y, dim=-1)\n",
    "    \n",
    "    distance = torch.acosh(-dot_product + torch.sqrt((1 + norm_x**2) * (1 + norm_y**2)))\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "de4ecc53-8b64-4fee-bfbf-d3b85d441d1f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T00:42:49.380909Z",
     "iopub.status.busy": "2025-03-05T00:42:49.380775Z",
     "iopub.status.idle": "2025-03-05T00:42:49.409691Z",
     "shell.execute_reply": "2025-03-05T00:42:49.408948Z"
    },
    "papermill": {
     "duration": 0.034974,
     "end_time": "2025-03-05T00:42:49.410900",
     "exception": false,
     "start_time": "2025-03-05T00:42:49.375926",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def expm_o(v, c=1.0):\n",
    "    c = torch.tensor(c)\n",
    "    vspace = v\n",
    "    vnorm = torch.norm(v, p=2, dim=-1, keepdim=True)\n",
    "    xspace = torch.sinh(torch.sqrt(c) * vnorm) * vspace / (torch.sqrt(c) * vnorm)\n",
    "    batch_min = xspace.min(dim=1, keepdim=True).values\n",
    "    batch_max = xspace.max(dim=1, keepdim=True).values\n",
    "    xspace_scaled=(xspace - batch_min) / (batch_max - batch_min)\n",
    "    return xspace_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c6639968-6b1d-4601-a69f-6e83b9863ab6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T00:42:49.421444Z",
     "iopub.status.busy": "2025-03-05T00:42:49.421045Z",
     "iopub.status.idle": "2025-03-05T00:42:49.429500Z",
     "shell.execute_reply": "2025-03-05T00:42:49.429100Z"
    },
    "papermill": {
     "duration": 0.014643,
     "end_time": "2025-03-05T00:42:49.430497",
     "exception": false,
     "start_time": "2025-03-05T00:42:49.415854",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_mrr_hyperbolic(model1, data_loader_val, distance_fn):\n",
    "    model1.eval()\n",
    "    \n",
    "    total_rr = 0.0\n",
    "    num_queries = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader_val:\n",
    "            anchor_text = batch[0]\n",
    "            positive_text = batch[1]\n",
    "            negative_texts = batch[2]\n",
    "\n",
    "            anchor_input = tokenizer(anchor_text, return_tensors='pt', padding=True, truncation=True, max_length=512).to(device)\n",
    "            positive_input = tokenizer(positive_text, return_tensors='pt', padding=True, truncation=True, max_length=512).to(device)\n",
    "\n",
    "            anchor_embedding = expm_o(model1(**anchor_input).last_hidden_state[:, 0, :])\n",
    "            positive_embedding = expm_o(model1(**positive_input).last_hidden_state[:, 0, :])\n",
    "            negative_embedding = [expm_o(model1(**tokenizer(neg, return_tensors='pt', padding=True, truncation=True, max_length=512).to(device)).last_hidden_state[:, 0, :]) for neg in negative_texts]\n",
    "\n",
    "            pos_dist = distance_fn(anchor_embedding, positive_embedding)\n",
    "            neg_dist = torch.stack([distance_fn(anchor_embedding, neg) for neg in negative_embedding], dim=-1)\n",
    "            all_similarities=torch.cat([-pos_dist.unsqueeze(1), -neg_dist], dim=1)\n",
    "\n",
    "            sorted_similarities, sorted_indices = torch.sort(all_similarities, dim=1, descending=True)\n",
    "\n",
    "            # Find the rank of the first relevant (positive) document\n",
    "            positive_rank = (sorted_indices == 0).nonzero(as_tuple=True)[1] + 1  # +1 to make rank 1-based\n",
    "            total_rr += torch.sum(1.0 / positive_rank.float()).item()  # Reciprocal rank\n",
    "            num_queries += len(positive_rank)\n",
    "            \n",
    "    mrr = total_rr / num_queries\n",
    "    return mrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9c54c77e-2dde-4c88-9eaf-439a409e845e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T00:42:49.440745Z",
     "iopub.status.busy": "2025-03-05T00:42:49.440305Z",
     "iopub.status.idle": "2025-03-05T00:43:11.965201Z",
     "shell.execute_reply": "2025-03-05T00:43:11.964521Z"
    },
    "papermill": {
     "duration": 22.530895,
     "end_time": "2025-03-05T00:43:11.966063",
     "exception": false,
     "start_time": "2025-03-05T00:42:49.435168",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4628858146844087\n"
     ]
    }
   ],
   "source": [
    "mrr_validation_hyperbolic = evaluate_mrr_hyperbolic(model1=lora_model_hyperbolic, data_loader_val=data_loader,distance_fn=lorentzian_distance)\n",
    "print(mrr_validation_hyperbolic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e097240-0b21-4a85-8959-2c74522b15a8",
   "metadata": {
    "papermill": {
     "duration": 0.006353,
     "end_time": "2025-03-05T00:43:11.984953",
     "exception": false,
     "start_time": "2025-03-05T00:43:11.978600",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d883371b-b6e4-40de-b212-93ed5fcb6061",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T00:43:11.997654Z",
     "iopub.status.busy": "2025-03-05T00:43:11.997353Z",
     "iopub.status.idle": "2025-03-05T00:43:12.004214Z",
     "shell.execute_reply": "2025-03-05T00:43:12.003815Z"
    },
    "papermill": {
     "duration": 0.014372,
     "end_time": "2025-03-05T00:43:12.005269",
     "exception": false,
     "start_time": "2025-03-05T00:43:11.990897",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median Query Length: 10.0\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "print(\"Median Query Length:\", statistics.median(query_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4b02b505-a8f9-480d-959e-effcbc2ed3a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T00:43:12.017812Z",
     "iopub.status.busy": "2025-03-05T00:43:12.017679Z",
     "iopub.status.idle": "2025-03-05T00:43:12.054229Z",
     "shell.execute_reply": "2025-03-05T00:43:12.053850Z"
    },
    "papermill": {
     "duration": 0.044227,
     "end_time": "2025-03-05T00:43:12.055472",
     "exception": false,
     "start_time": "2025-03-05T00:43:12.011245",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5297325231410839"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mrr_validation_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5c10dccb-fbc7-448b-b3d9-4d7e045dafd3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T00:43:12.066887Z",
     "iopub.status.busy": "2025-03-05T00:43:12.066760Z",
     "iopub.status.idle": "2025-03-05T00:43:12.077468Z",
     "shell.execute_reply": "2025-03-05T00:43:12.077122Z"
    },
    "papermill": {
     "duration": 0.017226,
     "end_time": "2025-03-05T00:43:12.078492",
     "exception": false,
     "start_time": "2025-03-05T00:43:12.061266",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5387088568122299"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mrr_validation_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b9c22c87-c20f-4a86-a8d3-d941340ea726",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T00:43:12.089923Z",
     "iopub.status.busy": "2025-03-05T00:43:12.089795Z",
     "iopub.status.idle": "2025-03-05T00:43:12.101850Z",
     "shell.execute_reply": "2025-03-05T00:43:12.101503Z"
    },
    "papermill": {
     "duration": 0.01868,
     "end_time": "2025-03-05T00:43:12.102495",
     "exception": false,
     "start_time": "2025-03-05T00:43:12.083815",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4628858146844087"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mrr_validation_hyperbolic"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 89.621523,
   "end_time": "2025-03-05T00:43:14.761017",
   "environment_variables": {},
   "exception": null,
   "input_path": "FiQA.ipynb",
   "output_path": "FiQA_output.ipynb",
   "parameters": {},
   "start_time": "2025-03-05T00:41:45.139494",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "14646cfcddf44917a1f7896deee44f41": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_2ac6cc4e435740e79c2942f792bd16e9",
       "placeholder": "​",
       "style": "IPY_MODEL_18801cf0598f417f8d47df31b7a582e2",
       "tabbable": null,
       "tooltip": null,
       "value": " 57638/57638 [00:00&lt;00:00, 171841.28it/s]"
      }
     },
     "154534f5515749f29a878e4e3886ebbd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_9490e8ee7d4f4a25ad15ffb33d094491",
       "max": 57638.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_4fb1f29e50214b38ac5eb0ff8405d964",
       "tabbable": null,
       "tooltip": null,
       "value": 57638.0
      }
     },
     "18801cf0598f417f8d47df31b7a582e2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "2ac6cc4e435740e79c2942f792bd16e9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "33613537cd30412baec6144e1bea6047": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "4fb1f29e50214b38ac5eb0ff8405d964": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "9490e8ee7d4f4a25ad15ffb33d094491": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9a4b5511061d41dbb0eeb3b6d0efe795": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "adc95d6f502a40d29eedc715f7165914": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c952ea4c23684a0696a99c980dc737fd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_adc95d6f502a40d29eedc715f7165914",
       "placeholder": "​",
       "style": "IPY_MODEL_33613537cd30412baec6144e1bea6047",
       "tabbable": null,
       "tooltip": null,
       "value": "100%"
      }
     },
     "d48d79afba7247569ae5c17956bab16b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_c952ea4c23684a0696a99c980dc737fd",
        "IPY_MODEL_154534f5515749f29a878e4e3886ebbd",
        "IPY_MODEL_14646cfcddf44917a1f7896deee44f41"
       ],
       "layout": "IPY_MODEL_9a4b5511061d41dbb0eeb3b6d0efe795",
       "tabbable": null,
       "tooltip": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}