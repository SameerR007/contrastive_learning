{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6d4b65f-fa6b-4517-8694-8627bc49833b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T00:57:47.943638Z",
     "iopub.status.busy": "2025-03-05T00:57:47.943399Z",
     "iopub.status.idle": "2025-03-05T00:57:48.027841Z",
     "shell.execute_reply": "2025-03-05T00:57:48.027406Z"
    },
    "papermill": {
     "duration": 0.092886,
     "end_time": "2025-03-05T00:57:48.028540",
     "exception": false,
     "start_time": "2025-03-05T00:57:47.935654",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dss/dsshome1/07/ra65bex2/srawat/myenv/lib/python3.12/site-packages/beir/datasets/data_loader.py:8: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "from beir.datasets.data_loader import GenericDataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a91d6914-e301-422c-b839-1fafeb1e8fa4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T00:57:48.036292Z",
     "iopub.status.busy": "2025-03-05T00:57:48.036148Z",
     "iopub.status.idle": "2025-03-05T00:57:48.038455Z",
     "shell.execute_reply": "2025-03-05T00:57:48.038087Z"
    },
    "papermill": {
     "duration": 0.006862,
     "end_time": "2025-03-05T00:57:48.039242",
     "exception": false,
     "start_time": "2025-03-05T00:57:48.032380",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_path = '/dss/dsshome1/07/ra65bex2/srawat/scidocs/scidocs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41e17333-2c34-4b7b-91f6-3cbd3972f0d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T00:57:48.047592Z",
     "iopub.status.busy": "2025-03-05T00:57:48.047215Z",
     "iopub.status.idle": "2025-03-05T00:57:49.102459Z",
     "shell.execute_reply": "2025-03-05T00:57:49.101913Z"
    },
    "papermill": {
     "duration": 1.060809,
     "end_time": "2025-03-05T00:57:49.103597",
     "exception": false,
     "start_time": "2025-03-05T00:57:48.042788",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b605ead828a464eaae0e0e9c2ae6d90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25657 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "corpus, queries, qrels = GenericDataLoader(data_path).load(split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d653c60-435a-4e10-8506-6ef5d01f8675",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T00:57:49.112703Z",
     "iopub.status.busy": "2025-03-05T00:57:49.112340Z",
     "iopub.status.idle": "2025-03-05T00:57:51.321796Z",
     "shell.execute_reply": "2025-03-05T00:57:51.321295Z"
    },
    "papermill": {
     "duration": 2.214459,
     "end_time": "2025-03-05T00:57:51.322566",
     "exception": false,
     "start_time": "2025-03-05T00:57:49.108107",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /dss/dsshome1/07/ra65bex2/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /dss/dsshome1/07/ra65bex2/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "def clean_text(text):\n",
    "    return re.sub(r'[^\\w\\s.!?]', '', text)\n",
    "def select_words(text, percentage):\n",
    "    words = [w for w in text.split() if w.lower() not in stop_words]\n",
    "    return random.sample(words, min(int(percentage*len(words)), len(words)))\n",
    "def introduce_typo(word):\n",
    "    if len(word) > 1:\n",
    "        idx = random.randint(0, len(word) - 1)\n",
    "        return word[:idx] + random.choice('abcdefghijklmnopqrstuvwxyz') + word[idx+1:]\n",
    "    return word\n",
    "def introduce_noise(word):\n",
    "    noise_chars = ['@', '#', '$', '%', '&', '*']\n",
    "    if len(word) > 1:\n",
    "        idx = random.randint(0, len(word) - 1)\n",
    "        return word[:idx] + random.choice(noise_chars) + word[idx+1:]\n",
    "    return word\n",
    "def replace_with_synonym(word):\n",
    "    synonyms = [syn.lemmas()[0].name() for syn in wordnet.synsets(word) if syn.lemmas()]\n",
    "    return random.choice(synonyms) if synonyms else word\n",
    "def corrupt_word(word, method):\n",
    "    if method == 'typo':\n",
    "        return introduce_typo(word)\n",
    "    elif method == 'noise':\n",
    "        return introduce_noise(word)\n",
    "    elif method == 'synonym':\n",
    "        return replace_with_synonym(word)\n",
    "    return word\n",
    "def corrupt_text(text):\n",
    "    corrupted_words = []  \n",
    "    words_to_corrupt=select_words(clean_text(text), percentage=0.5)\n",
    "    for word in clean_text(text).split():\n",
    "        if word in words_to_corrupt:\n",
    "            corruption_method = random.choice(['typo', 'noise', 'synonym'])\n",
    "            corrupted_words.append(corrupt_word(word, corruption_method))\n",
    "        else:\n",
    "            corrupted_words.append(word)\n",
    "    return ' '.join(corrupted_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a29044d5-3952-4f3d-aa43-e1efd34fcad3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T00:57:51.331395Z",
     "iopub.status.busy": "2025-03-05T00:57:51.331126Z",
     "iopub.status.idle": "2025-03-05T00:57:56.142322Z",
     "shell.execute_reply": "2025-03-05T00:57:56.141660Z"
    },
    "papermill": {
     "duration": 4.816484,
     "end_time": "2025-03-05T00:57:56.143340",
     "exception": false,
     "start_time": "2025-03-05T00:57:51.326856",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "contrastive_pairs=[]\n",
    "query_lengths = []\n",
    "import random\n",
    "c=0\n",
    "for query_id, relevant_docs in qrels.items():\n",
    "    try:\n",
    "        query_text = queries[query_id]\n",
    "        query_lengths.append(len(query_text.split()))\n",
    "        for doc_id in relevant_docs:\n",
    "            positive = corpus[doc_id][\"text\"]\n",
    "        #print(relevant_docs)\n",
    "        positive_doc_ids = set(relevant_docs)\n",
    "        all_doc_ids = set(corpus.keys())\n",
    "        negative_doc_ids = all_doc_ids - positive_doc_ids\n",
    "        negative_doc_ids=list(negative_doc_ids)\n",
    "        negative_doc_samples = random.sample(negative_doc_ids, k=5)\n",
    "        negatives=[]\n",
    "        for neg_doc_id in negative_doc_samples:\n",
    "            negative_doc_text = corpus[neg_doc_id][\"text\"]\n",
    "            negatives.append(negative_doc_text)\n",
    "        contrastive_pairs.append({\n",
    "            \"anchor\": corrupt_text(query_text),\n",
    "            \"positive\": positive,\n",
    "            \"negatives\": negatives\n",
    "        })\n",
    "    except:\n",
    "        c=c+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49721946-fff3-4690-bd92-d981cecdf62b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T00:57:56.152402Z",
     "iopub.status.busy": "2025-03-05T00:57:56.152211Z",
     "iopub.status.idle": "2025-03-05T00:57:56.156089Z",
     "shell.execute_reply": "2025-03-05T00:57:56.155712Z"
    },
    "papermill": {
     "duration": 0.009278,
     "end_time": "2025-03-05T00:57:56.156760",
     "exception": false,
     "start_time": "2025-03-05T00:57:56.147482",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de8ef367-dcb4-4bb6-af3a-20f190930ed1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T00:57:56.164495Z",
     "iopub.status.busy": "2025-03-05T00:57:56.164301Z",
     "iopub.status.idle": "2025-03-05T00:57:56.173793Z",
     "shell.execute_reply": "2025-03-05T00:57:56.173422Z"
    },
    "papermill": {
     "duration": 0.014186,
     "end_time": "2025-03-05T00:57:56.174534",
     "exception": false,
     "start_time": "2025-03-05T00:57:56.160348",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(contrastive_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a2ccada-419a-4f79-ad4d-b605780281a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T00:57:56.182753Z",
     "iopub.status.busy": "2025-03-05T00:57:56.182395Z",
     "iopub.status.idle": "2025-03-05T00:57:56.190875Z",
     "shell.execute_reply": "2025-03-05T00:57:56.190354Z"
    },
    "papermill": {
     "duration": 0.013196,
     "end_time": "2025-03-05T00:57:56.191522",
     "exception": false,
     "start_time": "2025-03-05T00:57:56.178326",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'anchor': 'A Direct Saarch Me$hod to solve Economic murder Problem with ValvePoint consequence',\n",
       "  'positive': 'Many applications in speech, robotics, finance, and biology deal with sequential data, where ordering matters and recurrent structures are common. However, this structure cannot be easily captured by standard kernel functions. To model such structure, we propose expressive closed-form kernel functions for Gaussian processes. The resulting model, GP-LSTM, fully encapsulates the inductive biases of long short-term memory (LSTM) recurrent networks, while retaining the non-parametric probabilistic advantages of Gaussian processes. We learn the properties of the proposed kernels by optimizing the Gaussian process marginal likelihood using a new provably convergent semi-stochastic gradient procedure, and exploit the structure of these kernels for scalable training and prediction. This approach provides a practical representation for Bayesian LSTMs. We demonstrate state-of-the-art performance on several benchmarks, and thoroughly investigate a consequential autonomous driving application, where the predictive uncertainties provided by GP-LSTM are uniquely valuable.',\n",
       "  'negatives': ['Abstract. Recent years have seen the development of many graph clustering algorithms, which can identify community structure in networks. The vast majority of these only find disjoint communities, but in many real-world networks communities overlap to some extent. We present a new algorithm for discovering overlapping communities in networks, by extending Girvan and Newman’s well-known algorithm based on the betweenness centrality measure. Like the original algorithm, ours performs hierarchical clustering — partitioning a network into any desired number of clusters — but allows them to overlap. Experiments confirm good performance on randomly generated networks based on a known overlapping community structure, and interesting results have also been obtained on a range of real-world networks.',\n",
       "   'The Deep Stacking Network (DSN) is a special type of deep architecture developed to enable and benefit from parallel learning of its model parameters on large CPU clusters. As a prospective key component of future speech recognizers, the architectural design of the DSN and its parallel training endow the DSN with scalability over a vast amount of training data. In this paper, we present our first parallel implementation of the DSN training algorithm. Particularly, we show the tradeoff between the time/memory saving via training parallelism and the associated cost arising from inter-CPU communication. Further, in phone classification experiments, we demonstrate a significantly lowered error rate using parallel full-batch training distributed over a CPU cluster, compared with sequential minibatch training implemented in a single CPU machine under otherwise identical experimental conditions and as exploited prior to the work reported in this paper.',\n",
       "   'Kearns, Neel, Roth, and Wu [ICML 2018] recently proposed a notion of rich subgroup fairness intended to bridge the gap between statistical and individual notions of fairness. Rich subgroup fairness picks a statistical fairness constraint (say, equalizing false positive rates across protected groups), but then asks that this constraint hold over an exponentially or infinitely large collection of subgroups defined by a class of functions with bounded VC dimension. They give an algorithm guaranteed to learn subject to this constraint, under the condition that it has access to oracles for perfectly learning absent a fairness constraint. In this paper, we undertake an extensive empirical evaluation of the algorithm of Kearns et al. On four real datasets for which fairness is a concern, we investigate the basic convergence of the algorithm when instantiated with fast heuristics in place of learning oracles, measure the tradeoffs between fairness and accuracy, and compare this approach with the recent algorithm of Agarwal, Beygelzeimer, Dudik, Langford, and Wallach [ICML 2018], which implements weaker and more traditional marginal fairness constraints defined by individual protected attributes. We find that in general, the Kearns et al. algorithm converges quickly, large gains in fairness can be obtained with mild costs to accuracy, and that optimizing accuracy subject only to marginal fairness leads to classifiers with substantial subgroup unfairness. We also provide a number of analyses and visualizations of the dynamics and behavior of the Kearns et al. algorithm. Overall we find this algorithm to be effective on real data, and rich subgroup fairness to be a viable notion in practice.',\n",
       "   'In this paper, we present a new Integer Program (IP) for the Air Traffic Flow Management (ATFM) problem. The model we propose provides a complete representation of all the phases of each flights, i.e., the phase of taking-off, of cruising and of landing; suggesting all the actions to be implemented to achieve the goal of safe, efficient, and expeditious aircraft movement. The distinctive feature of the model is that it allows rerouting decisions. These decisions are formulated by means of “local” conditions, which allow us to represent such decisions in a very compact way by only introducing new constraints. Moreover, to strengthen the polyhedral structure of the underlying relaxation, we also present three classes of valid inequalities. We report short computational times (less than 15 minutes) on instances of the size of the US air traffic control system that make it realistic that our approach can be used as the main engine of managing air traffic in the US.',\n",
       "   'Recurrent Neural Networks (RNNs) and their variants, such as Long-Short Term Memory (LSTM) networks, and Gated Recurrent Unit (GRU) networks, have achieved promising performance in sequential data modeling. The hidden layers in RNNs can be regarded as the memory units, which are helpful in storing information in sequential contexts. However, when dealing with high dimensional input data, such as video and text, the input-to-hidden linear transformation in RNNs brings high memory usage and huge computational cost. This makes the training of RNNs very difficult. To address this challenge, we propose a novel compact LSTM model, named as TR-LSTM, by utilizing the low-rank tensor ring decomposition (TRD) to reformulate the input-to-hidden transformation. Compared with other tensor decomposition methods, TRLSTM is more stable. In addition, TR-LSTM can complete an end-to-end training and also provide a fundamental building block for RNNs in handling large input data. Experiments on real-world action recognition datasets have demonstrated the promising performance of the proposed TR-LSTM compared with the tensortrain LSTM and other state-of-the-art competitors.']},\n",
       " {'anchor': 'BearqshBullish Sentiment A#alysis on Financial Microblogs',\n",
       "  'positive': 'In this paper, we will consider the approximation properties of a recently introduced neural network model called graph neural network (GNN), which can be used to process-structured data inputs, e.g., acyclic graphs, cyclic graphs, and directed or undirected graphs. This class of neural networks implements a function tau(G, n) isin R m that maps a graph G and one of its nodes n onto an m-dimensional Euclidean space. We characterize the functions that can be approximated by GNNs, in probability, up to any prescribed degree of precision. This set contains the maps that satisfy a property called preservation of the unfolding equivalence, and includes most of the practically useful functions on graphs; the only known exception is when the input graph contains particular patterns of symmetries when unfolding equivalence may not be preserved. The result can be considered an extension of the universal approximation property established for the classic feedforward neural networks (FNNs). Some experimental examples are used to show the computational capabilities of the proposed model.',\n",
       "  'negatives': ['We present a simple method for rendering Islamic star patterns based on Hankin’s “polygons-in-contact” technique. The method builds star patterns from a tiling of the plane and a small number of intuitive parameters. We show how this method can be adapted to construct Islamic designs reminiscent of Huff’s parquet deformations. Finally, we introduce a geometric transformation on tilings that expands the range of patterns accessible using our method. This transformation simplifies construction techniques given in previous work, and clarifies previously unexplained relationships between certain classes of star patterns.',\n",
       "   'This paper reviews the use of similarity searching in chemical databases. It begins by introducing the concept of similarity searching, differentiating it from the more common substructure searching, and then discusses the current generation of fragment-based measures that are used for searching chemical structure databases. The next sections focus upon two of the principal characteristics of a similarity measure: the coefficient that is used to quantify the degree of structural resemblance between pairs of molecules and the structural representations that are used to characterize molecules that are being compared in a similarity calculation. New types of similarity measure are then compared with current approaches, and examples are given of several applications that are related to similarity searching.',\n",
       "   'Most routing algorithms for sensor networks focus on finding energy efficient paths to prolong the lifetime of sensor networks. As a result, the power of sensors on efficient paths depletes quickly, and consequently sensor networks become incapable of monitoring events from some parts of their target areas. In many sensor network applications, the events that must be tracked occur at random locations and have non-deterministic generation patterns. Therefore, ideally, routing algorithms should consider not only energy efficiency, but also the amount of energy remaining in each sensor, thus avoiding non-functioning sensors due to early power depletion. This paper introduces a new metric, energy cost, devised to consider a balance of sensors’ remaining energies, as well as energy efficiency. This metric gives rise to the design of the distributed energy balanced routing (DEBR) algorithm devised to balance the data traffic of sensor networks in a decentralized manner and consequently prolong the lifetime of the networks. DEBR is scalable in the number of sensors and also robust to the variations in the dynamics of event generation. We demonstrate the effectiveness of the proposed algorithm by comparing three existing routing algorithms: direct communication approach, minimum transmission energy, and self-organized routing and find that energy balance should be considered to extend lifetime of sensor network and increase robustness of sensor network for diverse event generation patterns. 2009 Elsevier Ltd. All rights reserved.',\n",
       "   'The problem we are addressing in Alvey Project MMI149 is that of using computer vision to understand the unconstrained 3D world, in which the viewed scenes will in general contain too wide a diversity of objects for topdown recognition techniques to work. For example, we desire to obtain an understanding of natural scenes, containing roads, buildings, trees, bushes, etc., as typified by the two frames from a sequence illustrated in Figure 1. The solution to this problem that we are pursuing is to use a computer vision system based upon motion analysis of a monocular image sequence from a mobile camera. By extraction and tracking of image features, representations of the 3D analogues of these features can be constructed.',\n",
       "   \"In terms of public health, childhood vaccination programs have benefits that far outweigh risks. However, some parents decide not to vaccinate their children. This paper explores the ways in which such parents talked about the perceived risks and benefits incurred by vaccinating (or not vaccinating) their children. Between 2013-2016 we undertook 29 in-depth interviews with non-vaccinating and/or 'vaccine hesitant' parents in Australia. Interviews were conducted in an open and non-judgmental manner, akin to empathic neutrality. Interviews focused on parents talking about the factors that shaped their decisions not to (or partially) vaccinate their children. All interviews were transcribed and analysed using both inductive and deductive processes. The main themes focus on parental perceptions of: 1. their capacity to reason; 2. their rejection of Western medical epistemology; and 3. their participation in labour intensive parenting practices (which we term salutogenic parenting). Parents engaged in an ongoing search for information about how best to parent their children (capacity to reason), which for many led to questioning/distrust of traditional scientific knowledge (rejection of Western medical epistemology). Salutogenic parenting spontaneously arose in interviews, whereby parents practised health promoting activities which they saw as boosting the natural immunity of their children and protecting them from illness (reducing or negating the perceived need for vaccinations). Salutogenic parenting practices included breastfeeding, eating organic and/or home-grown food, cooking from scratch to reduce preservative consumption and reducing exposure to toxins. We interpret our data as a 'logic of care', which is seen by parents as internally consistent, logically inter-related and inter-dependent. Whilst not necessarily sharing the parents' reasoning, we argue that an understanding of their attitudes towards health and well-being is imperative for any efforts to engage with their vaccine refusal at a policy level.\"]}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contrastive_pairs[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ade92f9-e3df-4d0a-b849-b1a721e18cf6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T00:57:56.199822Z",
     "iopub.status.busy": "2025-03-05T00:57:56.199688Z",
     "iopub.status.idle": "2025-03-05T00:57:56.206814Z",
     "shell.execute_reply": "2025-03-05T00:57:56.206505Z"
    },
    "papermill": {
     "duration": 0.011986,
     "end_time": "2025-03-05T00:57:56.207473",
     "exception": false,
     "start_time": "2025-03-05T00:57:56.195487",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(qrels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b97f7b4-f007-41f6-bfbb-1b9b01665e9d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T00:57:56.216061Z",
     "iopub.status.busy": "2025-03-05T00:57:56.215686Z",
     "iopub.status.idle": "2025-03-05T00:57:59.453643Z",
     "shell.execute_reply": "2025-03-05T00:57:59.453092Z"
    },
    "papermill": {
     "duration": 3.243545,
     "end_time": "2025-03-05T00:57:59.454986",
     "exception": false,
     "start_time": "2025-03-05T00:57:56.211441",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a415b29a-a543-4679-8f78-44f715b3067d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T00:57:59.471473Z",
     "iopub.status.busy": "2025-03-05T00:57:59.470961Z",
     "iopub.status.idle": "2025-03-05T00:57:59.474453Z",
     "shell.execute_reply": "2025-03-05T00:57:59.474042Z"
    },
    "papermill": {
     "duration": 0.009034,
     "end_time": "2025-03-05T00:57:59.475107",
     "exception": false,
     "start_time": "2025-03-05T00:57:59.466073",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ContrastiveDataset:\n",
    "    def __init__(self, pairs):\n",
    "        self.pairs = pairs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.pairs[idx]\n",
    "        return item[\"anchor\"], item[\"positive\"], item[\"negatives\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a39efeab-fd20-411a-80c5-315f362e00d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T00:57:59.484118Z",
     "iopub.status.busy": "2025-03-05T00:57:59.483831Z",
     "iopub.status.idle": "2025-03-05T00:57:59.493085Z",
     "shell.execute_reply": "2025-03-05T00:57:59.492698Z"
    },
    "papermill": {
     "duration": 0.014512,
     "end_time": "2025-03-05T00:57:59.493797",
     "exception": false,
     "start_time": "2025-03-05T00:57:59.479285",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "contrastive_dataset = ContrastiveDataset(contrastive_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d103bbfa-895a-4020-a7e5-21de659f27dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T00:57:59.503288Z",
     "iopub.status.busy": "2025-03-05T00:57:59.502718Z",
     "iopub.status.idle": "2025-03-05T00:57:59.509868Z",
     "shell.execute_reply": "2025-03-05T00:57:59.509458Z"
    },
    "papermill": {
     "duration": 0.012691,
     "end_time": "2025-03-05T00:57:59.510800",
     "exception": false,
     "start_time": "2025-03-05T00:57:59.498109",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_loader = DataLoader(contrastive_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8b0277f-f526-4087-82da-c4cdd65d32da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T00:57:59.520200Z",
     "iopub.status.busy": "2025-03-05T00:57:59.519774Z",
     "iopub.status.idle": "2025-03-05T00:57:59.527837Z",
     "shell.execute_reply": "2025-03-05T00:57:59.527469Z"
    },
    "papermill": {
     "duration": 0.013445,
     "end_time": "2025-03-05T00:57:59.528498",
     "exception": false,
     "start_time": "2025-03-05T00:57:59.515053",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e15526a4-b3fe-435b-91c9-ad4064562f0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T00:57:59.537972Z",
     "iopub.status.busy": "2025-03-05T00:57:59.537423Z",
     "iopub.status.idle": "2025-03-05T00:58:03.258529Z",
     "shell.execute_reply": "2025-03-05T00:58:03.257740Z"
    },
    "papermill": {
     "duration": 3.726945,
     "end_time": "2025-03-05T00:58:03.259734",
     "exception": false,
     "start_time": "2025-03-05T00:57:59.532789",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1220736/261098231.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  lora_model_baseline = torch.load(file_path_baseline)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "file_path_baseline =\"/dss/dsshome1/07/ra65bex2/srawat/contrastive_learning/v1.1/app_baseline/checkpoint_epoch_3.pth\"\n",
    "lora_model_baseline = torch.load(file_path_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9999e628-5966-4dda-b5c5-c0d762fce27d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T00:58:03.272289Z",
     "iopub.status.busy": "2025-03-05T00:58:03.271705Z",
     "iopub.status.idle": "2025-03-05T00:58:03.277616Z",
     "shell.execute_reply": "2025-03-05T00:58:03.277293Z"
    },
    "papermill": {
     "duration": 0.011547,
     "end_time": "2025-03-05T00:58:03.278292",
     "exception": false,
     "start_time": "2025-03-05T00:58:03.266745",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "lora_model_baseline = lora_model_baseline.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7e6a3a61-8db0-43db-b575-6399f8515950",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T00:58:03.287610Z",
     "iopub.status.busy": "2025-03-05T00:58:03.287273Z",
     "iopub.status.idle": "2025-03-05T00:58:03.489674Z",
     "shell.execute_reply": "2025-03-05T00:58:03.489105Z"
    },
    "papermill": {
     "duration": 0.208,
     "end_time": "2025-03-05T00:58:03.490708",
     "exception": false,
     "start_time": "2025-03-05T00:58:03.282708",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "68ac4919-76f1-4349-a314-4b1061126655",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T00:58:03.502186Z",
     "iopub.status.busy": "2025-03-05T00:58:03.501039Z",
     "iopub.status.idle": "2025-03-05T00:58:03.504757Z",
     "shell.execute_reply": "2025-03-05T00:58:03.504359Z"
    },
    "papermill": {
     "duration": 0.010242,
     "end_time": "2025-03-05T00:58:03.505851",
     "exception": false,
     "start_time": "2025-03-05T00:58:03.495609",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cosine_distance(x, y):\n",
    "    return 1 - torch.nn.functional.cosine_similarity(x, y, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "990f63bd-4d48-4f58-a001-3b3250f65312",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T00:58:03.516738Z",
     "iopub.status.busy": "2025-03-05T00:58:03.516313Z",
     "iopub.status.idle": "2025-03-05T00:58:03.558440Z",
     "shell.execute_reply": "2025-03-05T00:58:03.557751Z"
    },
    "papermill": {
     "duration": 0.048119,
     "end_time": "2025-03-05T00:58:03.559359",
     "exception": false,
     "start_time": "2025-03-05T00:58:03.511240",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_mrr_baseline(model, data_loader_val, distance_fn):\n",
    "    model.eval()\n",
    "\n",
    "    total_rr = 0.0\n",
    "    num_queries = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader_val:\n",
    "            anchor_text = batch[0]\n",
    "            positive_text = batch[1]\n",
    "            negative_texts = batch[2]\n",
    "\n",
    "            anchor_input = tokenizer(anchor_text, return_tensors='pt', padding=True, truncation=True, max_length=512).to(device)\n",
    "            positive_input = tokenizer(positive_text, return_tensors='pt', padding=True, truncation=True, max_length=512).to(device)\n",
    "\n",
    "            anchor_embedding = model(**anchor_input).last_hidden_state[:, 0, :]\n",
    "            positive_embedding = model(**positive_input).last_hidden_state[:, 0, :]\n",
    "            negative_embedding = [model(**tokenizer(neg, return_tensors='pt', padding=True, truncation=True, max_length=512).to(device)).last_hidden_state[:, 0, :] for neg in negative_texts]\n",
    "\n",
    "            pos_dist = distance_fn(anchor_embedding, positive_embedding)\n",
    "            neg_dist = torch.stack([distance_fn(anchor_embedding, neg) for neg in negative_embedding], dim=-1)\n",
    "            all_similarities=torch.cat([-pos_dist.unsqueeze(1), -neg_dist], dim=1)\n",
    "\n",
    "            sorted_similarities, sorted_indices = torch.sort(all_similarities, dim=1, descending=True)\n",
    "\n",
    "            # Find the rank of the first relevant (positive) document\n",
    "            positive_rank = (sorted_indices == 0).nonzero(as_tuple=True)[1] + 1  # +1 to make rank 1-based\n",
    "            total_rr += torch.sum(1.0 / positive_rank.float()).item()  # Reciprocal rank\n",
    "            num_queries += len(positive_rank)\n",
    "\n",
    "    mrr = total_rr / num_queries\n",
    "    return mrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "534a9ec5-4211-4cb6-81f1-fb8a30caff92",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T00:58:03.569455Z",
     "iopub.status.busy": "2025-03-05T00:58:03.568889Z",
     "iopub.status.idle": "2025-03-05T00:58:36.780039Z",
     "shell.execute_reply": "2025-03-05T00:58:36.779089Z"
    },
    "papermill": {
     "duration": 33.224713,
     "end_time": "2025-03-05T00:58:36.788825",
     "exception": false,
     "start_time": "2025-03-05T00:58:03.564112",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3951666712760925\n"
     ]
    }
   ],
   "source": [
    "mrr_validation_baseline = evaluate_mrr_baseline(lora_model_baseline, data_loader, cosine_distance)\n",
    "print(mrr_validation_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61bbd65-41c9-4ac7-80ef-ba4a4fb02d45",
   "metadata": {
    "papermill": {
     "duration": 0.004513,
     "end_time": "2025-03-05T00:58:36.800536",
     "exception": false,
     "start_time": "2025-03-05T00:58:36.796023",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8a3dfd17-ee43-4c4e-9287-8ec6451bc062",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T00:58:36.810129Z",
     "iopub.status.busy": "2025-03-05T00:58:36.809913Z",
     "iopub.status.idle": "2025-03-05T00:58:37.177742Z",
     "shell.execute_reply": "2025-03-05T00:58:37.177156Z"
    },
    "papermill": {
     "duration": 0.374028,
     "end_time": "2025-03-05T00:58:37.178992",
     "exception": false,
     "start_time": "2025-03-05T00:58:36.804964",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1220736/2975798179.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  lora_model_average = torch.load(file_path_average)\n"
     ]
    }
   ],
   "source": [
    "file_path_average=\"/dss/dsshome1/07/ra65bex2/srawat/contrastive_learning/v1.1/app_average/average_checkpoint_epoch_3.pth\"\n",
    "lora_model_average = torch.load(file_path_average)\n",
    "lora_model_average = lora_model_average.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "49c10d3f-c53d-4222-aba4-0e763451baff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T00:58:37.189353Z",
     "iopub.status.busy": "2025-03-05T00:58:37.189172Z",
     "iopub.status.idle": "2025-03-05T00:58:37.192650Z",
     "shell.execute_reply": "2025-03-05T00:58:37.192284Z"
    },
    "papermill": {
     "duration": 0.009181,
     "end_time": "2025-03-05T00:58:37.193347",
     "exception": false,
     "start_time": "2025-03-05T00:58:37.184166",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def avg_embedding(inputs, model):\n",
    "    input=model(**inputs)\n",
    "    input_last_hidden_state=input.last_hidden_state\n",
    "    input_attention_mask = inputs['attention_mask']\n",
    "    input_masked_embeddings = input_last_hidden_state * input_attention_mask.unsqueeze(-1)\n",
    "    input_sum_embeddings = torch.sum(input_masked_embeddings, dim=1)\n",
    "    input_token_counts = torch.sum(input_attention_mask, dim=1).unsqueeze(-1)\n",
    "    input_avg_embeddings = input_sum_embeddings / input_token_counts\n",
    "    return(input_avg_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "22570a1b-93bf-41ef-99fe-de41c3857b41",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T00:58:37.203545Z",
     "iopub.status.busy": "2025-03-05T00:58:37.203301Z",
     "iopub.status.idle": "2025-03-05T00:58:37.212939Z",
     "shell.execute_reply": "2025-03-05T00:58:37.212534Z"
    },
    "papermill": {
     "duration": 0.015616,
     "end_time": "2025-03-05T00:58:37.213606",
     "exception": false,
     "start_time": "2025-03-05T00:58:37.197990",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_mrr_average(model, data_loader_val, distance_fn):\n",
    "    model.eval()  \n",
    "\n",
    "    total_rr = 0.0\n",
    "    num_queries = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader_val:\n",
    "            anchor_text = batch[0]\n",
    "            positive_text = batch[1]\n",
    "            negative_texts = batch[2]\n",
    "\n",
    "            anchor_input = tokenizer(anchor_text, return_tensors='pt', padding=True, truncation=True, max_length=512).to(device)\n",
    "            positive_input = tokenizer(positive_text, return_tensors='pt', padding=True, truncation=True, max_length=512).to(device)\n",
    "\n",
    "            anchor_embedding = avg_embedding(anchor_input, model)\n",
    "            positive_embedding = avg_embedding(positive_input, model)\n",
    "            negative_embedding = [avg_embedding(tokenizer(neg, return_tensors='pt', padding=True, truncation=True, max_length=512).to(device), model) for neg in negative_texts]\n",
    "\n",
    "            pos_dist = distance_fn(anchor_embedding, positive_embedding)\n",
    "            neg_dist = torch.stack([distance_fn(anchor_embedding, neg) for neg in negative_embedding], dim=-1)\n",
    "            all_similarities=torch.cat([-pos_dist.unsqueeze(1), -neg_dist], dim=1)\n",
    "            \n",
    "            sorted_similarities, sorted_indices = torch.sort(all_similarities, dim=1, descending=True)\n",
    "\n",
    "            # Find the rank of the first relevant (positive) document\n",
    "            positive_rank = (sorted_indices == 0).nonzero(as_tuple=True)[1] + 1  # +1 to make rank 1-based\n",
    "            total_rr += torch.sum(1.0 / positive_rank.float()).item()  # Reciprocal rank\n",
    "            num_queries += len(positive_rank)\n",
    "\n",
    "    mrr = total_rr / num_queries\n",
    "    return mrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "82977667-a984-467e-9eb6-9d6520ecb3b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T00:58:37.223764Z",
     "iopub.status.busy": "2025-03-05T00:58:37.223366Z",
     "iopub.status.idle": "2025-03-05T00:59:09.515849Z",
     "shell.execute_reply": "2025-03-05T00:59:09.514305Z"
    },
    "papermill": {
     "duration": 32.307399,
     "end_time": "2025-03-05T00:59:09.525867",
     "exception": false,
     "start_time": "2025-03-05T00:58:37.218468",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3895166733264923\n"
     ]
    }
   ],
   "source": [
    "mrr_validation_average = evaluate_mrr_average(lora_model_average, data_loader, cosine_distance)\n",
    "print(mrr_validation_average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966c23c7-dc92-49e8-bb1f-1520c0ccd13b",
   "metadata": {
    "papermill": {
     "duration": 0.005166,
     "end_time": "2025-03-05T00:59:09.539418",
     "exception": false,
     "start_time": "2025-03-05T00:59:09.534252",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "af58281c-1786-4bda-9eec-0fa0f127d140",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T00:59:09.552445Z",
     "iopub.status.busy": "2025-03-05T00:59:09.552232Z",
     "iopub.status.idle": "2025-03-05T00:59:09.987508Z",
     "shell.execute_reply": "2025-03-05T00:59:09.986364Z"
    },
    "papermill": {
     "duration": 0.443583,
     "end_time": "2025-03-05T00:59:09.988821",
     "exception": false,
     "start_time": "2025-03-05T00:59:09.545238",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1220736/2502257612.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  lora_model_hyperbolic = torch.load(file_path_hyperbolic)\n"
     ]
    }
   ],
   "source": [
    "file_path_hyperbolic=\"/dss/dsshome1/07/ra65bex2/srawat/contrastive_learning/v1.1/0.1hyperbolic/hyperbolic_lora_checkpoint_epoch_3.pth\"\n",
    "lora_model_hyperbolic = torch.load(file_path_hyperbolic)\n",
    "lora_model_hyperbolic = lora_model_hyperbolic.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d6f9507b-01e9-49d0-8327-760677bfcf0b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T00:59:10.002716Z",
     "iopub.status.busy": "2025-03-05T00:59:10.002571Z",
     "iopub.status.idle": "2025-03-05T00:59:10.008276Z",
     "shell.execute_reply": "2025-03-05T00:59:10.007629Z"
    },
    "papermill": {
     "duration": 0.01444,
     "end_time": "2025-03-05T00:59:10.009855",
     "exception": false,
     "start_time": "2025-03-05T00:59:09.995415",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def lorentzian_distance(x, y):\n",
    "    \n",
    "    dot_product = torch.sum(x * y, dim=-1)\n",
    "    norm_x = torch.norm(x, dim=-1)\n",
    "    norm_y = torch.norm(y, dim=-1)\n",
    "    \n",
    "    distance = torch.acosh(-dot_product + torch.sqrt((1 + norm_x**2) * (1 + norm_y**2)))\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "de4ecc53-8b64-4fee-bfbf-d3b85d441d1f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T00:59:10.022501Z",
     "iopub.status.busy": "2025-03-05T00:59:10.022368Z",
     "iopub.status.idle": "2025-03-05T00:59:10.036194Z",
     "shell.execute_reply": "2025-03-05T00:59:10.035301Z"
    },
    "papermill": {
     "duration": 0.021569,
     "end_time": "2025-03-05T00:59:10.037725",
     "exception": false,
     "start_time": "2025-03-05T00:59:10.016156",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def expm_o(v, c=1.0):\n",
    "    c = torch.tensor(c)\n",
    "    vspace = v\n",
    "    vnorm = torch.norm(v, p=2, dim=-1, keepdim=True)\n",
    "    xspace = torch.sinh(torch.sqrt(c) * vnorm) * vspace / (torch.sqrt(c) * vnorm)\n",
    "    batch_min = xspace.min(dim=1, keepdim=True).values\n",
    "    batch_max = xspace.max(dim=1, keepdim=True).values\n",
    "    xspace_scaled=(xspace - batch_min) / (batch_max - batch_min)\n",
    "    return xspace_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c6639968-6b1d-4601-a69f-6e83b9863ab6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T00:59:10.052725Z",
     "iopub.status.busy": "2025-03-05T00:59:10.052593Z",
     "iopub.status.idle": "2025-03-05T00:59:10.060110Z",
     "shell.execute_reply": "2025-03-05T00:59:10.059695Z"
    },
    "papermill": {
     "duration": 0.016959,
     "end_time": "2025-03-05T00:59:10.061676",
     "exception": false,
     "start_time": "2025-03-05T00:59:10.044717",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_mrr_hyperbolic(model1, data_loader_val, distance_fn):\n",
    "    model1.eval()\n",
    "    \n",
    "    total_rr = 0.0\n",
    "    num_queries = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader_val:\n",
    "            anchor_text = batch[0]\n",
    "            positive_text = batch[1]\n",
    "            negative_texts = batch[2]\n",
    "\n",
    "            anchor_input = tokenizer(anchor_text, return_tensors='pt', padding=True, truncation=True, max_length=512).to(device)\n",
    "            positive_input = tokenizer(positive_text, return_tensors='pt', padding=True, truncation=True, max_length=512).to(device)\n",
    "\n",
    "            anchor_embedding = expm_o(model1(**anchor_input).last_hidden_state[:, 0, :])\n",
    "            positive_embedding = expm_o(model1(**positive_input).last_hidden_state[:, 0, :])\n",
    "            negative_embedding = [expm_o(model1(**tokenizer(neg, return_tensors='pt', padding=True, truncation=True, max_length=512).to(device)).last_hidden_state[:, 0, :]) for neg in negative_texts]\n",
    "\n",
    "            pos_dist = distance_fn(anchor_embedding, positive_embedding)\n",
    "            neg_dist = torch.stack([distance_fn(anchor_embedding, neg) for neg in negative_embedding], dim=-1)\n",
    "            all_similarities=torch.cat([-pos_dist.unsqueeze(1), -neg_dist], dim=1)\n",
    "\n",
    "            sorted_similarities, sorted_indices = torch.sort(all_similarities, dim=1, descending=True)\n",
    "\n",
    "            # Find the rank of the first relevant (positive) document\n",
    "            positive_rank = (sorted_indices == 0).nonzero(as_tuple=True)[1] + 1  # +1 to make rank 1-based\n",
    "            total_rr += torch.sum(1.0 / positive_rank.float()).item()  # Reciprocal rank\n",
    "            num_queries += len(positive_rank)\n",
    "            \n",
    "    mrr = total_rr / num_queries\n",
    "    return mrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9c54c77e-2dde-4c88-9eaf-439a409e845e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T00:59:10.076910Z",
     "iopub.status.busy": "2025-03-05T00:59:10.076781Z",
     "iopub.status.idle": "2025-03-05T00:59:42.165661Z",
     "shell.execute_reply": "2025-03-05T00:59:42.164885Z"
    },
    "papermill": {
     "duration": 32.112098,
     "end_time": "2025-03-05T00:59:42.181233",
     "exception": false,
     "start_time": "2025-03-05T00:59:10.069135",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.411733341217041\n"
     ]
    }
   ],
   "source": [
    "mrr_validation_hyperbolic = evaluate_mrr_hyperbolic(model1=lora_model_hyperbolic, data_loader_val=data_loader,distance_fn=lorentzian_distance)\n",
    "print(mrr_validation_hyperbolic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e097240-0b21-4a85-8959-2c74522b15a8",
   "metadata": {
    "papermill": {
     "duration": 0.005377,
     "end_time": "2025-03-05T00:59:42.194427",
     "exception": false,
     "start_time": "2025-03-05T00:59:42.189050",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d883371b-b6e4-40de-b212-93ed5fcb6061",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T00:59:42.205803Z",
     "iopub.status.busy": "2025-03-05T00:59:42.205261Z",
     "iopub.status.idle": "2025-03-05T00:59:42.215117Z",
     "shell.execute_reply": "2025-03-05T00:59:42.214650Z"
    },
    "papermill": {
     "duration": 0.016209,
     "end_time": "2025-03-05T00:59:42.215926",
     "exception": false,
     "start_time": "2025-03-05T00:59:42.199717",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median Query Length: 9.0\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "print(\"Median Query Length:\", statistics.median(query_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4b02b505-a8f9-480d-959e-effcbc2ed3a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T00:59:42.227912Z",
     "iopub.status.busy": "2025-03-05T00:59:42.227530Z",
     "iopub.status.idle": "2025-03-05T00:59:42.253168Z",
     "shell.execute_reply": "2025-03-05T00:59:42.252773Z"
    },
    "papermill": {
     "duration": 0.032459,
     "end_time": "2025-03-05T00:59:42.253904",
     "exception": false,
     "start_time": "2025-03-05T00:59:42.221445",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3951666712760925"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mrr_validation_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5c10dccb-fbc7-448b-b3d9-4d7e045dafd3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T00:59:42.265814Z",
     "iopub.status.busy": "2025-03-05T00:59:42.264903Z",
     "iopub.status.idle": "2025-03-05T00:59:42.269678Z",
     "shell.execute_reply": "2025-03-05T00:59:42.269283Z"
    },
    "papermill": {
     "duration": 0.011071,
     "end_time": "2025-03-05T00:59:42.270491",
     "exception": false,
     "start_time": "2025-03-05T00:59:42.259420",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3895166733264923"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mrr_validation_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b9c22c87-c20f-4a86-a8d3-d941340ea726",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T00:59:42.281484Z",
     "iopub.status.busy": "2025-03-05T00:59:42.281357Z",
     "iopub.status.idle": "2025-03-05T00:59:42.285571Z",
     "shell.execute_reply": "2025-03-05T00:59:42.285142Z"
    },
    "papermill": {
     "duration": 0.01042,
     "end_time": "2025-03-05T00:59:42.286239",
     "exception": false,
     "start_time": "2025-03-05T00:59:42.275819",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.411733341217041"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mrr_validation_hyperbolic"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 118.412435,
   "end_time": "2025-03-05T00:59:44.714466",
   "environment_variables": {},
   "exception": null,
   "input_path": "SCIDOCS.ipynb",
   "output_path": "SCIDOCS_output.ipynb",
   "parameters": {},
   "start_time": "2025-03-05T00:57:46.302031",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "06f7f37f62f445758c8a0e0212a5195d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_6758057401604bb38970d907b5afab80",
       "placeholder": "​",
       "style": "IPY_MODEL_7f76ceeb9e834708b474f3f9c7d36e71",
       "tabbable": null,
       "tooltip": null,
       "value": " 25657/25657 [00:00&lt;00:00, 34166.24it/s]"
      }
     },
     "166a24621b414b66bb89c2e8adace147": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "1b605ead828a464eaae0e0e9c2ae6d90": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_f814dc3af0f0485ca9e144be3d76157d",
        "IPY_MODEL_b2c7a79d27f74f7ea700cd9dc22a0c6b",
        "IPY_MODEL_06f7f37f62f445758c8a0e0212a5195d"
       ],
       "layout": "IPY_MODEL_ec17d951318d4562962176bd40341475",
       "tabbable": null,
       "tooltip": null
      }
     },
     "3042e98b9a084e6ba7bcd348c8cdd6ce": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "4e4545970d1b445b81947f306558d95c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "6758057401604bb38970d907b5afab80": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7f76ceeb9e834708b474f3f9c7d36e71": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "b2c7a79d27f74f7ea700cd9dc22a0c6b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_ef5b2faca19b4d6c8cd5d19315026924",
       "max": 25657.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_166a24621b414b66bb89c2e8adace147",
       "tabbable": null,
       "tooltip": null,
       "value": 25657.0
      }
     },
     "ec17d951318d4562962176bd40341475": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "ef5b2faca19b4d6c8cd5d19315026924": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f814dc3af0f0485ca9e144be3d76157d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_3042e98b9a084e6ba7bcd348c8cdd6ce",
       "placeholder": "​",
       "style": "IPY_MODEL_4e4545970d1b445b81947f306558d95c",
       "tabbable": null,
       "tooltip": null,
       "value": "100%"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}