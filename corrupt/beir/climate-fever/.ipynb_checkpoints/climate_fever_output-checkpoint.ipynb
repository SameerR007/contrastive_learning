{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6d4b65f-fa6b-4517-8694-8627bc49833b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T03:05:56.472159Z",
     "iopub.status.busy": "2025-03-05T03:05:56.471843Z",
     "iopub.status.idle": "2025-03-05T03:05:56.556122Z",
     "shell.execute_reply": "2025-03-05T03:05:56.555676Z"
    },
    "papermill": {
     "duration": 0.089311,
     "end_time": "2025-03-05T03:05:56.556819",
     "exception": false,
     "start_time": "2025-03-05T03:05:56.467508",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dss/dsshome1/07/ra65bex2/srawat/myenv/lib/python3.12/site-packages/beir/datasets/data_loader.py:8: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "from beir.datasets.data_loader import GenericDataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a91d6914-e301-422c-b839-1fafeb1e8fa4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T03:05:56.564430Z",
     "iopub.status.busy": "2025-03-05T03:05:56.564148Z",
     "iopub.status.idle": "2025-03-05T03:05:56.566648Z",
     "shell.execute_reply": "2025-03-05T03:05:56.566226Z"
    },
    "papermill": {
     "duration": 0.006801,
     "end_time": "2025-03-05T03:05:56.567265",
     "exception": false,
     "start_time": "2025-03-05T03:05:56.560464",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_path='/dss/dsshome1/07/ra65bex2/srawat/climate-fever/climate-fever'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41e17333-2c34-4b7b-91f6-3cbd3972f0d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T03:05:56.575653Z",
     "iopub.status.busy": "2025-03-05T03:05:56.575289Z",
     "iopub.status.idle": "2025-03-05T03:06:24.492361Z",
     "shell.execute_reply": "2025-03-05T03:06:24.491757Z"
    },
    "papermill": {
     "duration": 27.922564,
     "end_time": "2025-03-05T03:06:24.493173",
     "exception": false,
     "start_time": "2025-03-05T03:05:56.570609",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1f9ee8eb32c4413aed5f61eec4d3d9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5416593 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "corpus, queries, qrels = GenericDataLoader(data_path).load(split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d653c60-435a-4e10-8506-6ef5d01f8675",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T03:06:24.505498Z",
     "iopub.status.busy": "2025-03-05T03:06:24.505326Z",
     "iopub.status.idle": "2025-03-05T03:06:30.480106Z",
     "shell.execute_reply": "2025-03-05T03:06:30.479631Z"
    },
    "papermill": {
     "duration": 5.979471,
     "end_time": "2025-03-05T03:06:30.480776",
     "exception": false,
     "start_time": "2025-03-05T03:06:24.501305",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /dss/dsshome1/07/ra65bex2/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /dss/dsshome1/07/ra65bex2/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "def clean_text(text):\n",
    "    return re.sub(r'[^\\w\\s.!?]', '', text)\n",
    "def select_words(text, percentage):\n",
    "    words = [w for w in text.split() if w.lower() not in stop_words]\n",
    "    return random.sample(words, min(int(percentage*len(words)), len(words)))\n",
    "def introduce_typo(word):\n",
    "    if len(word) > 1:\n",
    "        idx = random.randint(0, len(word) - 1)\n",
    "        return word[:idx] + random.choice('abcdefghijklmnopqrstuvwxyz') + word[idx+1:]\n",
    "    return word\n",
    "def introduce_noise(word):\n",
    "    noise_chars = ['@', '#', '$', '%', '&', '*']\n",
    "    if len(word) > 1:\n",
    "        idx = random.randint(0, len(word) - 1)\n",
    "        return word[:idx] + random.choice(noise_chars) + word[idx+1:]\n",
    "    return word\n",
    "def replace_with_synonym(word):\n",
    "    synonyms = [syn.lemmas()[0].name() for syn in wordnet.synsets(word) if syn.lemmas()]\n",
    "    return random.choice(synonyms) if synonyms else word\n",
    "def corrupt_word(word, method):\n",
    "    if method == 'typo':\n",
    "        return introduce_typo(word)\n",
    "    elif method == 'noise':\n",
    "        return introduce_noise(word)\n",
    "    elif method == 'synonym':\n",
    "        return replace_with_synonym(word)\n",
    "    return word\n",
    "def corrupt_text(text):\n",
    "    corrupted_words = []  \n",
    "    words_to_corrupt=select_words(clean_text(text), percentage=0.5)\n",
    "    for word in clean_text(text).split():\n",
    "        if word in words_to_corrupt:\n",
    "            corruption_method = random.choice(['typo', 'noise', 'synonym'])\n",
    "            corrupted_words.append(corrupt_word(word, corruption_method))\n",
    "        else:\n",
    "            corrupted_words.append(word)\n",
    "    return ' '.join(corrupted_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29044d5-3952-4f3d-aa43-e1efd34fcad3",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": false,
     "start_time": "2025-03-05T03:06:30.486305",
     "status": "running"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "contrastive_pairs=[]\n",
    "query_lengths = []\n",
    "import random\n",
    "c=0\n",
    "for query_id, relevant_docs in qrels.items():\n",
    "    try:\n",
    "        query_text = queries[query_id]\n",
    "        query_lengths.append(len(query_text.split()))\n",
    "        for doc_id in relevant_docs:\n",
    "            positive = corpus[doc_id][\"text\"]\n",
    "        #print(relevant_docs)\n",
    "        positive_doc_ids = set(relevant_docs)\n",
    "        all_doc_ids = set(corpus.keys())\n",
    "        negative_doc_ids = all_doc_ids - positive_doc_ids\n",
    "        negative_doc_ids=list(negative_doc_ids)\n",
    "        negative_doc_samples = random.sample(negative_doc_ids, k=5)\n",
    "        negatives=[]\n",
    "        for neg_doc_id in negative_doc_samples:\n",
    "            negative_doc_text = corpus[neg_doc_id][\"text\"]\n",
    "            negatives.append(negative_doc_text)\n",
    "        contrastive_pairs.append({\n",
    "            \"anchor\": corrupt_text(query_text),\n",
    "            \"positive\": positive,\n",
    "            \"negatives\": negatives\n",
    "        })\n",
    "    except:\n",
    "        c=c+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49721946-fff3-4690-bd92-d981cecdf62b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8ef367-dcb4-4bb6-af3a-20f190930ed1",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(contrastive_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2ccada-419a-4f79-ad4d-b605780281a3",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "contrastive_pairs[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ade92f9-e3df-4d0a-b849-b1a721e18cf6",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(qrels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b97f7b4-f007-41f6-bfbb-1b9b01665e9d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a415b29a-a543-4679-8f78-44f715b3067d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ContrastiveDataset:\n",
    "    def __init__(self, pairs):\n",
    "        self.pairs = pairs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.pairs[idx]\n",
    "        return item[\"anchor\"], item[\"positive\"], item[\"negatives\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39efeab-fd20-411a-80c5-315f362e00d2",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "contrastive_dataset = ContrastiveDataset(contrastive_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d103bbfa-895a-4020-a7e5-21de659f27dc",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_loader = DataLoader(contrastive_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b0277f-f526-4087-82da-c4cdd65d32da",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15526a4-b3fe-435b-91c9-ad4064562f0f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "file_path_baseline =\"/dss/dsshome1/07/ra65bex2/srawat/contrastive_learning/v1.1/app_baseline/checkpoint_epoch_3.pth\"\n",
    "lora_model_baseline = torch.load(file_path_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9999e628-5966-4dda-b5c5-c0d762fce27d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "lora_model_baseline = lora_model_baseline.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6a3a61-8db0-43db-b575-6399f8515950",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ac4919-76f1-4349-a314-4b1061126655",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cosine_distance(x, y):\n",
    "    return 1 - torch.nn.functional.cosine_similarity(x, y, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990f63bd-4d48-4f58-a001-3b3250f65312",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_mrr_baseline(model, data_loader_val, distance_fn):\n",
    "    model.eval()\n",
    "\n",
    "    total_rr = 0.0\n",
    "    num_queries = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader_val:\n",
    "            anchor_text = batch[0]\n",
    "            positive_text = batch[1]\n",
    "            negative_texts = batch[2]\n",
    "\n",
    "            anchor_input = tokenizer(anchor_text, return_tensors='pt', padding=True, truncation=True, max_length=512).to(device)\n",
    "            positive_input = tokenizer(positive_text, return_tensors='pt', padding=True, truncation=True, max_length=512).to(device)\n",
    "\n",
    "            anchor_embedding = model(**anchor_input).last_hidden_state[:, 0, :]\n",
    "            positive_embedding = model(**positive_input).last_hidden_state[:, 0, :]\n",
    "            negative_embedding = [model(**tokenizer(neg, return_tensors='pt', padding=True, truncation=True, max_length=512).to(device)).last_hidden_state[:, 0, :] for neg in negative_texts]\n",
    "\n",
    "            pos_dist = distance_fn(anchor_embedding, positive_embedding)\n",
    "            neg_dist = torch.stack([distance_fn(anchor_embedding, neg) for neg in negative_embedding], dim=-1)\n",
    "            all_similarities=torch.cat([-pos_dist.unsqueeze(1), -neg_dist], dim=1)\n",
    "\n",
    "            sorted_similarities, sorted_indices = torch.sort(all_similarities, dim=1, descending=True)\n",
    "\n",
    "            # Find the rank of the first relevant (positive) document\n",
    "            positive_rank = (sorted_indices == 0).nonzero(as_tuple=True)[1] + 1  # +1 to make rank 1-based\n",
    "            total_rr += torch.sum(1.0 / positive_rank.float()).item()  # Reciprocal rank\n",
    "            num_queries += len(positive_rank)\n",
    "\n",
    "    mrr = total_rr / num_queries\n",
    "    return mrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534a9ec5-4211-4cb6-81f1-fb8a30caff92",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mrr_validation_baseline = evaluate_mrr_baseline(lora_model_baseline, data_loader, cosine_distance)\n",
    "print(mrr_validation_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61bbd65-41c9-4ac7-80ef-ba4a4fb02d45",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3dfd17-ee43-4c4e-9287-8ec6451bc062",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_path_average=\"/dss/dsshome1/07/ra65bex2/srawat/contrastive_learning/v1.1/app_average/average_checkpoint_epoch_3.pth\"\n",
    "lora_model_average = torch.load(file_path_average)\n",
    "lora_model_average = lora_model_average.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c10d3f-c53d-4222-aba4-0e763451baff",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def avg_embedding(inputs, model):\n",
    "    input=model(**inputs)\n",
    "    input_last_hidden_state=input.last_hidden_state\n",
    "    input_attention_mask = inputs['attention_mask']\n",
    "    input_masked_embeddings = input_last_hidden_state * input_attention_mask.unsqueeze(-1)\n",
    "    input_sum_embeddings = torch.sum(input_masked_embeddings, dim=1)\n",
    "    input_token_counts = torch.sum(input_attention_mask, dim=1).unsqueeze(-1)\n",
    "    input_avg_embeddings = input_sum_embeddings / input_token_counts\n",
    "    return(input_avg_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22570a1b-93bf-41ef-99fe-de41c3857b41",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_mrr_average(model, data_loader_val, distance_fn):\n",
    "    model.eval()  \n",
    "\n",
    "    total_rr = 0.0\n",
    "    num_queries = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader_val:\n",
    "            anchor_text = batch[0]\n",
    "            positive_text = batch[1]\n",
    "            negative_texts = batch[2]\n",
    "\n",
    "            anchor_input = tokenizer(anchor_text, return_tensors='pt', padding=True, truncation=True, max_length=512).to(device)\n",
    "            positive_input = tokenizer(positive_text, return_tensors='pt', padding=True, truncation=True, max_length=512).to(device)\n",
    "\n",
    "            anchor_embedding = avg_embedding(anchor_input, model)\n",
    "            positive_embedding = avg_embedding(positive_input, model)\n",
    "            negative_embedding = [avg_embedding(tokenizer(neg, return_tensors='pt', padding=True, truncation=True, max_length=512).to(device), model) for neg in negative_texts]\n",
    "\n",
    "            pos_dist = distance_fn(anchor_embedding, positive_embedding)\n",
    "            neg_dist = torch.stack([distance_fn(anchor_embedding, neg) for neg in negative_embedding], dim=-1)\n",
    "            all_similarities=torch.cat([-pos_dist.unsqueeze(1), -neg_dist], dim=1)\n",
    "            \n",
    "            sorted_similarities, sorted_indices = torch.sort(all_similarities, dim=1, descending=True)\n",
    "\n",
    "            # Find the rank of the first relevant (positive) document\n",
    "            positive_rank = (sorted_indices == 0).nonzero(as_tuple=True)[1] + 1  # +1 to make rank 1-based\n",
    "            total_rr += torch.sum(1.0 / positive_rank.float()).item()  # Reciprocal rank\n",
    "            num_queries += len(positive_rank)\n",
    "\n",
    "    mrr = total_rr / num_queries\n",
    "    return mrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82977667-a984-467e-9eb6-9d6520ecb3b8",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mrr_validation_average = evaluate_mrr_average(lora_model_average, data_loader, cosine_distance)\n",
    "print(mrr_validation_average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966c23c7-dc92-49e8-bb1f-1520c0ccd13b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af58281c-1786-4bda-9eec-0fa0f127d140",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_path_hyperbolic=\"/dss/dsshome1/07/ra65bex2/srawat/contrastive_learning/v1.1/0.1hyperbolic/hyperbolic_lora_checkpoint_epoch_3.pth\"\n",
    "lora_model_hyperbolic = torch.load(file_path_hyperbolic)\n",
    "lora_model_hyperbolic = lora_model_hyperbolic.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f9507b-01e9-49d0-8327-760677bfcf0b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def lorentzian_distance(x, y):\n",
    "    \n",
    "    dot_product = torch.sum(x * y, dim=-1)\n",
    "    norm_x = torch.norm(x, dim=-1)\n",
    "    norm_y = torch.norm(y, dim=-1)\n",
    "    \n",
    "    distance = torch.acosh(-dot_product + torch.sqrt((1 + norm_x**2) * (1 + norm_y**2)))\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4ecc53-8b64-4fee-bfbf-d3b85d441d1f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def expm_o(v, c=1.0):\n",
    "    c = torch.tensor(c)\n",
    "    vspace = v\n",
    "    vnorm = torch.norm(v, p=2, dim=-1, keepdim=True)\n",
    "    xspace = torch.sinh(torch.sqrt(c) * vnorm) * vspace / (torch.sqrt(c) * vnorm)\n",
    "    batch_min = xspace.min(dim=1, keepdim=True).values\n",
    "    batch_max = xspace.max(dim=1, keepdim=True).values\n",
    "    xspace_scaled=(xspace - batch_min) / (batch_max - batch_min)\n",
    "    return xspace_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6639968-6b1d-4601-a69f-6e83b9863ab6",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_mrr_hyperbolic(model1, data_loader_val, distance_fn):\n",
    "    model1.eval()\n",
    "    \n",
    "    total_rr = 0.0\n",
    "    num_queries = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader_val:\n",
    "            anchor_text = batch[0]\n",
    "            positive_text = batch[1]\n",
    "            negative_texts = batch[2]\n",
    "\n",
    "            anchor_input = tokenizer(anchor_text, return_tensors='pt', padding=True, truncation=True, max_length=512).to(device)\n",
    "            positive_input = tokenizer(positive_text, return_tensors='pt', padding=True, truncation=True, max_length=512).to(device)\n",
    "\n",
    "            anchor_embedding = expm_o(model1(**anchor_input).last_hidden_state[:, 0, :])\n",
    "            positive_embedding = expm_o(model1(**positive_input).last_hidden_state[:, 0, :])\n",
    "            negative_embedding = [expm_o(model1(**tokenizer(neg, return_tensors='pt', padding=True, truncation=True, max_length=512).to(device)).last_hidden_state[:, 0, :]) for neg in negative_texts]\n",
    "\n",
    "            pos_dist = distance_fn(anchor_embedding, positive_embedding)\n",
    "            neg_dist = torch.stack([distance_fn(anchor_embedding, neg) for neg in negative_embedding], dim=-1)\n",
    "            all_similarities=torch.cat([-pos_dist.unsqueeze(1), -neg_dist], dim=1)\n",
    "\n",
    "            sorted_similarities, sorted_indices = torch.sort(all_similarities, dim=1, descending=True)\n",
    "\n",
    "            # Find the rank of the first relevant (positive) document\n",
    "            positive_rank = (sorted_indices == 0).nonzero(as_tuple=True)[1] + 1  # +1 to make rank 1-based\n",
    "            total_rr += torch.sum(1.0 / positive_rank.float()).item()  # Reciprocal rank\n",
    "            num_queries += len(positive_rank)\n",
    "            \n",
    "    mrr = total_rr / num_queries\n",
    "    return mrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c54c77e-2dde-4c88-9eaf-439a409e845e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mrr_validation_hyperbolic = evaluate_mrr_hyperbolic(model1=lora_model_hyperbolic, data_loader_val=data_loader,distance_fn=lorentzian_distance)\n",
    "print(mrr_validation_hyperbolic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e097240-0b21-4a85-8959-2c74522b15a8",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d883371b-b6e4-40de-b212-93ed5fcb6061",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import statistics\n",
    "print(\"Median Query Length:\", statistics.median(query_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b02b505-a8f9-480d-959e-effcbc2ed3a2",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mrr_validation_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c10dccb-fbc7-448b-b3d9-4d7e045dafd3",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mrr_validation_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c22c87-c20f-4a86-a8d3-d941340ea726",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "mrr_validation_hyperbolic"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "papermill": {
   "default_parameters": {},
   "duration": null,
   "end_time": null,
   "environment_variables": {},
   "exception": null,
   "input_path": "climate_fever.ipynb",
   "output_path": "climate_fever_output.ipynb",
   "parameters": {},
   "start_time": "2025-03-05T03:05:54.864473",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}