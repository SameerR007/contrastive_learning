{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6d4b65f-fa6b-4517-8694-8627bc49833b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T01:07:48.627259Z",
     "iopub.status.busy": "2025-03-05T01:07:48.626401Z",
     "iopub.status.idle": "2025-03-05T01:07:48.713794Z",
     "shell.execute_reply": "2025-03-05T01:07:48.713317Z"
    },
    "papermill": {
     "duration": 0.093338,
     "end_time": "2025-03-05T01:07:48.714610",
     "exception": false,
     "start_time": "2025-03-05T01:07:48.621272",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/dss/dsshome1/07/ra65bex2/srawat/myenv/lib/python3.12/site-packages/beir/datasets/data_loader.py:8: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "from beir.datasets.data_loader import GenericDataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a91d6914-e301-422c-b839-1fafeb1e8fa4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T01:07:48.723031Z",
     "iopub.status.busy": "2025-03-05T01:07:48.722768Z",
     "iopub.status.idle": "2025-03-05T01:07:48.725593Z",
     "shell.execute_reply": "2025-03-05T01:07:48.725186Z"
    },
    "papermill": {
     "duration": 0.007705,
     "end_time": "2025-03-05T01:07:48.726398",
     "exception": false,
     "start_time": "2025-03-05T01:07:48.718693",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_path = '/dss/dsshome1/07/ra65bex2/srawat/webis-touche2020/webis-touche2020'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41e17333-2c34-4b7b-91f6-3cbd3972f0d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T01:07:48.736523Z",
     "iopub.status.busy": "2025-03-05T01:07:48.736224Z",
     "iopub.status.idle": "2025-03-05T01:07:52.649340Z",
     "shell.execute_reply": "2025-03-05T01:07:52.648851Z"
    },
    "papermill": {
     "duration": 3.919515,
     "end_time": "2025-03-05T01:07:52.650133",
     "exception": false,
     "start_time": "2025-03-05T01:07:48.730618",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04b5660207d8430a9ae7fdd637921199",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/382545 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "corpus, queries, qrels = GenericDataLoader(data_path).load(split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d653c60-435a-4e10-8506-6ef5d01f8675",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T01:07:52.658136Z",
     "iopub.status.busy": "2025-03-05T01:07:52.657959Z",
     "iopub.status.idle": "2025-03-05T01:07:54.830820Z",
     "shell.execute_reply": "2025-03-05T01:07:54.830276Z"
    },
    "papermill": {
     "duration": 2.17752,
     "end_time": "2025-03-05T01:07:54.831595",
     "exception": false,
     "start_time": "2025-03-05T01:07:52.654075",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /dss/dsshome1/07/ra65bex2/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /dss/dsshome1/07/ra65bex2/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "def clean_text(text):\n",
    "    return re.sub(r'[^\\w\\s.!?]', '', text)\n",
    "def select_words(text, percentage):\n",
    "    words = [w for w in text.split() if w.lower() not in stop_words]\n",
    "    return random.sample(words, min(int(percentage*len(words)), len(words)))\n",
    "def introduce_typo(word):\n",
    "    if len(word) > 1:\n",
    "        idx = random.randint(0, len(word) - 1)\n",
    "        return word[:idx] + random.choice('abcdefghijklmnopqrstuvwxyz') + word[idx+1:]\n",
    "    return word\n",
    "def introduce_noise(word):\n",
    "    noise_chars = ['@', '#', '$', '%', '&', '*']\n",
    "    if len(word) > 1:\n",
    "        idx = random.randint(0, len(word) - 1)\n",
    "        return word[:idx] + random.choice(noise_chars) + word[idx+1:]\n",
    "    return word\n",
    "def replace_with_synonym(word):\n",
    "    synonyms = [syn.lemmas()[0].name() for syn in wordnet.synsets(word) if syn.lemmas()]\n",
    "    return random.choice(synonyms) if synonyms else word\n",
    "def corrupt_word(word, method):\n",
    "    if method == 'typo':\n",
    "        return introduce_typo(word)\n",
    "    elif method == 'noise':\n",
    "        return introduce_noise(word)\n",
    "    elif method == 'synonym':\n",
    "        return replace_with_synonym(word)\n",
    "    return word\n",
    "def corrupt_text(text):\n",
    "    corrupted_words = []  \n",
    "    words_to_corrupt=select_words(clean_text(text), percentage=0.5)\n",
    "    for word in clean_text(text).split():\n",
    "        if word in words_to_corrupt:\n",
    "            corruption_method = random.choice(['typo', 'noise', 'synonym'])\n",
    "            corrupted_words.append(corrupt_word(word, corruption_method))\n",
    "        else:\n",
    "            corrupted_words.append(word)\n",
    "    return ' '.join(corrupted_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a29044d5-3952-4f3d-aa43-e1efd34fcad3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T01:07:54.845745Z",
     "iopub.status.busy": "2025-03-05T01:07:54.845519Z",
     "iopub.status.idle": "2025-03-05T01:08:01.079935Z",
     "shell.execute_reply": "2025-03-05T01:08:01.079188Z"
    },
    "papermill": {
     "duration": 6.239667,
     "end_time": "2025-03-05T01:08:01.080972",
     "exception": false,
     "start_time": "2025-03-05T01:07:54.841305",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "contrastive_pairs=[]\n",
    "query_lengths = []\n",
    "import random\n",
    "c=0\n",
    "for query_id, relevant_docs in qrels.items():\n",
    "    try:\n",
    "        query_text = queries[query_id]\n",
    "        query_lengths.append(len(query_text.split()))\n",
    "        for doc_id in relevant_docs:\n",
    "            positive = corpus[doc_id][\"text\"]\n",
    "        #print(relevant_docs)\n",
    "        positive_doc_ids = set(relevant_docs)\n",
    "        all_doc_ids = set(corpus.keys())\n",
    "        negative_doc_ids = all_doc_ids - positive_doc_ids\n",
    "        negative_doc_ids=list(negative_doc_ids)\n",
    "        negative_doc_samples = random.sample(negative_doc_ids, k=5)\n",
    "        negatives=[]\n",
    "        for neg_doc_id in negative_doc_samples:\n",
    "            negative_doc_text = corpus[neg_doc_id][\"text\"]\n",
    "            negatives.append(negative_doc_text)\n",
    "        contrastive_pairs.append({\n",
    "            \"anchor\": corrupt_text(query_text),\n",
    "            \"positive\": positive,\n",
    "            \"negatives\": negatives\n",
    "        })\n",
    "    except:\n",
    "        c=c+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "49721946-fff3-4690-bd92-d981cecdf62b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T01:08:01.092058Z",
     "iopub.status.busy": "2025-03-05T01:08:01.091905Z",
     "iopub.status.idle": "2025-03-05T01:08:01.095595Z",
     "shell.execute_reply": "2025-03-05T01:08:01.095213Z"
    },
    "papermill": {
     "duration": 0.008969,
     "end_time": "2025-03-05T01:08:01.096330",
     "exception": false,
     "start_time": "2025-03-05T01:08:01.087361",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "de8ef367-dcb4-4bb6-af3a-20f190930ed1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T01:08:01.105616Z",
     "iopub.status.busy": "2025-03-05T01:08:01.105264Z",
     "iopub.status.idle": "2025-03-05T01:08:01.118552Z",
     "shell.execute_reply": "2025-03-05T01:08:01.118172Z"
    },
    "papermill": {
     "duration": 0.018775,
     "end_time": "2025-03-05T01:08:01.119711",
     "exception": false,
     "start_time": "2025-03-05T01:08:01.100936",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(contrastive_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a2ccada-419a-4f79-ad4d-b605780281a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T01:08:01.128151Z",
     "iopub.status.busy": "2025-03-05T01:08:01.128018Z",
     "iopub.status.idle": "2025-03-05T01:08:01.142210Z",
     "shell.execute_reply": "2025-03-05T01:08:01.141804Z"
    },
    "papermill": {
     "duration": 0.019405,
     "end_time": "2025-03-05T01:08:01.142829",
     "exception": false,
     "start_time": "2025-03-05T01:08:01.123424",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'anchor': 'Should @eachers get tenure?',\n",
       "  'positive': 'I believe that all mentally fit teachers should have a gun in the class room. NOT loose in a drawer, but in a lock box, with a key or a code. If ONE teacher would have had a gun in Conn. those kids would have lived to see there next Christmas. I rest my case.',\n",
       "  'negatives': ['I AM SO SORRY For forfeiting the earlier roundAnd opponent, if you need my evidence, just ask, I have it readyMy opponents main argument is essentially that the election is not balanced and it is unfairHowever, my 3rd contention directly refutes thisSuper PACs, which take the money from corporations and donate them to candidates, are actually creating competition between the political candidates bettering democracy and voter turnout.A February 2012 Slate Magazine article gave us is the Republican Primaries and how without Super PACs, Mitt Romney would win by a huge margin. But since there are Super PACs, there is a more competitive race for the fight for president, and this keeps other alternative candidates in the election too. Because of this, there are more choices in the election, and thus, with more candidates to fit these voter’s ideologies, there is more voter turnout.Another study conducted by the CATO organization was published in 2002 which showed that without PACs, the Mccain-Feingold Act would apply and most donations would go to the incumbents instead of the challenger. With the PACs, the current law made by the Citizen’s United decision would apply and money would go to both candidates. This makes the election fair and competitive.Also, An increase in campaign spending means that more people are participating in democracy. The Citizens United Decision recognizes campaign contributions as a form of free speech, so what an increase in campaign donations means is that more people are making posters and flyers, and there is more of a participation in democracy. According to a study done in the Social Science Quarterly, overall, an increase in campaign spending equates to an increase in voter participation, thus strengthening our democracy.Another point is that one cannot say that there is a money disparity in the campaigning1. People pay with their dollars. Campaign spending is free speech2. if a person gets more votes, it is fair? Of course. This is the natural process of democracy. Our government allows significant disparities in the election process. Why does money harm this process?3. Corporations support the candidate that has a better message, so it is their choice to give them money and support them. Thus, when our opponents claim that money disparity is not fair, this is the problem of capitalism, not the Citizens United Decision, since there has been unequal campaign funding since the start of our democracy.Judge, look at this at a logical standpointWe have to look at this at a capitalist viewThe US is a capitalist society. Any money that is earned can be spent HOWEVER THEY WANT TOJudge this is nesccesary for you to understand So I hope you vote CON/NEG',\n",
       "   'I love that animals are in zoos they make them safe to see',\n",
       "   \"Firstly, my argument about female cancers is a rebute of your argument that circumcision can prevent cancers in women (round one argument). Why would circumcising/not circumcising a man affect the body of the women he has sexual relations with? Secondly, the part(s) of the penis removed during circumcision do serve a purpose, just as a female's breasts (which, by the way, aren't removed even if the woman is incapable of reproducing- they're just left alone). Con is failing to recognise that the foreskin is not the only thing that may be removed during circumcision. Up to five different areas can be amputated. This has been linked to infertility as men who've been circumcised can have difficulty ejaculating, thus preventing conception. Con also fails to recognise that circumcision, no matter the age of the male performed on, can go very, very wrong. In one case, it even lead to the suicide of a man called David Reimer. David and his twin were both scheduled for circumcision as infants due to a tightening of the skin of the penis (often misdiagnosed in babies). David's surgery went horribly wrong and he was rushed out of the theatre. Horrified, Reimer's parents stopped his twin's surgery from going ahead in fear that he, too, would be just as severely mutilated. David's genitalia turned black and rotted away entirely as a result of the botched surgery. Confused of what else to do, David's parents allowed him to undergo gender reassignment. They raised him as a girl, but he was put through further surgery to reconstruct his body. Eventually, Reimer's parents told him about the failed circumcision. He'd often odd as a little girl so decided to live as a male, rejecting female hormone treatments. However, these series of horrific decisions made by surgeons and medical proffessionals proved fatal. He committed suicide in 2004. There are many more cases of males being horrified that they were circumcised without being giving the option themselves. This is not the only case of death and emotional trauma circumcision has been linked to, as you can read in the first source. Source also argues that baby boys have a slightly higher risk of death through blood loss as the loss of just over 2 ounces of blood can be enough to kill a newborn. Con makes an argument that circumcision can prevent STDs, but they disregard that so can proper hygeine of the genitals. Why put males through the risk of blood loss and/or emotional trauma, when they can simply learn how to correctly clean themselves? Again, I am not against circumcision full-stop. I just think that it shouldn't be done at birth- a man should make the decision to be circumcised or not in later life. If he's prepared to take that risk, that is completely ethical, but that choice should be his alone. My source also points out the double-standard of circumcision- why is it okay to circumcise a boy but not a girl? FGM is seen as hoorrific but, in the long run, it has less an effect on the individual's ability to reproduce. Women do not need to climax to get pregnant, but men must in order to impregnate. This just shows the sexist double-standard that circumcised males face. Source: http://intaction.org...\",\n",
       "   'Argument: Not only did constant scandals take Clinton\\'s focus off running the country he lost credibility in the eye of the public every time. When Paula Jones sued Clinton for sexual harassment, he became the first sitting president to testify before a grand jury investigating his own conduct. His affair with White House intern Monica Lewinsky culminated in Clinton\\'s impeachment by the House of Representatives on Dec. 19, 1998 on charges of perjury and obstruction of justice. Clinton cut NASA\\'s budget by $715 million in 1995 (about 5%) and did not restore the bulk of the money until three months before he left office. The result was a space program struggling to operate with less money for most of Clinton\\'s time in office. Some blame the 2003 Space Shuttle Columbia explosion on Clinton\\'s decision to slash NASA\\'s budget by an aggregate of $56 million over his presidency. Clinton was unable to fulfill his campaign promise to repeal the ban on homosexuals serving in the military. Faced with strong opposition from conservatives early in his presidency, Clinton settled on a compromise policy referred to as \"don\\'t ask, don\\'t tell,\" which allowed gays to serve in the military if they did not disclose their sexual orientation. Neither conservatives nor liberals were satisfied by the outcome. Clinton\\'s gun law backfired terribly, because the number of federal prisoners doubled under Clinton, and 58 percent of them were serving time for drug-related offenses. Resources were geared towards incarceration instead of rehabilitation or crime prevention. Clinton\\'s 1994 Crime Bill was filled with \"pork spending\" that distributed $10 billion to states and special interest groups. In rebuttal towards your \"And, the Bill banned the manufacture of 19 specific types of deadly assault weapons,\" the bill was repealed 10 years ago on 9/13/2004. As seen at www.nbcnews.com it says \"The expiration Monday of a 10-year federal ban on assault weapons means firearms like AK-47s, Uzis and TEC-9s can now be legally bought \" a development that has critics upset and gun owners pleased. The 1994 ban, signed by then President Clinton, outlawed 19 types of military-style assault weapons. A clause directed that the ban expire unless Congress specifically reauthorized it, which it did not.\" This shows that this bill may have succeeded for his term but in the long run, it did not. Clinton\\'s Goals 2000 program did not ensure uniform quality of standards among all the states because he compromised on oversight to get the program passed. The impact therefore varied by state and Clinton never fulfilled his goal of equalizing education standards and improving results for all students. By 2000, six years after IASA was implemented, only 17 states were in full compliance with the standards. Clinton gets too much credit for the economy boom in in the 1990\"s, which was already growing at a rapid pace before he became president. It was the republican controlled congress which made the economy that it was. Clinton failure to regulate the financial-services markets enabled the bad lending and Wall Street scams that led to the 2007 banking crisis. Citations- http://www.nbcnews.com... For gun laws http://clinton.procon.org...- For everything else Sincerely PM',\n",
       "   'A non existent universe does not exist']},\n",
       " {'anchor': 'Is vaping with e%igarettes safe?',\n",
       "  'positive': 'We have to accept that for a wide variety of social reasons teens are now more sexually active than ...',\n",
       "  'negatives': ['destruction=turn my back life is real, and destruction dosnt happen in reality the reaper is a metaphor i am me, like the reader',\n",
       "   'Russia and the US have a fundamental divergence over the notion of spheres of interest. Russia only accepts any other country playing a role in its near abroad very grudgingly and will attempt to get other great powers out whenever possible. In the aftermath of 9/11 Russia could not prevent American intervention in Central Asia therefore it was sensible to make sure it was co-opted to serve Russia’s own interests, namely to be against international terrorism, rather than being directed against Russia herself. By doing so Russia could preserve her influence in the region. As America was willing to take on the costs of maintaining the security of the region Russia could retrench and cut costs.[1]\\xa0Yet Russia began to force the US out as soon as was possible, for example forcing the closure of a U.S. airbase in Kyrgyzstan.[2] Russia has sometimes seemed to purposefully take the opposite side to the US in Eastern Europe. An example of this occurring was over the possibility of independence for Kosovo almost a decade after the conflict that forced Serbian forces out of the country. According to Charles Kupchan “on the question of Kosovo, direct Russian interests are difficult to discern, and therefore it appears that Russia’s backing of Serbia is part of a more muscular Russian policy, and a desire to stand up to the United States and the EU across the board.”[3] [1]\\xa0Lena Jonson, Vladimir Putin and Central Asia The Shaping of Russian Foreign Policy, (I.B. Tauris, London, 2004), pp.172-174 [2]\\xa0Schwirtz, Michael, ‘Kyrgyzstan Insists U.S. Base to Close’, The New York Times, 11 June 2009, http://www.nytimes.com/2009/06/12/world/asia/12kyrgyz.html [3]\\xa0Bernard Gwertzmann, ‘Interview Kupchan: Russian Opposition to Kosovo Independence ‘Perplexing’, Foreign Affairs, Dec 2007,\\xa0http://www.cfr.org/kosovo/kupchan-russian-opposition-kosovo-independence-perplexing/p15093\\xa0accessed 27/4/11',\n",
       "   \"Half the debates are about the so-called 'god' because you wrote them. Atheism is the absence of religion, saying there is no deity, no supreme being, governing our lives You can argue all you want, but arguing on an idea, with no concrete proof, is a failure waiting to happen. Science has proved that there is no supreme being, because all that has a beginning has an end. And do you understand that every other debate topic is taken, to do a debate, I have to do this subject, the most repulsive ever. And no one thinks about it constantly, otherwise they would get nothing done. I have never seen someone, but a priest, carry a bible around. I am only thinking about it now because you brought it up. Please argue about something else. And by the way, humans are not insignificant.\",\n",
       "   \"I don't believe Australia needs to do its fair share in accepting Syrian refugees.\",\n",
       "   \"First of all, Pro should win this debate because Pro is, of course, number one. Pro is number one and also, is indeed the best. Pro knows a colleague named Victor, and to the victor goes the spoils. Therefore, unless Con is named victor, Pro shall win this debate. Pro is the smartest person on this website, so that means that Pro should win this debate. There is no reason why Pro will not win. Pro has a dog named Mordecai, so obvious he should win this debate. Pro has a self-cleaning oven, that also leads one to believe that the winner should be Pro. The address of Pro's house is 1, and the street Pro lives on is First, these two factors combines to insure the definite and deserved victory of Pro. In this debate, Pro has chosen the funnier picture to represent him as his avatar, thus proving that Pro should win this debate. Coffee requires three packets of sugar, not two, which means that Pro should win this debate. The Earth goes around the Sun and not the other way around, so of course the winner is Pro. Pro should also win for the simple reason that Frankenstein was THE NAME OF THE SCIENTIST AND NOT THE MONSTER. There is no reason why Con could beat Pro in this debate.\"]}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contrastive_pairs[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ade92f9-e3df-4d0a-b849-b1a721e18cf6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T01:08:01.152400Z",
     "iopub.status.busy": "2025-03-05T01:08:01.151382Z",
     "iopub.status.idle": "2025-03-05T01:08:01.163862Z",
     "shell.execute_reply": "2025-03-05T01:08:01.163469Z"
    },
    "papermill": {
     "duration": 0.017793,
     "end_time": "2025-03-05T01:08:01.164837",
     "exception": false,
     "start_time": "2025-03-05T01:08:01.147044",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(qrels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b97f7b4-f007-41f6-bfbb-1b9b01665e9d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T01:08:01.174111Z",
     "iopub.status.busy": "2025-03-05T01:08:01.173803Z",
     "iopub.status.idle": "2025-03-05T01:08:04.659754Z",
     "shell.execute_reply": "2025-03-05T01:08:04.659048Z"
    },
    "papermill": {
     "duration": 3.49211,
     "end_time": "2025-03-05T01:08:04.661332",
     "exception": false,
     "start_time": "2025-03-05T01:08:01.169222",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a415b29a-a543-4679-8f78-44f715b3067d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T01:08:04.678082Z",
     "iopub.status.busy": "2025-03-05T01:08:04.677152Z",
     "iopub.status.idle": "2025-03-05T01:08:04.682040Z",
     "shell.execute_reply": "2025-03-05T01:08:04.681386Z"
    },
    "papermill": {
     "duration": 0.010971,
     "end_time": "2025-03-05T01:08:04.682727",
     "exception": false,
     "start_time": "2025-03-05T01:08:04.671756",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ContrastiveDataset:\n",
    "    def __init__(self, pairs):\n",
    "        self.pairs = pairs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.pairs[idx]\n",
    "        return item[\"anchor\"], item[\"positive\"], item[\"negatives\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a39efeab-fd20-411a-80c5-315f362e00d2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T01:08:04.692361Z",
     "iopub.status.busy": "2025-03-05T01:08:04.692227Z",
     "iopub.status.idle": "2025-03-05T01:08:04.701414Z",
     "shell.execute_reply": "2025-03-05T01:08:04.701039Z"
    },
    "papermill": {
     "duration": 0.014983,
     "end_time": "2025-03-05T01:08:04.702108",
     "exception": false,
     "start_time": "2025-03-05T01:08:04.687125",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "contrastive_dataset = ContrastiveDataset(contrastive_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d103bbfa-895a-4020-a7e5-21de659f27dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T01:08:04.711160Z",
     "iopub.status.busy": "2025-03-05T01:08:04.710820Z",
     "iopub.status.idle": "2025-03-05T01:08:04.723341Z",
     "shell.execute_reply": "2025-03-05T01:08:04.722980Z"
    },
    "papermill": {
     "duration": 0.017407,
     "end_time": "2025-03-05T01:08:04.723997",
     "exception": false,
     "start_time": "2025-03-05T01:08:04.706590",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_loader = DataLoader(contrastive_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8b0277f-f526-4087-82da-c4cdd65d32da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T01:08:04.733455Z",
     "iopub.status.busy": "2025-03-05T01:08:04.733111Z",
     "iopub.status.idle": "2025-03-05T01:08:04.744113Z",
     "shell.execute_reply": "2025-03-05T01:08:04.743749Z"
    },
    "papermill": {
     "duration": 0.015976,
     "end_time": "2025-03-05T01:08:04.744752",
     "exception": false,
     "start_time": "2025-03-05T01:08:04.728776",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e15526a4-b3fe-435b-91c9-ad4064562f0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T01:08:04.754518Z",
     "iopub.status.busy": "2025-03-05T01:08:04.754391Z",
     "iopub.status.idle": "2025-03-05T01:08:08.364939Z",
     "shell.execute_reply": "2025-03-05T01:08:08.364386Z"
    },
    "papermill": {
     "duration": 3.61654,
     "end_time": "2025-03-05T01:08:08.366004",
     "exception": false,
     "start_time": "2025-03-05T01:08:04.749464",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1257190/261098231.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  lora_model_baseline = torch.load(file_path_baseline)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "file_path_baseline =\"/dss/dsshome1/07/ra65bex2/srawat/contrastive_learning/v1.1/app_baseline/checkpoint_epoch_3.pth\"\n",
    "lora_model_baseline = torch.load(file_path_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9999e628-5966-4dda-b5c5-c0d762fce27d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T01:08:08.377967Z",
     "iopub.status.busy": "2025-03-05T01:08:08.377488Z",
     "iopub.status.idle": "2025-03-05T01:08:08.382937Z",
     "shell.execute_reply": "2025-03-05T01:08:08.382540Z"
    },
    "papermill": {
     "duration": 0.010758,
     "end_time": "2025-03-05T01:08:08.383569",
     "exception": false,
     "start_time": "2025-03-05T01:08:08.372811",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "lora_model_baseline = lora_model_baseline.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7e6a3a61-8db0-43db-b575-6399f8515950",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T01:08:08.392647Z",
     "iopub.status.busy": "2025-03-05T01:08:08.392508Z",
     "iopub.status.idle": "2025-03-05T01:08:08.601397Z",
     "shell.execute_reply": "2025-03-05T01:08:08.600884Z"
    },
    "papermill": {
     "duration": 0.214298,
     "end_time": "2025-03-05T01:08:08.602244",
     "exception": false,
     "start_time": "2025-03-05T01:08:08.387946",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "68ac4919-76f1-4349-a314-4b1061126655",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T01:08:08.611852Z",
     "iopub.status.busy": "2025-03-05T01:08:08.611707Z",
     "iopub.status.idle": "2025-03-05T01:08:08.614216Z",
     "shell.execute_reply": "2025-03-05T01:08:08.613852Z"
    },
    "papermill": {
     "duration": 0.007772,
     "end_time": "2025-03-05T01:08:08.614811",
     "exception": false,
     "start_time": "2025-03-05T01:08:08.607039",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cosine_distance(x, y):\n",
    "    return 1 - torch.nn.functional.cosine_similarity(x, y, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "990f63bd-4d48-4f58-a001-3b3250f65312",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T01:08:08.623861Z",
     "iopub.status.busy": "2025-03-05T01:08:08.623720Z",
     "iopub.status.idle": "2025-03-05T01:08:08.636878Z",
     "shell.execute_reply": "2025-03-05T01:08:08.636291Z"
    },
    "papermill": {
     "duration": 0.018353,
     "end_time": "2025-03-05T01:08:08.637503",
     "exception": false,
     "start_time": "2025-03-05T01:08:08.619150",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_mrr_baseline(model, data_loader_val, distance_fn):\n",
    "    model.eval()\n",
    "\n",
    "    total_rr = 0.0\n",
    "    num_queries = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader_val:\n",
    "            anchor_text = batch[0]\n",
    "            positive_text = batch[1]\n",
    "            negative_texts = batch[2]\n",
    "\n",
    "            anchor_input = tokenizer(anchor_text, return_tensors='pt', padding=True, truncation=True, max_length=512).to(device)\n",
    "            positive_input = tokenizer(positive_text, return_tensors='pt', padding=True, truncation=True, max_length=512).to(device)\n",
    "\n",
    "            anchor_embedding = model(**anchor_input).last_hidden_state[:, 0, :]\n",
    "            positive_embedding = model(**positive_input).last_hidden_state[:, 0, :]\n",
    "            negative_embedding = [model(**tokenizer(neg, return_tensors='pt', padding=True, truncation=True, max_length=512).to(device)).last_hidden_state[:, 0, :] for neg in negative_texts]\n",
    "\n",
    "            pos_dist = distance_fn(anchor_embedding, positive_embedding)\n",
    "            neg_dist = torch.stack([distance_fn(anchor_embedding, neg) for neg in negative_embedding], dim=-1)\n",
    "            all_similarities=torch.cat([-pos_dist.unsqueeze(1), -neg_dist], dim=1)\n",
    "\n",
    "            sorted_similarities, sorted_indices = torch.sort(all_similarities, dim=1, descending=True)\n",
    "\n",
    "            # Find the rank of the first relevant (positive) document\n",
    "            positive_rank = (sorted_indices == 0).nonzero(as_tuple=True)[1] + 1  # +1 to make rank 1-based\n",
    "            total_rr += torch.sum(1.0 / positive_rank.float()).item()  # Reciprocal rank\n",
    "            num_queries += len(positive_rank)\n",
    "\n",
    "    mrr = total_rr / num_queries\n",
    "    return mrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "534a9ec5-4211-4cb6-81f1-fb8a30caff92",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T01:08:08.646829Z",
     "iopub.status.busy": "2025-03-05T01:08:08.646687Z",
     "iopub.status.idle": "2025-03-05T01:08:11.241317Z",
     "shell.execute_reply": "2025-03-05T01:08:11.240923Z"
    },
    "papermill": {
     "duration": 2.600034,
     "end_time": "2025-03-05T01:08:11.241994",
     "exception": false,
     "start_time": "2025-03-05T01:08:08.641960",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4272108856512576\n"
     ]
    }
   ],
   "source": [
    "mrr_validation_baseline = evaluate_mrr_baseline(lora_model_baseline, data_loader, cosine_distance)\n",
    "print(mrr_validation_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61bbd65-41c9-4ac7-80ef-ba4a4fb02d45",
   "metadata": {
    "papermill": {
     "duration": 0.004527,
     "end_time": "2025-03-05T01:08:11.253403",
     "exception": false,
     "start_time": "2025-03-05T01:08:11.248876",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8a3dfd17-ee43-4c4e-9287-8ec6451bc062",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T01:08:11.262753Z",
     "iopub.status.busy": "2025-03-05T01:08:11.262613Z",
     "iopub.status.idle": "2025-03-05T01:08:11.621324Z",
     "shell.execute_reply": "2025-03-05T01:08:11.620889Z"
    },
    "papermill": {
     "duration": 0.364162,
     "end_time": "2025-03-05T01:08:11.621937",
     "exception": false,
     "start_time": "2025-03-05T01:08:11.257775",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1257190/2975798179.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  lora_model_average = torch.load(file_path_average)\n"
     ]
    }
   ],
   "source": [
    "file_path_average=\"/dss/dsshome1/07/ra65bex2/srawat/contrastive_learning/v1.1/app_average/average_checkpoint_epoch_3.pth\"\n",
    "lora_model_average = torch.load(file_path_average)\n",
    "lora_model_average = lora_model_average.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "49c10d3f-c53d-4222-aba4-0e763451baff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T01:08:11.631594Z",
     "iopub.status.busy": "2025-03-05T01:08:11.631455Z",
     "iopub.status.idle": "2025-03-05T01:08:11.634316Z",
     "shell.execute_reply": "2025-03-05T01:08:11.634021Z"
    },
    "papermill": {
     "duration": 0.008272,
     "end_time": "2025-03-05T01:08:11.634871",
     "exception": false,
     "start_time": "2025-03-05T01:08:11.626599",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def avg_embedding(inputs, model):\n",
    "    input=model(**inputs)\n",
    "    input_last_hidden_state=input.last_hidden_state\n",
    "    input_attention_mask = inputs['attention_mask']\n",
    "    input_masked_embeddings = input_last_hidden_state * input_attention_mask.unsqueeze(-1)\n",
    "    input_sum_embeddings = torch.sum(input_masked_embeddings, dim=1)\n",
    "    input_token_counts = torch.sum(input_attention_mask, dim=1).unsqueeze(-1)\n",
    "    input_avg_embeddings = input_sum_embeddings / input_token_counts\n",
    "    return(input_avg_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "22570a1b-93bf-41ef-99fe-de41c3857b41",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T01:08:11.644467Z",
     "iopub.status.busy": "2025-03-05T01:08:11.644340Z",
     "iopub.status.idle": "2025-03-05T01:08:11.655958Z",
     "shell.execute_reply": "2025-03-05T01:08:11.655647Z"
    },
    "papermill": {
     "duration": 0.017198,
     "end_time": "2025-03-05T01:08:11.656574",
     "exception": false,
     "start_time": "2025-03-05T01:08:11.639376",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_mrr_average(model, data_loader_val, distance_fn):\n",
    "    model.eval()  \n",
    "\n",
    "    total_rr = 0.0\n",
    "    num_queries = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader_val:\n",
    "            anchor_text = batch[0]\n",
    "            positive_text = batch[1]\n",
    "            negative_texts = batch[2]\n",
    "\n",
    "            anchor_input = tokenizer(anchor_text, return_tensors='pt', padding=True, truncation=True, max_length=512).to(device)\n",
    "            positive_input = tokenizer(positive_text, return_tensors='pt', padding=True, truncation=True, max_length=512).to(device)\n",
    "\n",
    "            anchor_embedding = avg_embedding(anchor_input, model)\n",
    "            positive_embedding = avg_embedding(positive_input, model)\n",
    "            negative_embedding = [avg_embedding(tokenizer(neg, return_tensors='pt', padding=True, truncation=True, max_length=512).to(device), model) for neg in negative_texts]\n",
    "\n",
    "            pos_dist = distance_fn(anchor_embedding, positive_embedding)\n",
    "            neg_dist = torch.stack([distance_fn(anchor_embedding, neg) for neg in negative_embedding], dim=-1)\n",
    "            all_similarities=torch.cat([-pos_dist.unsqueeze(1), -neg_dist], dim=1)\n",
    "            \n",
    "            sorted_similarities, sorted_indices = torch.sort(all_similarities, dim=1, descending=True)\n",
    "\n",
    "            # Find the rank of the first relevant (positive) document\n",
    "            positive_rank = (sorted_indices == 0).nonzero(as_tuple=True)[1] + 1  # +1 to make rank 1-based\n",
    "            total_rr += torch.sum(1.0 / positive_rank.float()).item()  # Reciprocal rank\n",
    "            num_queries += len(positive_rank)\n",
    "\n",
    "    mrr = total_rr / num_queries\n",
    "    return mrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "82977667-a984-467e-9eb6-9d6520ecb3b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T01:08:11.665962Z",
     "iopub.status.busy": "2025-03-05T01:08:11.665832Z",
     "iopub.status.idle": "2025-03-05T01:08:13.478584Z",
     "shell.execute_reply": "2025-03-05T01:08:13.478044Z"
    },
    "papermill": {
     "duration": 1.818272,
     "end_time": "2025-03-05T01:08:13.479363",
     "exception": false,
     "start_time": "2025-03-05T01:08:11.661091",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5163265539675342\n"
     ]
    }
   ],
   "source": [
    "mrr_validation_average = evaluate_mrr_average(lora_model_average, data_loader, cosine_distance)\n",
    "print(mrr_validation_average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966c23c7-dc92-49e8-bb1f-1520c0ccd13b",
   "metadata": {
    "papermill": {
     "duration": 0.00448,
     "end_time": "2025-03-05T01:08:13.495228",
     "exception": false,
     "start_time": "2025-03-05T01:08:13.490748",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "af58281c-1786-4bda-9eec-0fa0f127d140",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T01:08:13.504750Z",
     "iopub.status.busy": "2025-03-05T01:08:13.504604Z",
     "iopub.status.idle": "2025-03-05T01:08:13.859500Z",
     "shell.execute_reply": "2025-03-05T01:08:13.858981Z"
    },
    "papermill": {
     "duration": 0.360841,
     "end_time": "2025-03-05T01:08:13.860537",
     "exception": false,
     "start_time": "2025-03-05T01:08:13.499696",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1257190/2502257612.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  lora_model_hyperbolic = torch.load(file_path_hyperbolic)\n"
     ]
    }
   ],
   "source": [
    "file_path_hyperbolic=\"/dss/dsshome1/07/ra65bex2/srawat/contrastive_learning/v1.1/0.1hyperbolic/hyperbolic_lora_checkpoint_epoch_3.pth\"\n",
    "lora_model_hyperbolic = torch.load(file_path_hyperbolic)\n",
    "lora_model_hyperbolic = lora_model_hyperbolic.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d6f9507b-01e9-49d0-8327-760677bfcf0b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T01:08:13.871151Z",
     "iopub.status.busy": "2025-03-05T01:08:13.870748Z",
     "iopub.status.idle": "2025-03-05T01:08:13.873684Z",
     "shell.execute_reply": "2025-03-05T01:08:13.873312Z"
    },
    "papermill": {
     "duration": 0.008597,
     "end_time": "2025-03-05T01:08:13.874367",
     "exception": false,
     "start_time": "2025-03-05T01:08:13.865770",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def lorentzian_distance(x, y):\n",
    "    \n",
    "    dot_product = torch.sum(x * y, dim=-1)\n",
    "    norm_x = torch.norm(x, dim=-1)\n",
    "    norm_y = torch.norm(y, dim=-1)\n",
    "    \n",
    "    distance = torch.acosh(-dot_product + torch.sqrt((1 + norm_x**2) * (1 + norm_y**2)))\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "de4ecc53-8b64-4fee-bfbf-d3b85d441d1f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T01:08:13.884088Z",
     "iopub.status.busy": "2025-03-05T01:08:13.883951Z",
     "iopub.status.idle": "2025-03-05T01:08:13.895298Z",
     "shell.execute_reply": "2025-03-05T01:08:13.894940Z"
    },
    "papermill": {
     "duration": 0.016918,
     "end_time": "2025-03-05T01:08:13.895966",
     "exception": false,
     "start_time": "2025-03-05T01:08:13.879048",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def expm_o(v, c=1.0):\n",
    "    c = torch.tensor(c)\n",
    "    vspace = v\n",
    "    vnorm = torch.norm(v, p=2, dim=-1, keepdim=True)\n",
    "    xspace = torch.sinh(torch.sqrt(c) * vnorm) * vspace / (torch.sqrt(c) * vnorm)\n",
    "    batch_min = xspace.min(dim=1, keepdim=True).values\n",
    "    batch_max = xspace.max(dim=1, keepdim=True).values\n",
    "    xspace_scaled=(xspace - batch_min) / (batch_max - batch_min)\n",
    "    return xspace_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c6639968-6b1d-4601-a69f-6e83b9863ab6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T01:08:13.905743Z",
     "iopub.status.busy": "2025-03-05T01:08:13.905610Z",
     "iopub.status.idle": "2025-03-05T01:08:13.915381Z",
     "shell.execute_reply": "2025-03-05T01:08:13.915028Z"
    },
    "papermill": {
     "duration": 0.015411,
     "end_time": "2025-03-05T01:08:13.916063",
     "exception": false,
     "start_time": "2025-03-05T01:08:13.900652",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_mrr_hyperbolic(model1, data_loader_val, distance_fn):\n",
    "    model1.eval()\n",
    "    \n",
    "    total_rr = 0.0\n",
    "    num_queries = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader_val:\n",
    "            anchor_text = batch[0]\n",
    "            positive_text = batch[1]\n",
    "            negative_texts = batch[2]\n",
    "\n",
    "            anchor_input = tokenizer(anchor_text, return_tensors='pt', padding=True, truncation=True, max_length=512).to(device)\n",
    "            positive_input = tokenizer(positive_text, return_tensors='pt', padding=True, truncation=True, max_length=512).to(device)\n",
    "\n",
    "            anchor_embedding = expm_o(model1(**anchor_input).last_hidden_state[:, 0, :])\n",
    "            positive_embedding = expm_o(model1(**positive_input).last_hidden_state[:, 0, :])\n",
    "            negative_embedding = [expm_o(model1(**tokenizer(neg, return_tensors='pt', padding=True, truncation=True, max_length=512).to(device)).last_hidden_state[:, 0, :]) for neg in negative_texts]\n",
    "\n",
    "            pos_dist = distance_fn(anchor_embedding, positive_embedding)\n",
    "            neg_dist = torch.stack([distance_fn(anchor_embedding, neg) for neg in negative_embedding], dim=-1)\n",
    "            all_similarities=torch.cat([-pos_dist.unsqueeze(1), -neg_dist], dim=1)\n",
    "\n",
    "            sorted_similarities, sorted_indices = torch.sort(all_similarities, dim=1, descending=True)\n",
    "\n",
    "            # Find the rank of the first relevant (positive) document\n",
    "            positive_rank = (sorted_indices == 0).nonzero(as_tuple=True)[1] + 1  # +1 to make rank 1-based\n",
    "            total_rr += torch.sum(1.0 / positive_rank.float()).item()  # Reciprocal rank\n",
    "            num_queries += len(positive_rank)\n",
    "            \n",
    "    mrr = total_rr / num_queries\n",
    "    return mrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9c54c77e-2dde-4c88-9eaf-439a409e845e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T01:08:13.925817Z",
     "iopub.status.busy": "2025-03-05T01:08:13.925682Z",
     "iopub.status.idle": "2025-03-05T01:08:15.773092Z",
     "shell.execute_reply": "2025-03-05T01:08:15.772698Z"
    },
    "papermill": {
     "duration": 1.853039,
     "end_time": "2025-03-05T01:08:15.773755",
     "exception": false,
     "start_time": "2025-03-05T01:08:13.920716",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.36258502882354116\n"
     ]
    }
   ],
   "source": [
    "mrr_validation_hyperbolic = evaluate_mrr_hyperbolic(model1=lora_model_hyperbolic, data_loader_val=data_loader,distance_fn=lorentzian_distance)\n",
    "print(mrr_validation_hyperbolic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e097240-0b21-4a85-8959-2c74522b15a8",
   "metadata": {
    "papermill": {
     "duration": 0.004845,
     "end_time": "2025-03-05T01:08:15.784000",
     "exception": false,
     "start_time": "2025-03-05T01:08:15.779155",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d883371b-b6e4-40de-b212-93ed5fcb6061",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T01:08:15.794038Z",
     "iopub.status.busy": "2025-03-05T01:08:15.793796Z",
     "iopub.status.idle": "2025-03-05T01:08:15.799229Z",
     "shell.execute_reply": "2025-03-05T01:08:15.798924Z"
    },
    "papermill": {
     "duration": 0.011135,
     "end_time": "2025-03-05T01:08:15.799843",
     "exception": false,
     "start_time": "2025-03-05T01:08:15.788708",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median Query Length: 6\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "print(\"Median Query Length:\", statistics.median(query_lengths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4b02b505-a8f9-480d-959e-effcbc2ed3a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T01:08:15.809890Z",
     "iopub.status.busy": "2025-03-05T01:08:15.809754Z",
     "iopub.status.idle": "2025-03-05T01:08:15.821634Z",
     "shell.execute_reply": "2025-03-05T01:08:15.821343Z"
    },
    "papermill": {
     "duration": 0.017446,
     "end_time": "2025-03-05T01:08:15.822216",
     "exception": false,
     "start_time": "2025-03-05T01:08:15.804770",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4272108856512576"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mrr_validation_baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5c10dccb-fbc7-448b-b3d9-4d7e045dafd3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T01:08:15.833174Z",
     "iopub.status.busy": "2025-03-05T01:08:15.832527Z",
     "iopub.status.idle": "2025-03-05T01:08:15.844674Z",
     "shell.execute_reply": "2025-03-05T01:08:15.844358Z"
    },
    "papermill": {
     "duration": 0.018068,
     "end_time": "2025-03-05T01:08:15.845261",
     "exception": false,
     "start_time": "2025-03-05T01:08:15.827193",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5163265539675342"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mrr_validation_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b9c22c87-c20f-4a86-a8d3-d941340ea726",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-05T01:08:15.855572Z",
     "iopub.status.busy": "2025-03-05T01:08:15.855447Z",
     "iopub.status.idle": "2025-03-05T01:08:15.866212Z",
     "shell.execute_reply": "2025-03-05T01:08:15.865898Z"
    },
    "papermill": {
     "duration": 0.016621,
     "end_time": "2025-03-05T01:08:15.866903",
     "exception": false,
     "start_time": "2025-03-05T01:08:15.850282",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36258502882354116"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mrr_validation_hyperbolic"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 32.627078,
   "end_time": "2025-03-05T01:08:19.630246",
   "environment_variables": {},
   "exception": null,
   "input_path": "touche2020.ipynb",
   "output_path": "touche2020_output.ipynb",
   "parameters": {},
   "start_time": "2025-03-05T01:07:47.003168",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "04b5660207d8430a9ae7fdd637921199": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_7686fe64664e45329e53cbdcf894cec3",
        "IPY_MODEL_b6a0a76e2e5b473189df2e714388ab5c",
        "IPY_MODEL_e00785e4b1b84315bf85c0ed468d3b00"
       ],
       "layout": "IPY_MODEL_c17dc37aa17b4e3bb0f5e600e7dcfdb6",
       "tabbable": null,
       "tooltip": null
      }
     },
     "495fddeec93d413394d3d88836fc0765": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "59527effcfea49afb649dfc50653ac3c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "65b14b9333714d49adf4b5d2305ae3d3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "7686fe64664e45329e53cbdcf894cec3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_84cc6352bb7e4270b4ee54138a60b5d9",
       "placeholder": "​",
       "style": "IPY_MODEL_8661ac10511547eab8265a94090b386d",
       "tabbable": null,
       "tooltip": null,
       "value": "100%"
      }
     },
     "84cc6352bb7e4270b4ee54138a60b5d9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8661ac10511547eab8265a94090b386d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "b6a0a76e2e5b473189df2e714388ab5c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_59527effcfea49afb649dfc50653ac3c",
       "max": 382545.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_65b14b9333714d49adf4b5d2305ae3d3",
       "tabbable": null,
       "tooltip": null,
       "value": 382545.0
      }
     },
     "c17dc37aa17b4e3bb0f5e600e7dcfdb6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e00785e4b1b84315bf85c0ed468d3b00": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_495fddeec93d413394d3d88836fc0765",
       "placeholder": "​",
       "style": "IPY_MODEL_e08189e5989d41c287f170bc69671bde",
       "tabbable": null,
       "tooltip": null,
       "value": " 382545/382545 [00:03&lt;00:00, 140149.31it/s]"
      }
     },
     "e08189e5989d41c287f170bc69671bde": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}