{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset('ms_marco', 'v1.1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    validation: Dataset({\n",
       "        features: ['answers', 'passages', 'query', 'query_id', 'query_type', 'wellFormedAnswers'],\n",
       "        num_rows: 10047\n",
       "    })\n",
       "    train: Dataset({\n",
       "        features: ['answers', 'passages', 'query', 'query_id', 'query_type', 'wellFormedAnswers'],\n",
       "        num_rows: 82326\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['answers', 'passages', 'query', 'query_id', 'query_type', 'wellFormedAnswers'],\n",
       "        num_rows: 9650\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset('ms_marco', 'v1.1', split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['answers', 'passages', 'query', 'query_id', 'query_type', 'wellFormedAnswers'],\n",
       "    num_rows: 82326\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datasets.arrow_dataset.Dataset"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(example):\n",
    "    positive_passages=[]\n",
    "    for p in enumerate(example['passages'][\"is_selected\"]):\n",
    "        if p[1]==1:\n",
    "            positive_passages.append(example[\"passages\"][\"passage_text\"][p[0]])\n",
    "    negative_passages = []\n",
    "    for p in enumerate(example['passages'][\"is_selected\"]):\n",
    "        if p[1]==0:\n",
    "            negative_passages.append(example[\"passages\"][\"passage_text\"][p[0]])\n",
    "    if (len(positive_passages)>0 and len(negative_passages)>=5):\n",
    "        positive = positive_passages[0]\n",
    "        negatives = negative_passages[:5]\n",
    "        return {\n",
    "            \"query\": example[\"query\"],\n",
    "            \"positive\": positive,\n",
    "            \"negatives\": negatives\n",
    "        }\n",
    "    else:\n",
    "        return {\"query\": None, \"positive\": None, \"negatives\": None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = dataset.map(preprocess, remove_columns=dataset.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = processed_data.filter(lambda x: x['query'] is not None and x['positive'] is not None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "contrastive_pairs = []\n",
    "for item in processed_data:\n",
    "    query = item[\"query\"]\n",
    "    positive = item[\"positive\"]\n",
    "    negatives = item[\"negatives\"]\n",
    "    contrastive_pairs.append({\n",
    "        \"anchor\": query,\n",
    "        \"positive\": positive,\n",
    "        \"negatives\": negatives\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74538"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(contrastive_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastiveDataset:\n",
    "    def __init__(self, pairs):\n",
    "        self.pairs = pairs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.pairs[idx]\n",
    "        return item[\"anchor\"], item[\"positive\"], item[\"negatives\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "contrastive_dataset = ContrastiveDataset(contrastive_pairs[0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_loader = DataLoader(contrastive_dataset, batch_size=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = AutoModel.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_config = LoraConfig(\n",
    "    task_type= \"FEATURE_EXTRACTION\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n"
     ]
    }
   ],
   "source": [
    "lora_model = get_peft_model(model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 294,912 || all params: 109,777,152 || trainable%: 0.2686\n"
     ]
    }
   ],
   "source": [
    "lora_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_distance(x, y):\n",
    "    return 1 - torch.nn.functional.cosine_similarity(x, y, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([\n",
    "    [1.0, 2.0, 3.0],  # First vector\n",
    "    [4.0, 5.0, 6.0]   # Second vector\n",
    "])\n",
    "\n",
    "y = torch.tensor([\n",
    "    [7.0, 8.0, 9.0],  # First vector\n",
    "    [10.0, 11.0, 12.0] # Second vector\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9594, 0.9961])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.functional.cosine_similarity(x, y, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9339, 0.9693, 0.9839])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.functional.cosine_similarity(x, y, dim=-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('price to install tile in shower', 'was ronald reagan a democrat')\n",
      "2\n",
      "('1 Install ceramic tile floor to match shower-Average prices for installation are between $11 to $22 per square foot; 2  A light/fan combination-Averages at $180 and one hour of installation; 3  Insulate and re-finish ceilings and walls-Fiberglass wall insulation with R-30 value will cost $2.25 per square foot.', \"From Wikipedia, the free encyclopedia. A Reagan Democrat is a traditionally Democratic voter in the United States, especially a white working-class Northerner, who defected from their party to support Republican President Ronald Reagan in either or both the 1980 and 1984 elections. During the 1980 election a dramatic number of voters in the U.S., disillusioned with the economic 'malaise' of the 1970s and the presidency of Jimmy Carter (even more than, four years earlier, Liberal Republican Gerald Ford), supported former California governor (and former Democrat) Ronald Reagan.\")\n",
      "2\n",
      "[('In regards to tile installation costs, consumers can expect to pay an average of $25 per square foot, depending on the grade of material that is used. For a medium-sized shower, the price can cost about $2,000. Tile installation materials include:', 'In his younger years, Ronald Reagan was a member of the Democratic Party and campaigned for Democratic candidates; however, his views grew more conservative over time, and in the early 1960s he officially became a Republican. In November 1984, Ronald Reagan was reelected in a landslide, defeating Walter Mondale and his running mate Geraldine Ferraro (1935-), the first female vice-presidential candidate from a major U.S. political party.'), ('1 Polished nickel faucets-Average cost is $400 each plus four hours of installation; 2  Install ceramic tile floor to match shower-Average prices for installation are between $11 to $22 per square foot; 3  A light/fan combination-Averages at $180 and one hour', 'Ronald Reagan began his political life in the Democratic Party, but as he became more and more conservative, he ultimately changed to the Republican Party in the early 1960s. Yes, he switched parties in 1962. He said that he did not desert the Democrats but rather they deserted him. Yes, Ronald Reagan was a member of the Democratic Party until he s … witched to the Republican Party in 1962, at the age of 51. 8 people found this useful.'), ('Enhancement and improvement costs. 1  Polished nickel faucets-Average cost is $400 each plus four hours of installation; 2  Install ceramic tile floor to match shower-Average prices for installation are between $11 to $22 per square foot; 3  A light/fan combination-Averages at $180 and one hour of installation; 4  Insulate and re-finish ceilings and 5  ... Painti', 'Ronald Wilson Reagan (/ˈrɒnəld ˈwɪlsən ˈreɪɡən/ ; February 6, 1911 – June 5, 2004) was an American politician, commentator, and actor, who served as the 40th President of the United States from 1981 to 1989. I think Ronald Reagan changed the trajectory of America in a way that Richard Nixon did not and in a way that Bill Clinton did not. He put us on a fundamentally different path because the country was ready for it.'), ('Granite shower tile is available at an average of $3.49 per square foot to $6.99 per square foot. Polished stone wall tile comes in many choices, including pebble stone that costs about $10 per square foot and $12 per square foot for a smooth surface polished stone tile.', \"When Reagan was a 'liberal Democrat'. In 1948, a very different sounding Ronald Reagan campaigned on the radio for Democrat Harry Truman. Listen to the old audio recording. ... more Duration: {{video.duration.momentjs}}. \"), ('1 Higher-end tile such as granite or marble is going to cost more than a standard ceramic tile. 2  On average, plan on spending anywhere from $2,500 to as much as $5,000 or more for a standard 3′ x 5′ shower. 3  Showers can widely vary in size, but most of the time the cost will be within this price range.', 'Ronald Reagan (1911-2004), a former actor and California governor, served as the 40th U.S. president from 1981 to 1989. Raised in small-town Illinois, he became a Hollywood actor in his 20s and later served as the Republican governor of California from 1967 to 1975. In November 1984, Ronald Reagan was reelected in a landslide, defeating Walter Mondale and his running mate Geraldine Ferraro (1935-), the first female vice-presidential candidate from a major U.S. political party.')]\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "for batch in data_loader:\n",
    "    anchor_texts = batch[0]\n",
    "    positive_texts = batch[1]\n",
    "    negative_texts = batch[2]\n",
    "    print(anchor_texts)\n",
    "    print(len(anchor_texts))\n",
    "    print(positive_texts)\n",
    "    print(len(positive_texts))\n",
    "    print(negative_texts)\n",
    "    print(len(negative_texts))\n",
    "    break\n",
    "    anchor_inputs = tokenizer(anchor_texts, return_tensors='pt', padding=True, truncation=True, max_length=512).to(device)\n",
    "    positive_inputs = tokenizer(positive_texts, return_tensors='pt', padding=True, truncation=True, max_length=512).to(device)\n",
    "\n",
    "    anchor_embedding = lora_model(**anchor_inputs).last_hidden_state[:, 0, :]\n",
    "    print(anchor_embedding)\n",
    "    print(anchor_embedding.shape)\n",
    "    positive_embedding = lora_model(**positive_inputs).last_hidden_state[:, 0, :]\n",
    "    negative_embedding = [lora_model(**tokenizer(neg, return_tensors='pt', padding=True, truncation=True, max_length=512).to(device)).last_hidden_state[:, 0, :] for neg in negative_texts]\n",
    "    print(negative_embedding)\n",
    "    print(len(negative_embedding))\n",
    "    pos_dist = cosine_distance(anchor_embedding, positive_embedding)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_embedding = torch.tensor([\n",
    "    [0.45, 0.15, -0.35],  # Similar to the first anchor\n",
    "    [-0.25, 0.38, 0.85]   # Similar to the second anchor\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_embedding = [torch.tensor([\n",
    "    [-0.1, 0.2, 0.9],  # Negatives for the first anchor\n",
    "     [0.8, -0.5, 0.1]]),\n",
    "     torch.tensor([[-0.3, -0.2, -0.4],\n",
    "     [0.1, -0.1, 0.5]]),\n",
    "    torch.tensor([[0.5, 0.6, -0.2],   # Negatives for the second anchor\n",
    "     [0.7, 0.3, -0.9]]),\n",
    "     torch.tensor([[-0.8, -0.6, 0.3],\n",
    "     [-0.4, 0.4, 0.2]]),\n",
    "     torch.tensor([[-0.9, -0.6, 0.3],\n",
    "     [-0.4, 0.4, 0.1]])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(negative_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([1.6037, 1.3335]),\n",
       " tensor([1.0788, 0.2774]),\n",
       " tensor([0.1899, 1.7267]),\n",
       " tensor([1.9018, 0.2704]),\n",
       " tensor([1.9068, 0.3915])]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[cosine_distance(anchor_embedding, neg) for neg in negative_embedding]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.6037, 1.0788, 0.1899, 1.9018, 1.9068],\n",
       "        [1.3335, 0.2774, 1.7267, 0.2704, 0.3915]])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack([cosine_distance(anchor_embedding, neg) for neg in negative_embedding],dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_embedding = torch.tensor([\n",
    "    [0.85, 0.15, -0.35],  # Similar to the first anchor\n",
    "    [-0.35, 0.38, 0.85]   # Similar to the second anchor\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_distance(anchor_embedding, positive_embedding).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0393],\n",
       "        [0.0047]])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_distance(anchor_embedding, positive_embedding).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_distance(anchor_embedding, positive_embedding).unsqueeze(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack([cosine_distance(anchor_embedding, neg) for neg in negative_embedding],dim=-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0393, -1.6037, -1.0788, -0.1899, -1.9018, -1.9068],\n",
       "        [-0.0047, -1.3335, -0.2774, -1.7267, -0.2704, -0.3915]])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([-cosine_distance(anchor_embedding, positive_embedding).unsqueeze(1), -torch.stack([cosine_distance(anchor_embedding, neg) for neg in negative_embedding],dim=-1)], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0393, -1.6037, -1.0788, -0.1899, -1.9018, -1.9068],\n",
       "        [-0.0047, -1.3335, -0.2774, -1.7267, -0.2704, -0.3915]])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([-cosine_distance(anchor_embedding, positive_embedding).unsqueeze(1), -torch.stack([cosine_distance(anchor_embedding, neg) for neg in negative_embedding],dim=-1)], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(2, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.1501)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.CrossEntropyLoss()(torch.cat([-cosine_distance(anchor_embedding, positive_embedding).unsqueeze(1), -torch.stack([cosine_distance(anchor_embedding, neg) for neg in negative_embedding],dim=-1)], dim=1), torch.zeros(2, dtype=torch.long))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def info_nce_loss(anchor_embedding, positive_embedding, negative_embedding, distance_fn):\n",
    "\n",
    "    pos_dist = distance_fn(anchor_embedding, positive_embedding) \n",
    "    neg_dist = torch.stack([distance_fn(anchor_embedding, neg) for neg in negative_embedding], dim=-1) \n",
    "    \n",
    "    logits = torch.cat([-pos_dist.unsqueeze(1), -neg_dist], dim=1)\n",
    "    labels = torch.zeros(logits.size(0), dtype=torch.long, device=logits.device) \n",
    "\n",
    "    loss = torch.nn.CrossEntropyLoss()(logits, labels)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "optimizer = torch.optim.AdamW(lora_model.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PeftModelForFeatureExtraction(\n",
      "  (base_model): LoraModel(\n",
      "    (model): BertModel(\n",
      "      (embeddings): BertEmbeddings(\n",
      "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "        (position_embeddings): Embedding(512, 768)\n",
      "        (token_type_embeddings): Embedding(2, 768)\n",
      "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (encoder): BertEncoder(\n",
      "        (layer): ModuleList(\n",
      "          (0-11): 12 x BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): lora.Linear(\n",
      "                  (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (lora_dropout): ModuleDict(\n",
      "                    (default): Identity()\n",
      "                  )\n",
      "                  (lora_A): ModuleDict(\n",
      "                    (default): Linear(in_features=768, out_features=8, bias=False)\n",
      "                  )\n",
      "                  (lora_B): ModuleDict(\n",
      "                    (default): Linear(in_features=8, out_features=768, bias=False)\n",
      "                  )\n",
      "                  (lora_embedding_A): ParameterDict()\n",
      "                  (lora_embedding_B): ParameterDict()\n",
      "                  (lora_magnitude_vector): ModuleDict()\n",
      "                )\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): lora.Linear(\n",
      "                  (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (lora_dropout): ModuleDict(\n",
      "                    (default): Identity()\n",
      "                  )\n",
      "                  (lora_A): ModuleDict(\n",
      "                    (default): Linear(in_features=768, out_features=8, bias=False)\n",
      "                  )\n",
      "                  (lora_B): ModuleDict(\n",
      "                    (default): Linear(in_features=8, out_features=768, bias=False)\n",
      "                  )\n",
      "                  (lora_embedding_A): ParameterDict()\n",
      "                  (lora_embedding_B): ParameterDict()\n",
      "                  (lora_magnitude_vector): ModuleDict()\n",
      "                )\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (pooler): BertPooler(\n",
      "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (activation): Tanh()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(lora_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Results-Based Accountability® (also known as RBA) is a disciplined way of thinking and taking action that communities can use to improve the lives of children, youth, families, adults and the community as a whole. RBA is also used by organizations to improve the performance of their programs. Creating Community Impact with RBA. Community impact focuses on conditions of well-being for children, families and the community as a whole that a group of leaders is working collectively to improve. For example: “Residents with good jobs,” “Children ready for school,” or “A safe and clean neighborhood”.'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_data[0]['positive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  3463,  1011,  2241, 17842, 29656,  1006,  2036,  2124,  2004,\n",
       "         21144,  2050,  1007,  2003,  1037, 28675,  2126,  1997,  3241,  1998,\n",
       "          2635,  2895,  2008,  4279,  2064,  2224,  2000,  5335,  1996,  3268,\n",
       "          1997,  2336,  1010,  3360,  1010,  2945,  1010,  6001,  1998,  1996,\n",
       "          2451,  2004,  1037,  2878,  1012, 21144,  2050,  2003,  2036,  2109,\n",
       "          2011,  4411,  2000,  5335,  1996,  2836,  1997,  2037,  3454,  1012,\n",
       "          4526,  2451,  4254,  2007, 21144,  2050,  1012,  2451,  4254,  7679,\n",
       "          2006,  3785,  1997,  2092,  1011,  2108,  2005,  2336,  1010,  2945,\n",
       "          1998,  1996,  2451,  2004,  1037,  2878,  2008,  1037,  2177,  1997,\n",
       "          4177,  2003,  2551, 13643,  2000,  5335,  1012,  2005,  2742,  1024,\n",
       "          1523,  3901,  2007,  2204,  5841,  1010,  1524,  1523,  2336,  3201,\n",
       "          2005,  2082,  1010,  1524,  2030,  1523,  1037,  3647,  1998,  4550,\n",
       "          5101,  1524,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(processed_data[0]['positive'], return_tensors='pt', padding=True, truncation=True, max_length=512).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2, Loss: 1.802066683769226\n",
      "Epoch 2/2, Loss: 1.7613139748573303\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()  \n",
    "    \n",
    "    total_loss = 0.0\n",
    "    for batch in data_loader:\n",
    "       \n",
    "        anchor_texts = batch[0]\n",
    "        positive_texts = batch[1]\n",
    "        negative_texts = batch[2]\n",
    "        \n",
    "        anchor_inputs = tokenizer(anchor_texts, return_tensors='pt', padding=True, truncation=True, max_length=512).to(device)\n",
    "        positive_inputs = tokenizer(positive_texts, return_tensors='pt', padding=True, truncation=True, max_length=512).to(device)\n",
    "    \n",
    "        anchor_embedding = lora_model(**anchor_inputs).last_hidden_state[:, 0, :]\n",
    "        positive_embedding = lora_model(**positive_inputs).last_hidden_state[:, 0, :]\n",
    "        negative_embedding = [lora_model(**tokenizer(neg, return_tensors='pt', padding=True, truncation=True, max_length=512).to(device)).last_hidden_state[:, 0, :] for neg in negative_texts]\n",
    "\n",
    "        loss = info_nce_loss(anchor_embedding, positive_embedding, negative_embedding, distance_fn=cosine_distance)\n",
    "        \n",
    "        optimizer.zero_grad()  \n",
    "        loss.backward()  \n",
    "        optimizer.step()  \n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss / len(data_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
