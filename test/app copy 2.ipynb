{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset('ms_marco', 'v1.1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    validation: Dataset({\n",
       "        features: ['answers', 'passages', 'query', 'query_id', 'query_type', 'wellFormedAnswers'],\n",
       "        num_rows: 10047\n",
       "    })\n",
       "    train: Dataset({\n",
       "        features: ['answers', 'passages', 'query', 'query_id', 'query_type', 'wellFormedAnswers'],\n",
       "        num_rows: 82326\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['answers', 'passages', 'query', 'query_id', 'query_type', 'wellFormedAnswers'],\n",
       "        num_rows: 9650\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset('ms_marco', 'v1.1', split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['answers', 'passages', 'query', 'query_id', 'query_type', 'wellFormedAnswers'],\n",
       "    num_rows: 82326\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datasets.arrow_dataset.Dataset"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(example):\n",
    "    positive_passages=[]\n",
    "    for p in enumerate(example['passages'][\"is_selected\"]):\n",
    "        if p[1]==1:\n",
    "            positive_passages.append(example[\"passages\"][\"passage_text\"][p[0]])\n",
    "    negative_passages = []\n",
    "    for p in enumerate(example['passages'][\"is_selected\"]):\n",
    "        if p[1]==0:\n",
    "            negative_passages.append(example[\"passages\"][\"passage_text\"][p[0]])\n",
    "    if (len(positive_passages)>0 and len(negative_passages)>=5):\n",
    "        positive = positive_passages[0]\n",
    "        negatives = negative_passages[:5]\n",
    "        return {\n",
    "            \"query\": example[\"query\"],\n",
    "            \"positive\": positive,\n",
    "            \"negatives\": negatives\n",
    "        }\n",
    "    else:\n",
    "        return {\"query\": None, \"positive\": None, \"negatives\": None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = dataset.map(preprocess, remove_columns=dataset.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data = processed_data.filter(lambda x: x['query'] is not None and x['positive'] is not None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "contrastive_pairs = []\n",
    "for item in processed_data:\n",
    "    query = item[\"query\"]\n",
    "    positive = item[\"positive\"]\n",
    "    negatives = item[\"negatives\"]\n",
    "    contrastive_pairs.append({\n",
    "        \"anchor\": query,\n",
    "        \"positive\": positive,\n",
    "        \"negatives\": negatives\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74538"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(contrastive_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrastiveDataset:\n",
    "    def __init__(self, pairs):\n",
    "        self.pairs = pairs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.pairs[idx]\n",
    "        return item[\"anchor\"], item[\"positive\"], item[\"negatives\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "contrastive_dataset = ContrastiveDataset(contrastive_pairs[0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_loader = DataLoader(contrastive_dataset, batch_size=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\huggingface_hub\\file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = AutoModel.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_config = LoraConfig(\n",
    "    task_type= \"FEATURE_EXTRACTION\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The installed version of bitsandbytes was compiled without GPU support. 8-bit optimizers, 8-bit multiplication, and GPU quantization are unavailable.\n"
     ]
    }
   ],
   "source": [
    "lora_model = get_peft_model(model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 294,912 || all params: 109,777,152 || trainable%: 0.2686\n"
     ]
    }
   ],
   "source": [
    "lora_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_embedding = torch.tensor([\n",
    "    [0.45, 0.15, -0.35],  # Similar to the first anchor\n",
    "    [-0.25, 0.38, 0.85]   # Similar to the second anchor\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchor_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.tensor([\n",
    "    [7.0, 8.0, 9.0],  # First vector\n",
    "    [10.0, 11.0, 12.0] # Second vector\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_embedding = [torch.tensor([\n",
    "    [-0.1, 0.2, 0.9],  # Negatives for the first anchor\n",
    "     [0.8, -0.5, 0.1]]),\n",
    "     torch.tensor([[-0.3, -0.2, -0.4],\n",
    "     [0.1, -0.1, 0.5]]),\n",
    "    torch.tensor([[0.5, 0.6, -0.2],   # Negatives for the second anchor\n",
    "     [0.7, 0.3, -0.9]]),\n",
    "     torch.tensor([[-0.8, -0.6, 0.3],\n",
    "     [-0.4, 0.4, 0.2]]),\n",
    "     torch.tensor([[-0.9, -0.6, 0.3],\n",
    "     [-0.4, 0.4, 0.1]])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_embeddings = []\n",
    "\n",
    "for i in range(len(anchor_embedding)): \n",
    "    sample_embeddings = torch.cat(\n",
    "        [anchor_embedding[i:i+1],  \n",
    "         y[i:i+1],  \n",
    "         torch.stack([neg[i] for neg in negative_embedding])],\n",
    "        dim=0\n",
    "    )\n",
    "    batch_embeddings.append(sample_embeddings)\n",
    "\n",
    "all_embeddings = torch.cat(batch_embeddings, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4500,  0.1500, -0.3500],\n",
       "        [ 7.0000,  8.0000,  9.0000],\n",
       "        [-0.1000,  0.2000,  0.9000],\n",
       "        [-0.3000, -0.2000, -0.4000],\n",
       "        [ 0.5000,  0.6000, -0.2000],\n",
       "        [-0.8000, -0.6000,  0.3000],\n",
       "        [-0.9000, -0.6000,  0.3000],\n",
       "        [-0.2500,  0.3800,  0.8500],\n",
       "        [10.0000, 11.0000, 12.0000],\n",
       "        [ 0.8000, -0.5000,  0.1000],\n",
       "        [ 0.1000, -0.1000,  0.5000],\n",
       "        [ 0.7000,  0.3000, -0.9000],\n",
       "        [-0.4000,  0.4000,  0.2000],\n",
       "        [-0.4000,  0.4000,  0.1000]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim=cosine_similarity(all_embeddings, all_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.00000000e+00,  1.46151394e-01, -6.03652894e-01,\n",
       "        -7.87523612e-02,  8.10077667e-01, -9.01783586e-01,\n",
       "        -9.06752169e-01, -6.21149242e-01,  1.73145324e-01,\n",
       "         4.47034836e-01, -4.73378688e-01,  9.71223056e-01,\n",
       "        -5.37186265e-01, -4.57717270e-01],\n",
       "       [ 1.46151394e-01,  9.99999940e-01,  6.96774721e-01,\n",
       "        -9.73246753e-01,  5.78836381e-01, -5.29513001e-01,\n",
       "        -5.37270665e-01,  6.65787041e-01,  9.99618590e-01,\n",
       "         1.89198583e-01,  6.07952893e-01, -4.87171337e-02,\n",
       "         2.63251334e-01,  1.62474632e-01],\n",
       "       [-6.03652894e-01,  6.96774721e-01,  9.99999940e-01,\n",
       "        -7.40889490e-01, -1.47125080e-01,  2.37555638e-01,\n",
       "         2.30556175e-01,  9.68650997e-01,  6.77307069e-01,\n",
       "        -1.02299146e-01,  8.71601939e-01, -7.49993026e-01,\n",
       "         5.39163828e-01,  3.94196808e-01],\n",
       "       [-7.87523612e-02, -9.73246753e-01, -7.40889490e-01,\n",
       "         9.99999881e-01, -4.37620789e-01,  4.26873296e-01,\n",
       "         4.46662486e-01, -6.56831563e-01, -9.71973777e-01,\n",
       "        -3.52332145e-01, -7.50478745e-01,  1.41754240e-01,\n",
       "        -1.23796850e-01,  2.50568313e-08],\n",
       "       [ 8.10077667e-01,  5.78836381e-01, -1.47125080e-01,\n",
       "        -4.37620789e-01,  1.00000012e+00, -9.74190593e-01,\n",
       "        -9.61340785e-01, -8.62018839e-02,  5.97289324e-01,\n",
       "         1.04595296e-01, -2.62575477e-01,  7.46954799e-01,\n",
       "         1.23792780e-08,  4.31833751e-02],\n",
       "       [-9.01783586e-01, -5.29513001e-01,  2.37555638e-01,\n",
       "         4.26873296e-01, -9.74190593e-01,  1.00000000e+00,\n",
       "         9.98360455e-01,  2.25533620e-01, -5.51484108e-01,\n",
       "        -3.12987685e-01,  2.39633888e-01, -8.20541918e-01,\n",
       "         2.23492786e-01,  1.83409750e-01],\n",
       "       [-9.06752169e-01, -5.37270665e-01,  2.30556175e-01,\n",
       "         4.46662486e-01, -9.61340785e-01,  9.98360455e-01,\n",
       "         1.00000012e+00,  2.32870221e-01, -5.59563696e-01,\n",
       "        -3.66233528e-01,  2.05737829e-01, -8.16076994e-01,\n",
       "         2.67261207e-01,  2.32621029e-01],\n",
       "       [-6.21149242e-01,  6.65787041e-01,  9.68650997e-01,\n",
       "        -6.56831563e-01, -8.62018839e-02,  2.25533620e-01,\n",
       "         2.32870221e-01,  1.00000000e+00,  6.45013332e-01,\n",
       "        -3.33485723e-01,  7.22645640e-01, -7.26727068e-01,\n",
       "         7.29558051e-01,  6.08515441e-01],\n",
       "       [ 1.73145324e-01,  9.99618590e-01,  6.77307069e-01,\n",
       "        -9.71973777e-01,  5.97289324e-01, -5.51484108e-01,\n",
       "        -5.59563696e-01,  6.45013332e-01,  1.00000012e+00,\n",
       "         2.04142794e-01,  5.94324648e-01, -2.21981388e-02,\n",
       "         2.44264513e-01,  1.45786300e-01],\n",
       "       [ 4.47034836e-01,  1.89198583e-01, -1.02299146e-01,\n",
       "        -3.52332145e-01,  1.04595296e-01, -3.12987685e-01,\n",
       "        -3.66233528e-01, -3.33485723e-01,  2.04142794e-01,\n",
       "         1.00000000e+00,  3.65148395e-01,  2.86102265e-01,\n",
       "        -8.78410399e-01, -9.35819209e-01],\n",
       "       [-4.73378688e-01,  6.07952893e-01,  8.71601939e-01,\n",
       "        -7.50478745e-01, -2.62575477e-01,  2.39633888e-01,\n",
       "         2.05737829e-01,  7.22645640e-01,  5.94324648e-01,\n",
       "         3.65148395e-01,  1.00000000e+00, -6.69259608e-01,\n",
       "         6.41500279e-02, -1.00503772e-01],\n",
       "       [ 9.71223056e-01, -4.87171337e-02, -7.49993026e-01,\n",
       "         1.41754240e-01,  7.46954799e-01, -8.20541918e-01,\n",
       "        -8.16076994e-01, -7.26727068e-01, -2.21981388e-02,\n",
       "         2.86102265e-01, -6.69259608e-01,  1.00000024e+00,\n",
       "        -4.80640382e-01, -3.69126856e-01],\n",
       "       [-5.37186265e-01,  2.63251334e-01,  5.39163828e-01,\n",
       "        -1.23796850e-01,  1.23792780e-08,  2.23492786e-01,\n",
       "         2.67261207e-01,  7.29558051e-01,  2.44264513e-01,\n",
       "        -8.78410399e-01,  6.41500279e-02, -4.80640382e-01,\n",
       "         9.99999881e-01,  9.86440003e-01],\n",
       "       [-4.57717270e-01,  1.62474632e-01,  3.94196808e-01,\n",
       "         2.50568313e-08,  4.31833751e-02,  1.83409750e-01,\n",
       "         2.32621029e-01,  6.08515441e-01,  1.45786300e-01,\n",
       "        -9.35819209e-01, -1.00503772e-01, -3.69126856e-01,\n",
       "         9.86440003e-01,  1.00000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14, 14)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "degree_matrix = np.diag(np.sum(sim, axis=1))\n",
    "laplacian_matrix = degree_matrix - sim\n",
    "laplacian_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14, 14)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "laplacian_pseudo_inv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-0.5, 0.0, -0.5, 0.5, -1.5, -1.5], [0.5, 0.0, 0.5, -0.5, 0.5, 0.5]]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "harmonic_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5000,  0.0000, -0.5000,  0.5000, -1.5000, -1.5000],\n",
       "        [ 0.5000,  0.0000,  0.5000, -0.5000,  0.5000,  0.5000]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(harmonic_distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(-torch.tensor(harmonic_distances)).size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.45,  0.15, -0.35],\n",
       "        [-0.25,  0.38,  0.85]],\n",
       "\n",
       "       [[ 7.  ,  8.  ,  9.  ],\n",
       "        [10.  , 11.  , 12.  ]],\n",
       "\n",
       "       [[-0.1 ,  0.2 ,  0.9 ],\n",
       "        [ 0.8 , -0.5 ,  0.1 ]],\n",
       "\n",
       "       [[-0.3 , -0.2 , -0.4 ],\n",
       "        [ 0.1 , -0.1 ,  0.5 ]],\n",
       "\n",
       "       [[ 0.5 ,  0.6 , -0.2 ],\n",
       "        [ 0.7 ,  0.3 , -0.9 ]],\n",
       "\n",
       "       [[-0.8 , -0.6 ,  0.3 ],\n",
       "        [-0.4 ,  0.4 ,  0.2 ]],\n",
       "\n",
       "       [[-0.9 , -0.6 ,  0.3 ],\n",
       "        [-0.4 ,  0.4 ,  0.1 ]]], dtype=float32)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_distance(x, y):\n",
    "    return 1 - torch.nn.functional.cosine_similarity(x, y, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('how long do you need for sydney and surrounding areas', 'was ronald reagan a democrat')\n",
      "[('Sydney, New South Wales, Australia is located in a coastal basin bordered by the Pacific Ocean to the east, the Blue Mountains to the west, the Hawkesbury River to the north and the Woronora Plateau to the south. The Sydney Statistical Division, used for census data, is the unofficial metropolitan area and covers 12,145 km² (4,689 mi²). This area includes the Central Coast and Blue Mountains as well as broad swathes of national park and other non-urban land.', 'In his younger years, Ronald Reagan was a member of the Democratic Party and campaigned for Democratic candidates; however, his views grew more conservative over time, and in the early 1960s he officially became a Republican. In November 1984, Ronald Reagan was reelected in a landslide, defeating Walter Mondale and his running mate Geraldine Ferraro (1935-), the first female vice-presidential candidate from a major U.S. political party.'), ('This itinerary will have you crossing the country to take in the Great Barrier Reef, Australia’s iconic reef in Queensland, before heading to Western Australia to see the breath taking Ningaloo Reef, one of Australia’s best kept secrets. View more information. 10 day-Sydney, rock and reef. It’s easy to see why Hamilton Island is one of the most popular spots for a getaway on the Great Barrier Reef. With palm-fringed beaches, top restaurants and stylish resorts, there’s plenty to do on land, while those keen to explore the clear waters of the Whitsundays will be richly rewarded.', 'Ronald Reagan began his political life in the Democratic Party, but as he became more and more conservative, he ultimately changed to the Republican Party in the early 1960s. Yes, he switched parties in 1962. He said that he did not desert the Democrats but rather they deserted him. Yes, Ronald Reagan was a member of the Democratic Party until he s … witched to the Republican Party in 1962, at the age of 51. 8 people found this useful.'), (\"The Sydney central business district, Sydney harbour and outer suburbs from the West. North Sydney 's commercial district. The extensive area covered by urban Sydney is formally divided into more than 300 suburbs for addressing and postal purposes, and administered as 38 local government areas. The Sydney Statistical Division, used for census data, is the unofficial metropolitan area and covers 12,145 km² (4,689 mi²). This area includes the Central Coast and Blue Mountains as well as broad swathes of national park and other non-urban land.\", 'Ronald Wilson Reagan (/ˈrɒnəld ˈwɪlsən ˈreɪɡən/ ; February 6, 1911 – June 5, 2004) was an American politician, commentator, and actor, who served as the 40th President of the United States from 1981 to 1989. I think Ronald Reagan changed the trajectory of America in a way that Richard Nixon did not and in a way that Bill Clinton did not. He put us on a fundamentally different path because the country was ready for it.'), (\"1 Taxis to the city centre should cost approximately $40 (including tolls), and more to other Sydney destinations (The Rocks $40-45, North Sydney $45, Manly $50, Parramatta $80-100 etc.) You can expect to pay a $3.80 airport taxi levy and a $5.50 Eastern Distributor toll on top of the metered fare. Newtown in Sydney's inner-west (approx 4km from the CBD) is renowned for its inexpensive cafes and restaurants on King St, in particular Thai food. It is highly popular among students from the nearby Sydney University.\", \"When Reagan was a 'liberal Democrat'. In 1948, a very different sounding Ronald Reagan campaigned on the radio for Democrat Harry Truman. Listen to the old audio recording. ... more Duration: {{video.duration.momentjs}}. \"), ('Sydney Attractions. Sydney is home to some of Australia’s most iconic attractions. The Sydney Opera House is a thriving hub of art, culture and history. 1km (return) - 1.5 hour (each way)Step out of your car and into the past. This short walk, perfect for walking with children and for visitors with ties to the local area, pulls you back thro... http://www.nationalparks.nsw.gov.au/scheyville-national-park/migrant-heritage-walk/walking.', 'Ronald Reagan (1911-2004), a former actor and California governor, served as the 40th U.S. president from 1981 to 1989. Raised in small-town Illinois, he became a Hollywood actor in his 20s and later served as the Republican governor of California from 1967 to 1975. In November 1984, Ronald Reagan was reelected in a landslide, defeating Walter Mondale and his running mate Geraldine Ferraro (1935-), the first female vice-presidential candidate from a major U.S. political party.')]\n"
     ]
    }
   ],
   "source": [
    "for batch in data_loader:\n",
    "    anchor_texts = batch[0]\n",
    "    positive_texts = batch[1]\n",
    "    negative_texts = batch[2]\n",
    "    print(anchor_texts)\n",
    "    print(len(anchor_texts))\n",
    "    print(positive_texts)\n",
    "    print(len(positive_texts))\n",
    "    print(negative_texts)\n",
    "    print(len(negative_texts))\n",
    "    anchor_inputs = tokenizer(anchor_texts, return_tensors='pt', padding=True, truncation=True, max_length=512).to(device)\n",
    "    positive_inputs = tokenizer(positive_texts, return_tensors='pt', padding=True, truncation=True, max_length=512).to(device)\n",
    "\n",
    "    anchor_embedding = lora_model(**anchor_inputs).last_hidden_state[:, 0, :]\n",
    "    print(anchor_embedding)\n",
    "    print(anchor_embedding.shape)\n",
    "    positive_embedding = lora_model(**positive_inputs).last_hidden_state[:, 0, :]\n",
    "    negative_embedding = [lora_model(**tokenizer(neg, return_tensors='pt', padding=True, truncation=True, max_length=512).to(device)).last_hidden_state[:, 0, :] for neg in negative_texts]\n",
    "    print(negative_embedding)\n",
    "    print(len(negative_embedding))\n",
    "    pos_dist = cosine_distance(anchor_embedding, positive_embedding)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'anchor': 'what is rba',\n",
       " 'positive': 'Results-Based Accountability® (also known as RBA) is a disciplined way of thinking and taking action that communities can use to improve the lives of children, youth, families, adults and the community as a whole. RBA is also used by organizations to improve the performance of their programs. Creating Community Impact with RBA. Community impact focuses on conditions of well-being for children, families and the community as a whole that a group of leaders is working collectively to improve. For example: “Residents with good jobs,” “Children ready for school,” or “A safe and clean neighborhood”.',\n",
       " 'negatives': [\"Since 2007, the RBA's outstanding reputation has been affected by the 'Securency' or NPA scandal. These RBA subsidiaries were involved in bribing overseas officials so that Australia might win lucrative note-printing contracts. The assets of the bank include the gold and foreign exchange reserves of Australia, which is estimated to have a net worth of A$101 billion. Nearly 94% of the RBA's employees work at its headquarters in Sydney, New South Wales and at the Business Resumption Site.\",\n",
       "  \"The Reserve Bank of Australia (RBA) came into being on 14 January 1960 as Australia 's central bank and banknote issuing authority, when the Reserve Bank Act 1959 removed the central banking functions from the Commonwealth Bank. The assets of the bank include the gold and foreign exchange reserves of Australia, which is estimated to have a net worth of A$101 billion. Nearly 94% of the RBA's employees work at its headquarters in Sydney, New South Wales and at the Business Resumption Site.\",\n",
       "  'RBA Recognized with the 2014 Microsoft US Regional Partner of the ... by PR Newswire. Contract Awarded for supply and support the. Securitisations System used for risk management and analysis. ',\n",
       "  'The inner workings of a rebuildable atomizer are surprisingly simple. The coil inside the RBA is made of some type of resistance wire, normally Kanthal or nichrome. When a current is applied to the coil (resistance wire), it heats up and the heated coil then vaporizes the eliquid. 1 The bottom feed RBA is, perhaps, the easiest of all RBA types to build, maintain, and use. 2  It is filled from below, much like bottom coil clearomizer. 3  Bottom feed RBAs can utilize cotton instead of silica for the wick. 4  The Genesis, or genny, is a top feed RBA that utilizes a short woven mesh wire.',\n",
       "  'Results-Based Accountability® (also known as RBA) is a disciplined way of thinking and taking action that communities can use to improve the lives of children, youth, families, adults and the community as a whole. RBA is also used by organizations to improve the performance of their programs. RBA improves the lives of children, families, and communities and the performance of programs because RBA: 1  Gets from talk to action quickly; 2  Is a simple, common sense process that everyone can understand; 3  Helps groups to surface and challenge assumptions that can be barriers to innovation;']}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contrastive_pairs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def info_nce_loss(anchor_embedding, positive_embedding, negative_embedding, distance_fn):\n",
    "    pos_dist = distance_fn(anchor_embedding, positive_embedding) \n",
    "    neg_dist = torch.stack([distance_fn(anchor_embedding, neg) for neg in negative_embedding], dim=-1)\n",
    "    \n",
    "    logits = torch.cat([-pos_dist.unsqueeze(1), -neg_dist], dim=1)\n",
    "    labels = torch.zeros(logits.size(0), dtype=torch.long, device=logits.device) \n",
    "\n",
    "    loss = torch.nn.CrossEntropyLoss()(logits, labels)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_dist = cosine_distance(anchor_embedding, y)  \n",
    "neg_dist = torch.stack([cosine_distance(anchor_embedding, neg) for neg in negative_embedding], dim=-1) \n",
    "\n",
    "logits = torch.cat([-pos_dist.unsqueeze(1), -neg_dist], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 6])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "optimizer = torch.optim.AdamW(lora_model.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PeftModelForFeatureExtraction(\n",
      "  (base_model): LoraModel(\n",
      "    (model): BertModel(\n",
      "      (embeddings): BertEmbeddings(\n",
      "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "        (position_embeddings): Embedding(512, 768)\n",
      "        (token_type_embeddings): Embedding(2, 768)\n",
      "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (encoder): BertEncoder(\n",
      "        (layer): ModuleList(\n",
      "          (0-11): 12 x BertLayer(\n",
      "            (attention): BertAttention(\n",
      "              (self): BertSelfAttention(\n",
      "                (query): lora.Linear(\n",
      "                  (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (lora_dropout): ModuleDict(\n",
      "                    (default): Identity()\n",
      "                  )\n",
      "                  (lora_A): ModuleDict(\n",
      "                    (default): Linear(in_features=768, out_features=8, bias=False)\n",
      "                  )\n",
      "                  (lora_B): ModuleDict(\n",
      "                    (default): Linear(in_features=8, out_features=768, bias=False)\n",
      "                  )\n",
      "                  (lora_embedding_A): ParameterDict()\n",
      "                  (lora_embedding_B): ParameterDict()\n",
      "                  (lora_magnitude_vector): ModuleDict()\n",
      "                )\n",
      "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (value): lora.Linear(\n",
      "                  (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
      "                  (lora_dropout): ModuleDict(\n",
      "                    (default): Identity()\n",
      "                  )\n",
      "                  (lora_A): ModuleDict(\n",
      "                    (default): Linear(in_features=768, out_features=8, bias=False)\n",
      "                  )\n",
      "                  (lora_B): ModuleDict(\n",
      "                    (default): Linear(in_features=8, out_features=768, bias=False)\n",
      "                  )\n",
      "                  (lora_embedding_A): ParameterDict()\n",
      "                  (lora_embedding_B): ParameterDict()\n",
      "                  (lora_magnitude_vector): ModuleDict()\n",
      "                )\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): BertSelfOutput(\n",
      "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): BertIntermediate(\n",
      "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): BertOutput(\n",
      "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (pooler): BertPooler(\n",
      "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "        (activation): Tanh()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(lora_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Results-Based Accountability® (also known as RBA) is a disciplined way of thinking and taking action that communities can use to improve the lives of children, youth, families, adults and the community as a whole. RBA is also used by organizations to improve the performance of their programs. Creating Community Impact with RBA. Community impact focuses on conditions of well-being for children, families and the community as a whole that a group of leaders is working collectively to improve. For example: “Residents with good jobs,” “Children ready for school,” or “A safe and clean neighborhood”.'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_data[0]['positive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  3463,  1011,  2241, 17842, 29656,  1006,  2036,  2124,  2004,\n",
       "         21144,  2050,  1007,  2003,  1037, 28675,  2126,  1997,  3241,  1998,\n",
       "          2635,  2895,  2008,  4279,  2064,  2224,  2000,  5335,  1996,  3268,\n",
       "          1997,  2336,  1010,  3360,  1010,  2945,  1010,  6001,  1998,  1996,\n",
       "          2451,  2004,  1037,  2878,  1012, 21144,  2050,  2003,  2036,  2109,\n",
       "          2011,  4411,  2000,  5335,  1996,  2836,  1997,  2037,  3454,  1012,\n",
       "          4526,  2451,  4254,  2007, 21144,  2050,  1012,  2451,  4254,  7679,\n",
       "          2006,  3785,  1997,  2092,  1011,  2108,  2005,  2336,  1010,  2945,\n",
       "          1998,  1996,  2451,  2004,  1037,  2878,  2008,  1037,  2177,  1997,\n",
       "          4177,  2003,  2551, 13643,  2000,  5335,  1012,  2005,  2742,  1024,\n",
       "          1523,  3901,  2007,  2204,  5841,  1010,  1524,  1523,  2336,  3201,\n",
       "          2005,  2082,  1010,  1524,  2030,  1523,  1037,  3647,  1998,  4550,\n",
       "          5101,  1524,  1012,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(processed_data[0]['positive'], return_tensors='pt', padding=True, truncation=True, max_length=512).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_laplacian(similarity_matrix):\n",
    "\n",
    "    degree_matrix = np.diag(np.sum(similarity_matrix, axis=1))\n",
    "    laplacian_matrix = degree_matrix - similarity_matrix  \n",
    "    return laplacian_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def harmonic_distance(laplacian_matrix):\n",
    "    laplacian_pseudo_inv = np.linalg.pinv(laplacian_matrix)\n",
    "    harmonic_distances = []\n",
    "    for anchor_idx in range(0, len(laplacian_matrix), 7):  \n",
    "        \n",
    "        anchor_node=np.zeros(len(laplacian_matrix))\n",
    "        anchor_node[anchor_idx] = 1\n",
    "\n",
    "        distances = []\n",
    "        for i in range(7-1):\n",
    "            node=np.zeros(len(laplacian_matrix))\n",
    "            node[anchor_idx+(i+1)] = 1\n",
    "            dist = np.dot(np.dot((anchor_node - node).T, laplacian_pseudo_inv), (anchor_node - node))\n",
    "            distances.append(dist)\n",
    "        \n",
    "        harmonic_distances.append(distances)\n",
    "    return(harmonic_distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def harmonic_loss(anchor_embedding, positive_embedding, negative_embedding):\n",
    "    batch_embeddings = []\n",
    "\n",
    "    for i in range(len(anchor_embedding)):  \n",
    "        sample_embeddings = torch.cat(\n",
    "            [anchor_embedding[i:i+1],  \n",
    "            positive_embedding[i:i+1],  \n",
    "            torch.stack([neg[i] for neg in negative_embedding])],  \n",
    "            dim=0\n",
    "        )\n",
    "        batch_embeddings.append(sample_embeddings)\n",
    "\n",
    "    all_embeddings = torch.cat(batch_embeddings, dim=0)\n",
    "    sim=cosine_similarity(all_embeddings, all_embeddings)\n",
    "    laplacian = compute_laplacian(sim)\n",
    "    loss=harmonic_distance(laplacian)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2, Loss: 1.802066683769226\n",
      "Epoch 2/2, Loss: 1.7613139748573303\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train() \n",
    "    \n",
    "    total_loss = 0.0\n",
    "    for batch in data_loader:\n",
    "       \n",
    "        anchor_texts = batch[0]\n",
    "        positive_texts = batch[1]\n",
    "        negative_texts = batch[2]\n",
    "     \n",
    "        anchor_inputs = tokenizer(anchor_texts, return_tensors='pt', padding=True, truncation=True, max_length=512).to(device)\n",
    "        positive_inputs = tokenizer(positive_texts, return_tensors='pt', padding=True, truncation=True, max_length=512).to(device)\n",
    "    \n",
    "        anchor_embedding = lora_model(**anchor_inputs).last_hidden_state[:, 0, :]\n",
    "        positive_embedding = lora_model(**positive_inputs).last_hidden_state[:, 0, :]\n",
    "        negative_embedding = [lora_model(**tokenizer(neg, return_tensors='pt', padding=True, truncation=True, max_length=512).to(device)).last_hidden_state[:, 0, :] for neg in negative_texts]\n",
    "\n",
    "        loss = harmonic_loss(anchor_embedding, positive_embedding, negative_embedding)\n",
    "        \n",
    "        optimizer.zero_grad()  \n",
    "        loss.backward() \n",
    "        optimizer.step() \n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss / len(data_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
