{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c643a105",
   "metadata": {
    "papermill": {
     "duration": 6.998238,
     "end_time": "2025-02-03T01:37:35.734856",
     "exception": false,
     "start_time": "2025-02-03T01:37:28.736618",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcba0194",
   "metadata": {
    "papermill": {
     "duration": 2.374298,
     "end_time": "2025-02-03T01:37:38.118381",
     "exception": false,
     "start_time": "2025-02-03T01:37:35.744083",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"CShorten/ML-ArXiv-Papers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c77ff31",
   "metadata": {
    "papermill": {
     "duration": 0.011238,
     "end_time": "2025-02-03T01:37:38.140062",
     "exception": false,
     "start_time": "2025-02-03T01:37:38.128824",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Unnamed: 0.1', 'Unnamed: 0', 'title', 'abstract'],\n",
       "        num_rows: 117592\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04a2a273",
   "metadata": {
    "papermill": {
     "duration": 0.047292,
     "end_time": "2025-02-03T01:37:38.192133",
     "exception": false,
     "start_time": "2025-02-03T01:37:38.144841",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "split_datasets = dataset[\"train\"].train_test_split(test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9dbe1eb6",
   "metadata": {
    "papermill": {
     "duration": 0.009377,
     "end_time": "2025-02-03T01:37:38.206374",
     "exception": false,
     "start_time": "2025-02-03T01:37:38.196997",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Unnamed: 0.1', 'Unnamed: 0', 'title', 'abstract'],\n",
       "        num_rows: 94073\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Unnamed: 0.1', 'Unnamed: 0', 'title', 'abstract'],\n",
       "        num_rows: 23519\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e518138",
   "metadata": {
    "papermill": {
     "duration": 0.008713,
     "end_time": "2025-02-03T01:37:38.219967",
     "exception": false,
     "start_time": "2025-02-03T01:37:38.211254",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_train = split_datasets[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f892510",
   "metadata": {
    "papermill": {
     "duration": 0.009058,
     "end_time": "2025-02-03T01:37:38.233944",
     "exception": false,
     "start_time": "2025-02-03T01:37:38.224886",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['Unnamed: 0.1', 'Unnamed: 0', 'title', 'abstract'],\n",
       "    num_rows: 94073\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "135d2875",
   "metadata": {
    "papermill": {
     "duration": 0.009902,
     "end_time": "2025-02-03T01:37:38.248859",
     "exception": false,
     "start_time": "2025-02-03T01:37:38.238957",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_train = dataset_train.remove_columns(['Unnamed: 0','Unnamed: 0.1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cbcdbc4c",
   "metadata": {
    "papermill": {
     "duration": 0.009293,
     "end_time": "2025-02-03T01:37:38.263143",
     "exception": false,
     "start_time": "2025-02-03T01:37:38.253850",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['title', 'abstract'],\n",
       "    num_rows: 94073\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c3dbc53",
   "metadata": {
    "papermill": {
     "duration": 0.010085,
     "end_time": "2025-02-03T01:37:38.278239",
     "exception": false,
     "start_time": "2025-02-03T01:37:38.268154",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Condition monitoring and early diagnostics methodologies for hydropower\\n  plants',\n",
       " 'abstract': '  Hydropower plants are one of the most convenient option for power generation,\\nas they generate energy exploiting a renewable source, they have relatively low\\noperating and maintenance costs, and they may be used to provide ancillary\\nservices, exploiting the large reservoirs of available water. The recent\\nadvances in Information and Communication Technologies (ICT) and in machine\\nlearning methodologies are seen as fundamental enablers to upgrade and\\nmodernize the current operation of most hydropower plants, in terms of\\ncondition monitoring, early diagnostics and eventually predictive maintenance.\\nWhile very few works, or running technologies, have been documented so far for\\nthe hydro case, in this paper we propose a novel Key Performance Indicator\\n(KPI) that we have recently developed and tested on operating hydropower\\nplants. In particular, we show that after more than one year of operation it\\nhas been able to identify several faults, and to support the operation and\\nmaintenance tasks of plant operators. Also, we show that the proposed KPI\\noutperforms conventional multivariable process control charts, like the\\nHotelling $t_2$ index.\\n'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "045e63c7",
   "metadata": {
    "papermill": {
     "duration": 5.109443,
     "end_time": "2025-02-03T01:37:43.392763",
     "exception": false,
     "start_time": "2025-02-03T01:37:38.283320",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6f6c29fb8684d55a7104b6bd6b6e22c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/94073 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_train = dataset_train.map(lambda x, idx: { 'index': idx }, with_indices=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4e9748a",
   "metadata": {
    "papermill": {
     "duration": 0.009764,
     "end_time": "2025-02-03T01:37:43.410221",
     "exception": false,
     "start_time": "2025-02-03T01:37:43.400457",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['title', 'abstract', 'index'],\n",
       "    num_rows: 94073\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69efe8a2",
   "metadata": {
    "papermill": {
     "duration": 0.010187,
     "end_time": "2025-02-03T01:37:43.425796",
     "exception": false,
     "start_time": "2025-02-03T01:37:43.415609",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'MetaTune: Meta-Learning Based Cost Model for Fast and Efficient\\n  Auto-tuning Frameworks',\n",
       " 'abstract': '  Deep learning compiler frameworks are gaining ground as a more portable\\nback-end for deep learning applications on increasingly diverse hardware.\\nHowever, they face the daunting challenge of matching performance offered by\\nhand-tuned target-specific libraries. While auto-tuning frameworks with\\nstatistical cost models can provide dynamic and efficient code optimization,\\nthey suffer from large space exploration and cost model training overheads.\\nThis paper proposes MetaTune, a meta-learning based cost model that more\\nquickly and accurately predicts the performance of optimized codes with\\npre-trained model parameters. MetaTune encodes convolution kernel codes as\\nstructurally similar graphs to facilitate meta-learning, meta-trains a GNN\\nmodel with a very small input data set, and then predicts optimization\\nparameters for unseen convolution operations with varying sizes and structures\\nduring compilation. The resulting framework with MetaTune provides 8 to 13%\\nbetter inference time on average for four CNN models with comparable or lower\\noptimization time while outperforming transfer learning by 10% in\\ncross-platform cases.\\n',\n",
       " 'index': 4}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63f1c92e",
   "metadata": {
    "papermill": {
     "duration": 0.010049,
     "end_time": "2025-02-03T01:37:43.441339",
     "exception": false,
     "start_time": "2025-02-03T01:37:43.431290",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Asymptotics of $\\\\ell_2$ Regularized Network Embeddings',\n",
       " 'abstract': '  A common approach to solving prediction tasks on large networks, such as node\\nclassification or link prediction, begin by learning a Euclidean embedding of\\nthe nodes of the network, from which traditional machine learning methods can\\nthen be applied. This includes methods such as DeepWalk and node2vec, which\\nlearn embeddings by optimizing stochastic losses formed over subsamples of the\\ngraph at each iteration of stochastic gradient descent. In this paper, we study\\nthe effects of adding an $\\\\ell_2$ penalty of the embedding vectors to the\\ntraining loss of these types of methods. We prove that, under some\\nexchangeability assumptions on the graph, this asymptotically leads to learning\\na graphon with a nuclear-norm-type penalty, and give guarantees for the\\nasymptotic distribution of the learned embedding vectors. In particular, the\\nexact form of the penalty depends on the choice of subsampling method used as\\npart of stochastic gradient descent. We also illustrate empirically that\\nconcatenating node covariates to $\\\\ell_2$ regularized node2vec embeddings leads\\nto comparable, when not superior, performance to methods which incorporate node\\ncovariates and the network structure in a non-linear manner.\\n',\n",
       " 'index': 20572}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_train[20572]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9993947",
   "metadata": {
    "papermill": {
     "duration": 0.055716,
     "end_time": "2025-02-03T01:37:43.502650",
     "exception": false,
     "start_time": "2025-02-03T01:37:43.446934",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "all_indexes = np.array(dataset_train['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3c956f8e",
   "metadata": {
    "papermill": {
     "duration": 0.011072,
     "end_time": "2025-02-03T01:37:43.519321",
     "exception": false,
     "start_time": "2025-02-03T01:37:43.508249",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def generate_hard_negatives(example, num_negatives=10,dataset=dataset_train):\n",
    "    query_index = example['index'] \n",
    "    anchor = example['title']\n",
    "    positive = example['abstract']\n",
    "    \n",
    "    negatives = []\n",
    "    \n",
    "    negative_indexes = np.delete(all_indexes, np.where(all_indexes == query_index))\n",
    "    \n",
    "    sampled_negatives = random.sample(list(negative_indexes), num_negatives)\n",
    "    \n",
    "    for idx in sampled_negatives:\n",
    "        negatives.append(dataset[int(idx)]['abstract'])\n",
    "    \n",
    "    return {\n",
    "        \"query\": anchor,\n",
    "        \"positive\": positive,\n",
    "        \"negatives\": negatives\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6ab12866",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": false,
     "start_time": "2025-02-03T01:37:43.525186",
     "status": "running"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21f8b90f12b9423180640c84a6e8196c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/94073 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "processed_data_train = dataset_train.map(generate_hard_negatives, remove_columns=dataset_train.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "861c271d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['query', 'positive', 'negatives'],\n",
       "    num_rows: 94073\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "96368bc5",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'Condition monitoring and early diagnostics methodologies for hydropower\\n  plants',\n",
       " 'positive': '  Hydropower plants are one of the most convenient option for power generation,\\nas they generate energy exploiting a renewable source, they have relatively low\\noperating and maintenance costs, and they may be used to provide ancillary\\nservices, exploiting the large reservoirs of available water. The recent\\nadvances in Information and Communication Technologies (ICT) and in machine\\nlearning methodologies are seen as fundamental enablers to upgrade and\\nmodernize the current operation of most hydropower plants, in terms of\\ncondition monitoring, early diagnostics and eventually predictive maintenance.\\nWhile very few works, or running technologies, have been documented so far for\\nthe hydro case, in this paper we propose a novel Key Performance Indicator\\n(KPI) that we have recently developed and tested on operating hydropower\\nplants. In particular, we show that after more than one year of operation it\\nhas been able to identify several faults, and to support the operation and\\nmaintenance tasks of plant operators. Also, we show that the proposed KPI\\noutperforms conventional multivariable process control charts, like the\\nHotelling $t_2$ index.\\n',\n",
       " 'negatives': ['  Kernel methods are considered an effective technique for on-line learning.\\nMany approaches have been developed for compactly representing the dual\\nsolution of a kernel method when the problem imposes memory constraints.\\nHowever, in literature no work is specifically tailored to streams of graphs.\\nMotivated by the fact that the size of the feature space representation of many\\nstate-of-the-art graph kernels is relatively small and thus it is explicitly\\ncomputable, we study whether executing kernel algorithms in the feature space\\ncan be more effective than the classical dual approach. We study three\\ndifferent algorithms and various strategies for managing the budget. Efficiency\\nand efficacy of the proposed approaches are experimentally assessed on\\nrelatively large graph streams exhibiting concept drift. It turns out that,\\nwhen strict memory budget constraints have to be enforced, working in feature\\nspace, given the current state of the art on graph kernels, is more than a\\nviable alternative to dual approaches, both in terms of speed and\\nclassification performance.\\n',\n",
       "  '  In variable or graph selection problems, finding a right-sized model or\\ncontrolling the number of false positives is notoriously difficult. Recently, a\\nmeta-algorithm called Stability Selection was proposed that can provide\\nreliable finite-sample control of the number of false positives. Its benefits\\nwere demonstrated when used in conjunction with the lasso and orthogonal\\nmatching pursuit algorithms.\\n  In this paper, we investigate the applicability of stability selection to\\nstructured selection algorithms: the group lasso and the structured\\ninput-output lasso. We find that using stability selection often increases the\\npower of both algorithms, but that the presence of complex structure reduces\\nthe reliability of error control under stability selection. We give strategies\\nfor setting tuning parameters to obtain a good model size under stability\\nselection, and highlight its strengths and weaknesses compared to competing\\nmethods screen and clean and cross-validation. We give guidelines about when to\\nuse which error control method.\\n',\n",
       "  '  Methods for learning from data depend on various types of tuning parameters,\\nsuch as penalization strength or step size. Since performance can depend\\nstrongly on these parameters, it is important to compare classes of\\nestimators-by considering prescribed finite sets of tuning parameters-not just\\nparticularly tuned methods. In this work, we investigate classes of methods via\\nthe relative performance of the best method in the class. We consider the\\ncentral problem of linear regression-with a random isotropic ground truth-and\\ninvestigate the estimation performance of two fundamental methods, gradient\\ndescent and ridge regression. We unveil the following phenomena. (1) For\\ngeneral designs, constant stepsize gradient descent outperforms ridge\\nregression when the eigenvalues of the empirical data covariance matrix decay\\nslowly, as a power law with exponent less than unity. If instead the\\neigenvalues decay quickly, as a power law with exponent greater than unity or\\nexponentially, we show that ridge regression outperforms gradient descent. (2)\\nFor orthogonal designs, we compute the exact minimax optimal class of\\nestimators (achieving min-max-min optimality), showing it is equivalent to\\ngradient descent with decaying learning rate. We find the sub-optimality of\\nridge regression and gradient descent with constant step size. Our results\\nhighlight that statistical performance can depend strongly on tuning\\nparameters. In particular, while optimally tuned ridge regression is the best\\nestimator in our setting, it can be outperformed by gradient descent by an\\narbitrary/unbounded amount when both methods are only tuned over finitely many\\nregularization parameters.\\n',\n",
       "  '  Accurate 3D object detection (3DOD) is crucial for safe navigation of complex\\nenvironments by autonomous robots. Regressing accurate 3D bounding boxes in\\ncluttered environments based on sparse LiDAR data is however a highly\\nchallenging problem. We address this task by exploring recent advances in\\nconditional energy-based models (EBMs) for probabilistic regression. While\\nmethods employing EBMs for regression have demonstrated impressive performance\\non 2D object detection in images, these techniques are not directly applicable\\nto 3D bounding boxes. In this work, we therefore design a differentiable\\npooling operator for 3D bounding boxes, serving as the core module of our EBM\\nnetwork. We further integrate this general approach into the state-of-the-art\\n3D object detector SA-SSD. On the KITTI dataset, our proposed approach\\nconsistently outperforms the SA-SSD baseline across all 3DOD metrics,\\ndemonstrating the potential of EBM-based regression for highly accurate 3DOD.\\nCode is available at https://github.com/fregu856/ebms_3dod.\\n',\n",
       "  '  Spherical signals exist in many applications, e.g., planetary data, LiDAR\\nscans and digitalization of 3D objects, calling for models that can process\\nspherical data effectively. It does not perform well when simply projecting\\nspherical data into the 2D plane and then using planar convolution neural\\nnetworks (CNNs), because of the distortion from projection and ineffective\\ntranslation equivariance. Actually, good principles of designing spherical CNNs\\nare avoiding distortions and converting the shift equivariance property in\\nplanar CNNs to rotation equivariance in the spherical domain. In this work, we\\nuse partial differential operators (PDOs) to design a spherical equivariant\\nCNN, PDO-eS2CNN, which is exactly rotation equivariant in the continuous\\ndomain. We then discretize PDO-eS2CNNs, and analyze the equivariance error\\nresulted from discretization. This is the first time that the equivariance\\nerror is theoretically analyzed in the spherical domain. In experiments,\\nPDO-eS2CNNs show greater parameter efficiency and outperform other spherical\\nCNNs significantly on several tasks.\\n',\n",
       "  '  Our community has greatly improved the efficiency of deep learning\\napplications, including by exploiting sparsity in inputs. Most of that work,\\nthough, is for inference, where weight sparsity is known statically, and/or for\\nspecialized hardware. We propose a scheme to leverage dynamic sparsity during\\ntraining. In particular, we exploit zeros introduced by the ReLU activation\\nfunction to both feature maps and their gradients. This is challenging because\\nthe sparsity degree is moderate and the locations of zeros change over time. We\\nalso rely purely on software. We identify zeros in a dense data representation\\nwithout transforming the data and performs conventional vectorized computation.\\nVariations of the scheme are applicable to all major components of training:\\nforward propagation, backward propagation by inputs, and backward propagation\\nby weights. Our method significantly outperforms a highly-optimized dense\\ndirect convolution on several popular deep neural networks. At realistic\\nsparsity, we speed up the training of the non-initial convolutional layers in\\nVGG16, ResNet-34, ResNet-50, and Fixup ResNet-50 by 2.19x, 1.37x, 1.31x, and\\n1.51x respectively on an Intel Skylake-X CPU.\\n',\n",
       "  \"  Convolutional Neural Networks and Deep Learning classification systems in\\ngeneral have been shown to be vulnerable to attack by specially crafted data\\nsamples that appear to belong to one class but are instead classified as\\nanother, commonly known as adversarial examples. A variety of attack strategies\\nhave been proposed to craft these samples; however, there is no standard model\\nthat is used to compare the success of each type of attack. Furthermore, there\\nis no literature currently available that evaluates how common hyperparameters\\nand optimization strategies may impact a model's ability to resist these\\nsamples. This research bridges that lack of awareness and provides a means for\\nthe selection of training and model parameters in future research on evasion\\nattacks against convolutional neural networks. The findings of this work\\nindicate that the selection of model hyperparameters does impact the ability of\\na model to resist attack, although they alone cannot prevent the existence of\\nadversarial examples.\\n\",\n",
       "  \"  Any-to-any voice conversion aims to convert the voice from and to any\\nspeakers even unseen during training, which is much more challenging compared\\nto one-to-one or many-to-many tasks, but much more attractive in real-world\\nscenarios. In this paper we proposed FragmentVC, in which the latent phonetic\\nstructure of the utterance from the source speaker is obtained from Wav2Vec\\n2.0, while the spectral features of the utterance(s) from the target speaker\\nare obtained from log mel-spectrograms. By aligning the hidden structures of\\nthe two different feature spaces with a two-stage training process, FragmentVC\\nis able to extract fine-grained voice fragments from the target speaker\\nutterance(s) and fuse them into the desired utterance, all based on the\\nattention mechanism of Transformer as verified with analysis on attention maps,\\nand is accomplished end-to-end. This approach is trained with reconstruction\\nloss only without any disentanglement considerations between content and\\nspeaker information and doesn't require parallel data. Objective evaluation\\nbased on speaker verification and subjective evaluation with MOS both showed\\nthat this approach outperformed SOTA approaches, such as AdaIN-VC and AutoVC.\\n\",\n",
       "  'We develop a deep learning based convolutional-regression model that\\nestimates the volumetric soil moisture content in the top ~5 cm of soil. Input\\npredictors include Sentinel-1 (active radar), Sentinel-2 (optical imagery), and\\nSMAP (passive radar) as well as geophysical variables from SoilGrids and\\nmodelled soil moisture fields from GLDAS. The model was trained and evaluated\\non data from ~1300 in-situ sensors globally over the period 2015 - 2021 and\\nobtained an average per-sensor correlation of 0.727 and ubRMSE of 0.054, and\\ncan be used to produce a soil moisture map at a nominal 320m resolution. These\\nresults are benchmarked against 13 other soil moisture works at different\\nlocations, and an ablation study was used to identify important predictors.',\n",
       "  '  Natural language often exhibits inherent hierarchical structure ingrained\\nwith complex syntax and semantics. However, most state-of-the-art deep\\ngenerative models learn embeddings only in Euclidean vector space, without\\naccounting for this structural property of language. In this paper, we\\ninvestigate text generation in a hyperbolic latent space to learn continuous\\nhierarchical representations. An Adversarial Poincare Variational Autoencoder\\n(APo-VAE) is presented, where both the prior and variational posterior of\\nlatent variables are defined over a Poincare ball via wrapped normal\\ndistributions. By adopting the primal-dual formulation of KL divergence, an\\nadversarial learning procedure is introduced to empower robust model training.\\nExtensive experiments in language modeling and dialog-response generation tasks\\ndemonstrate the winning effectiveness of the proposed APo-VAE model over VAEs\\nin Euclidean latent space, thanks to its superb capabilities in capturing\\nlatent language hierarchies in hyperbolic space.\\n']}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_data_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6188e153",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "contrastive_pairs_train = []\n",
    "for item in processed_data_train:\n",
    "    query = item[\"query\"]\n",
    "    positive = item[\"positive\"]\n",
    "    negatives = item[\"negatives\"]\n",
    "    contrastive_pairs_train.append({\n",
    "        \"anchor\": query,\n",
    "        \"positive\": positive,\n",
    "        \"negatives\": negatives\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "669c6a2e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94073"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(contrastive_pairs_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "670559eb",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "927b2173",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ContrastiveDataset:\n",
    "    def __init__(self, pairs):\n",
    "        self.pairs = pairs\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.pairs[idx]\n",
    "        return item[\"anchor\"], item[\"positive\"], item[\"negatives\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6918b6f3",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "contrastive_dataset_train = ContrastiveDataset(contrastive_pairs_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "362b05af",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_loader_train = DataLoader(contrastive_dataset_train, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9e89b105",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_loader_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ec267846",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cdfef80f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = AutoModel.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9191c4f0",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c5386cc4",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lora_config = LoraConfig(\n",
    "    task_type= \"FEATURE_EXTRACTION\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1411c521",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lora_model = get_peft_model(model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5b81fc5d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cosine_distance(x, y):\n",
    "    return 1 - torch.nn.functional.cosine_similarity(x, y, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "36a6dc08",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def info_nce_loss(anchor_embedding, positive_embedding, negative_embedding, distance_fn):\n",
    "\n",
    "    pos_dist = distance_fn(anchor_embedding, positive_embedding)\n",
    "    neg_dist = torch.stack([distance_fn(anchor_embedding, neg) for neg in negative_embedding], dim=-1)\n",
    "    \n",
    "    logits = torch.cat([-pos_dist.unsqueeze(1), -neg_dist], dim=1)\n",
    "    labels = torch.zeros(logits.size(0), dtype=torch.long, device=logits.device)\n",
    "\n",
    "    loss = torch.nn.CrossEntropyLoss()(logits, labels)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "185ff980",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "optimizer = torch.optim.AdamW(lora_model.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d997d7dc",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_epochs=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "93312d1a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "be00cde7",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a5333e18",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1d718a7f",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lora_model = lora_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8d0b1bf1",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_val = split_datasets[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1ca99f37",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['Unnamed: 0.1', 'Unnamed: 0', 'title', 'abstract'],\n",
       "    num_rows: 23519\n",
       "})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a314d3d6",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_val = dataset_val.remove_columns(['Unnamed: 0','Unnamed: 0.1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a58b2f1a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b87eafbb2487427180512d32ae5b1c63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/23519 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_val = dataset_val.map(lambda x, idx: { 'index': idx }, with_indices=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "454fc03a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['title', 'abstract', 'index'],\n",
       "    num_rows: 23519\n",
       "})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "59611a3b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_indexes_val = np.array(dataset_val['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f51a8e7e",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_hard_negatives_val(example, num_negatives=10,dataset=dataset_val):\n",
    "    query_index = example['index']\n",
    "    anchor = example['title']\n",
    "    positive = example['abstract']\n",
    "    \n",
    "    negatives = []\n",
    "    \n",
    "    negative_indexes = np.delete(all_indexes_val, np.where(all_indexes_val == query_index))\n",
    "    \n",
    "    sampled_negatives = random.sample(list(negative_indexes), num_negatives)\n",
    "    \n",
    "    for idx in sampled_negatives:\n",
    "        negatives.append(dataset[int(idx)]['abstract'])\n",
    "    \n",
    "    return {\n",
    "        \"query\": anchor,\n",
    "        \"positive\": positive,\n",
    "        \"negatives\": negatives\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "956100e1",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97574d893f774fe7bb153dc689dd94fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/23519 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "processed_data_val = dataset_val.map(generate_hard_negatives_val, remove_columns=dataset_val.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "70ecac28",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "contrastive_pairs_val = []\n",
    "for item in processed_data_val:\n",
    "    query = item[\"query\"]\n",
    "    positive = item[\"positive\"]\n",
    "    negatives = item[\"negatives\"]\n",
    "    contrastive_pairs_val.append({\n",
    "        \"anchor\": query,\n",
    "        \"positive\": positive,\n",
    "        \"negatives\": negatives\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ce529ab6",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "contrastive_dataset_val = ContrastiveDataset(contrastive_pairs_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5ac55437",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_loader_val = DataLoader(contrastive_dataset_val, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b73033c1",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_loader_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3004b977-0045-4fa7-9552-f4c50215714d",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def avg_embedding(inputs, model):\n",
    "    input=model(**inputs)\n",
    "    input_last_hidden_state=input.last_hidden_state\n",
    "    input_attention_mask = inputs['attention_mask']\n",
    "    input_masked_embeddings = input_last_hidden_state * input_attention_mask.unsqueeze(-1)\n",
    "    input_sum_embeddings = torch.sum(input_masked_embeddings, dim=1)\n",
    "    input_token_counts = torch.sum(input_attention_mask, dim=1).unsqueeze(-1)\n",
    "    input_avg_embeddings = input_sum_embeddings / input_token_counts\n",
    "    return(input_avg_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "76c29dae",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_mrr(model, data_loader_val, distance_fn):\n",
    "    model.eval()  \n",
    "\n",
    "    total_rr = 0.0\n",
    "    num_queries = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader_val:\n",
    "            anchor_text = batch[0]\n",
    "            positive_text = batch[1]\n",
    "            negative_texts = batch[2]\n",
    "\n",
    "            anchor_input = tokenizer(anchor_text, return_tensors='pt', padding=True, truncation=True, max_length=512).to(device)\n",
    "            positive_input = tokenizer(positive_text, return_tensors='pt', padding=True, truncation=True, max_length=512).to(device)\n",
    "\n",
    "            anchor_embedding = avg_embedding(anchor_input, model)\n",
    "            positive_embedding = avg_embedding(positive_input, model)\n",
    "            negative_embedding = [avg_embedding(tokenizer(neg, return_tensors='pt', padding=True, truncation=True, max_length=512).to(device), model) for neg in negative_texts]\n",
    "\n",
    "            pos_dist = distance_fn(anchor_embedding, positive_embedding)\n",
    "            neg_dist = torch.stack([distance_fn(anchor_embedding, neg) for neg in negative_embedding], dim=-1)\n",
    "            all_similarities=torch.cat([-pos_dist.unsqueeze(1), -neg_dist], dim=1)\n",
    "            \n",
    "            sorted_similarities, sorted_indices = torch.sort(all_similarities, dim=1, descending=True)\n",
    "\n",
    "            # Find the rank of the first relevant (positive) document\n",
    "            positive_rank = (sorted_indices == 0).nonzero(as_tuple=True)[1] + 1  # +1 to make rank 1-based\n",
    "            total_rr += torch.sum(1.0 / positive_rank.float()).item()  # Reciprocal rank\n",
    "            num_queries += len(positive_rank)\n",
    "\n",
    "    mrr = total_rr / num_queries\n",
    "    return mrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "84893f41",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "save_dir =\"/dss/dsshome1/07/ra65bex2/srawat/average\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1e46bee6",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "epoch_metrics = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "23f95333",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "32a21d84",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1:\n",
      "Checkpoint saved: /dss/dsshome1/07/ra65bex2/srawat/average/checkpoint_epoch_1.pth\n",
      "Epoch 1/3, Training Loss: 2.33770759900411\n",
      "Mean Reciprocal Rank (MRR) for validation set: 0.2983\n",
      "Epoch 1 took 0.2382 minutes.\n",
      "\n",
      "\n",
      "EPOCH 2:\n",
      "Checkpoint saved: /dss/dsshome1/07/ra65bex2/srawat/average/checkpoint_epoch_2.pth\n",
      "Epoch 2/3, Training Loss: 2.337019364039103\n",
      "Mean Reciprocal Rank (MRR) for validation set: 0.2983\n",
      "Epoch 2 took 0.1911 minutes.\n",
      "\n",
      "\n",
      "EPOCH 3:\n",
      "Checkpoint saved: /dss/dsshome1/07/ra65bex2/srawat/average/checkpoint_epoch_3.pth\n",
      "Epoch 3/3, Training Loss: 2.3341899712880454\n",
      "Mean Reciprocal Rank (MRR) for validation set: 0.2983\n",
      "Epoch 3 took 0.1808 minutes.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    start_time = time.time()\n",
    "    lora_model.train()\n",
    "    \n",
    "    total_loss = 0.0\n",
    "    for batch in data_loader_train:\n",
    "    \n",
    "        anchor_texts = batch[0]\n",
    "        positive_texts = batch[1]\n",
    "        negative_texts = batch[2]\n",
    "    \n",
    "        anchor_inputs = tokenizer(anchor_texts, return_tensors='pt', padding=True, truncation=True, max_length=512).to(device)\n",
    "        positive_inputs = tokenizer(positive_texts, return_tensors='pt', padding=True, truncation=True, max_length=512).to(device)\n",
    "\n",
    "    \n",
    "        anchor_embedding = avg_embedding(anchor_inputs, lora_model)\n",
    "        positive_embedding = avg_embedding(positive_inputs, lora_model)\n",
    "        negative_embedding = [avg_embedding(tokenizer(neg, return_tensors='pt', padding=True, truncation=True, max_length=512).to(device), lora_model) for neg in negative_texts]\n",
    "\n",
    "        loss = info_nce_loss(anchor_embedding, positive_embedding, negative_embedding, distance_fn=cosine_distance)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    save_path = os.path.join(save_dir, f\"checkpoint_epoch_{epoch+1}.pth\")\n",
    "    torch.save(lora_model, save_path)\n",
    "    print(f\"EPOCH {epoch+1}:\")\n",
    "    print(f\"Checkpoint saved: {save_path}\")\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Training Loss: {total_loss / len(data_loader_train)}\")\n",
    "    mrr_validation = evaluate_mrr(lora_model, data_loader_val, cosine_distance)\n",
    "    #mrr_train = evaluate_mrr(lora_model, data_loader_train, cosine_distance)\n",
    "    #print(f\"Mean Reciprocal Rank (MRR) for training set: {mrr_train:.4f}\")\n",
    "    print(f\"Mean Reciprocal Rank (MRR) for validation set: {mrr_validation:.4f}\")\n",
    "    end_time = time.time()\n",
    "    print(f\"Epoch {epoch+1} took {(end_time - start_time) / 60:.4f} minutes.\")\n",
    "    print(f\"\\n\")\n",
    "    epoch_metrics.append({\n",
    "        'epoch': epoch + 1,\n",
    "        'training_loss': total_loss / len(data_loader_train),\n",
    "        'mrr_validation': mrr_validation,\n",
    "        'time_taken_minutes': (end_time - start_time) / 60\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c27c8a",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a682b1",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(save_dir + '/epoch_metrics.json', 'w') as f:\n",
    "    json.dump(epoch_metrics, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7021e82",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "papermill": {
   "default_parameters": {},
   "duration": null,
   "end_time": null,
   "environment_variables": {},
   "exception": null,
   "input_path": "baseline.ipynb",
   "output_path": "baseline.ipynb",
   "parameters": {},
   "start_time": "2025-02-03T01:37:23.753984",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
